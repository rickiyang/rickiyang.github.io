<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[java重试工具类:spring-retry和guava-retryer]]></title>
    <url>%2Fposts%2F73e3dbd9.html</url>
    <content type="text"><![CDATA[日常开发中经常遇到调用外部接口失败的情况，这时候我们需要去设置失败重试机制，正常情况我们的重试机制是：如果出错了，一般是网络抖动或者延迟的情况，设置重试一次，或者几次，可能是如下方案：try-catch-redo简单重试模式： 12345try&#123; doSomething();&#125; catch &#123; redo();&#125; 如果想定制什么时候重试，重试几次，就需要我们自己定义重试策略，那么我们的代码就稍微复杂一些，可能是如下方案：try-catch-redo-retry strategy策略重试模式： 12345try&#123; doSomething();&#125; catch &#123; redo(retryTime,interval);&#125; 如上是我们一般的处理方案，由上我们大致可以看出如果想要实现一个优雅的重试方案，需要我们详细的去考虑重试机制，重试策略，重试失败措施，重试代码如何做到不侵入业务代码等等。所以，这样的一个小功能我们也是可以做成很有意思的小组件的。现代分布式系统中系统调用如此频繁，重试机制也是大家开发中的重复性劳动，所以这种不必要的代码已经有人给我们写好了，分别是Java中的Spring-Retry和Guava-Retrying。 其中Spring-Retry是基于Throwable类型的重试机制，即针对可捕获异常执行重试策略，并提供相应的回滚策略；而Guava-Retrying提供了更为丰富的重试源定义，譬如多个异常或者多个返回值。 Spring-Retry: 引入jar包： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt; &lt;version&gt;1.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; 通过构造一个重试模板来执行重试策略，在重试模板中可以设置重试次数，重试间隔和回退策略。我们通过一段代码来看一下： 123456789101112131415161718192021222324252627282930313233343536public void retryDoSomething(final Map&lt;String, Object&gt; map) throws Exception &#123; // 构建重试模板实例 RetryTemplate retryTemplate = new RetryTemplate(); // 设置重试策略，主要设置重试次数 SimpleRetryPolicy policy = new SimpleRetryPolicy(3, Collections.singletonMap(Exception.class, true)); // 设置重试回退操作策略，主要设置重试间隔时间 FixedBackOffPolicy fixedBackOffPolicy = new FixedBackOffPolicy(); fixedBackOffPolicy.setBackOffPeriod(100); retryTemplate.setRetryPolicy(policy); retryTemplate.setBackOffPolicy(fixedBackOffPolicy); // 通过RetryCallback 重试回调实例包装正常逻辑逻辑，第一次执行和重试执行执行的都是这段逻辑 final RetryCallback&lt;Object, Exception&gt; retryCallback = new RetryCallback&lt;Object, Exception&gt;() &#123; //RetryContext 重试操作上下文约定，统一spring-try包装 @Override public Object doWithRetry(RetryContext context) throws Exception &#123; System.out.println("do some thing"); Exception e = doSomething(map); System.out.println(context.getRetryCount()); throw e;//这个点特别注意，重试的根源通过Exception返回 &#125; &#125;; // 通过RecoveryCallback 重试流程正常结束或者达到重试上限后的退出恢复操作实例 final RecoveryCallback&lt;Object&gt; recoveryCallback = new RecoveryCallback&lt;Object&gt;() &#123; @Override public Object recover(RetryContext context) throws Exception &#123; System.out.println("do recory operation"); return null; &#125; &#125;; try &#123; // 由retryTemplate 执行execute方法开始逻辑执行 retryTemplate.execute(retryCallback, recoveryCallback); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; spring-retry是通过RetryTemplate的execute方法来执行重试代码的，execute方法是线程安全的，实现中他将retry的餐参数对象保存在ThreadLocal中： 123RetryContext context = this.open(retryPolicy, state);//ThreadLocal中保存context对象RetrySynchronizationManager.register(context); 以上代码需要注意的是重试的执行逻辑是在RetryCallback类中实现的，触发重试逻辑是在doWithRetry方法中抛出泛型异常。这就意味着如果你的代码并没有异常抛出但是仍然需要在某种返回值的条件下触发重试逻辑的时候，你需要手动的判断该返回值然后抛出异常。这个操作有点强人所难。 所以在此基础之上，guava-retryer重新做了设计，在支持重试次数和重试频度的基础上，能够兼容支持多个异常或者自定义实体对象的重试源定义。 引入jar： 12345&lt;dependency&gt; &lt;groupId&gt;com.github.rholder&lt;/groupId&gt; &lt;artifactId&gt;guava-retrying&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt; 代码如下：1234567891011121314151617181920212223242526public LedgerResult requestRestry(NrRequestParams nrRequestParams) &#123; Retryer&lt;LedgerResult&gt; retryer = RetryerBuilder.&lt;LedgerResult&gt;newBuilder() .retryIfExceptionOfType(BizException.class) .retryIfException() .retryIfResult(result -&gt; result == null) .withWaitStrategy(WaitStrategies.fixedWait(5, TimeUnit.MINUTES)) .withStopStrategy(StopStrategies.stopAfterAttempt(10)) .withRetryListener(new RetryListener() &#123; @Override public &lt;V&gt; void onRetry(Attempt&lt;V&gt; attempt) &#123; long attemptNumber = attempt.getAttemptNumber(); if (attemptNumber &gt; 1) &#123; logger.info("&lt;=====重试次数:&#123;&#125;,params:&#123;&#125;", attemptNumber - 1, nrRequestParams); &#125; &#125; &#125;) .build(); try &#123; return retryer.call(() -&gt; requestLedger(nrRequestParams)); &#125; catch (ExecutionException e) &#123; logger.error("&lt;&lt;&lt;&lt;&lt;=====重试失败====参数：&#123;&#125;", nrRequestParams, e); &#125; catch (RetryException e) &#123; logger.error("&lt;&lt;&lt;&lt;&lt;=====重试失败====参数：&#123;&#125;", nrRequestParams, e); &#125; return null; &#125; 通过RetryerBuilder来构造工厂对象，设置重试策略，比如支持特定异常类型，支持检测返回值类型判定，一个全局的监控方法，更加优雅的重试策略和停止策略设置等等。 guava的api对于用户来说更加的友好，大家会选择哪一个用于日常开发不言自明。]]></content>
      <categories>
        <category>java开发工具类</category>
      </categories>
      <tags>
        <tag>工具类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive基础知识]]></title>
    <url>%2Fposts%2F88686410.html</url>
    <content type="text"><![CDATA[hive基础知识Hive是建立在 Hadoop上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。Hive定义了简单的类 SQL查询语言，称为HQL，它允许熟悉SQL的用户查询数据。同时，这个语言也允许熟悉MapReduce开发者的开发自定义的mapper和reducer来处理内建的mapper和reducer无法完成的复杂的分析工作。 2.为什么会产生hive方便非java编程者（熟悉SQL语言）对hdfs的数据做mapreduce操作。 3.hive能做什么数据仓库： 不与用户交互；存放历史数据；反范式设计，专门引入冗余数据，保证数据完整。数据仓库面向分析，里面存放的数据用来做分析和挖掘。Hive是数据仓库，Hive将SQL转化为MapReduce可以识别的操作，承担解释器、编译器、优化器等角色，Hive运行时，元数据（表的结构、属性）存储在关系型数据库里面。因为元数据信息需要高效的读取。 4.初识hive4.1 hive数据类型hive支持的数据类型包括： 基本类型：tinyint, smallint, int,bigint, boolean, float, double, string,varchar,char 复杂类型：struct，map，array,data,timestamp 4.2 hive数据模型hive支持四中数据模型： external table 外部表 table 默认为内部表 partion 分区表 bucket 桶表 内部表：为指定表为别的形式的表默认都为内部表，hive会为其建立一个相应的目录保存。删除表时，元数据和数据都会被删除。 12create table test (name string , age string) location '/input/table_data';load data inpath '/input/data' into table test ; load命令会将/input/data下的数据加载到/input/table_data目录下，当删除test表的时候test表数据和/input/table_data下的数据都被删除。当然/input/data下也没有数据。如果创建内部表的时候没有指定location，就会在hdfs/hive，hdfs的默认目录下新建一个表目录。 注：本质上load data会转移数据。 外部表: 12create external table etest (name string , age string);load data inpath '/input/edata' into table etest; 当把/input/edata下的数据转移到hdfs的默认目录后执行删除操作，默认目录中已经载入的数据不会被删除，但是/input/edata下的数据已经没有了，相当于做了一次剪切操作。 分区表：hive的表在hdfs上是对应一个文件目录保存的，当使用hive进行查询的时候会对该目录下的文件进行全表扫描，这样是很浪费性能的，这样就引入了partion(分区)和bucket(桶)的概念。 分区表是指创建表时，指定partition的分区空间: partition by(字段名 字段类型) 分区表又分动态分区和静态分区，静态分区要求在建表的时候指定分区字段： 12345678create table dyn_part_test_spark( name string, score string)partitioned by ( grade string, class string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ','; 在装载完数据之后，分区的列grade和class所对应的值会生成若干个子目录，假如有如下插入语句： 1insert overwrite table dyn_part_test_spark partition(grade='grade1',class='class1') 那么查询的时候数据就位于grade1目录下的class1目录里面。 但是静态分区会有一个问题，那就是在分区之前对应分区的值是需要被确定的，即partition后面的值需要被确定。当值有很多个的时候，就需要重复执行很多类似于上面insert语句这样的插入语句。即在插入的时候需要指定你要插入那个分区，不然插入失败。 为了解决这个问题，所以提出了动态分区。 123456CREATE TABLE order_created_dynamic_partition ( orderNumber STRING, event_time STRING)PARTITIONED BY (event_month string);insert overwrite table dyn_part_test_spark partition(grade,class); 注意到insert语句后面没有指定具体的值，执行成功以后hdfs就会生成相应值对应的文件夹。这就是动态分区的好处。 要让hive表自动生成分区需要配置开启动态分区，配置如下： SET hive.exec.dynamic.partition=true; //是否开启动态分区，默认为false SET hive.exec.dynamic.partition.mode=nonstrict; //动态分区的模式，默认为strict SET hive.exec.max.dynamic.partitions.pernode = 1000;//在每个执行MR的节点上最大可创建分区个数，默认值100 SET hive.exec.max.dynamic.partitions=1000;//在所有执行MR的节点上，最大可创建多少分区，默认1000 桶表：对于每一个表或者是分区可以进一步组织为桶。在分桶时，对指定字段进行hash运算得到hash值，用hash值除以桶个数取余得到的值作为分桶依据。余数相同的数据会分到同一个桶。做hash运算时hash函数的选择取决于分桶字段的数据类型。分桶之后的查询效率比分区之后的效率要高。 1234create table teacher(id INT, name string, tno string,age INT)partitioned by (work_date string)clustered by (id) sorted by (name) into 2 bucketsrow format delimited fields terminated by ',' stored as textfile; hive中的table可以拆分为partition,table和partition可以进一步的通过”clustered by”拆分为桶，桶中的数据可以通过”sorted by”进行排序。比如上面的sql语句中通过id进行分桶，每个桶中的数据通过id进行排序。 插入数据： 1234567//创建中间表并插入数据create table tmp_teacher(id INT, name string, tno string,age INT);load data inpath '/data/input/' into table tmp_teacher;//将临时表的数据插入到桶表中insert into table teacher select * from tmp_teacher;//修改桶表中bucket的数量 alter table teacher clustered by(name) sorted by(age) into 10 buckets; 4.3 hive基本操作创建库：1create database userdb location '/local/path/' comment 'is coment message'; 显示数据库的路径：1describe database userdb; 删除数据库：1drop database if exists userdb; 默认情况下，hive是不允许删除含有表的数据库，首先删除表，之后在命令行使用‘CASCADE’关键词，同样可以使用‘RESTRICT’： 1drop database if exists userdb cascade; 建表：123create table t_order (order_sn string, user_id string,amount int,create_time timestamp)row format delimited fields terminated by '\t'location '/external/hive/t_order'; 建表指定导入数据的存储格式为每一列中间使用空格分开。导入数据:1load data local inpath '/root/order.txt' into table t_order; order.txt的内容如下： 3016080910 30086 10 2016-08-19 11:50:50 3016080911 30086 11 2016-08-19 11:51:22 3016080912 30000 9 3016080913 30000 2016-08-19 11:52:12 3016080914 30010 5rmb 2016-08-19 11:53:59 我们看到数据中第三第四列是有数据缺失的，第五列有数据格式错误，但是我们执行数据插入之后查询发现： hive&gt; select * from t_order; 3016080910 30086 10 2016-08-19 11:50:50 NULL NULL NULL 3016080911 30086 11 2016-08-19 11:51:22 NULL NULL NULL 3016080912 30000 9 NULL NULL NULL 3016080913 30000 2016-08-19 11:52:12 NULL NULL NULL 3016080914 30010 NULL 2016-08-19 11:53:59 NULL NULL NULL Time taken: 2.144 seconds, Fetched: 5 row(s) 数据缺失和格式错误的列会自动改为为NULL值。如果数据文件原本就在hdfs上，当我们加载hdfs上的数据到创建的（内部）表的时候，直接将文件移动到该hdfs文件夹下。 1load data inpath '/order.txt' into table t_order; 加载后，文件被移动到了对应表的hdfs文件夹下,同样可以直接查询到新增加的数据。external类型的表,表对应的是文件夹，对于文件的位置不做任何限制，放到hdfs任何位置都可以。 创建临时表： 创建表时通过SQL语句得到表结构和数据,用于创建一些临时表存储中间结果,这样的表在hdfs中有相应的目录结构和文件。 123create table t_order_tmpasselect order_sn,user_id from t_order; 这样会将从t_order中查询出来的两列作为t_order_tmp表的列并创建t_order_tmp表。 复制表结构（只能复制表结构，无法复制表的内容） 1create table t_order_like like t_order; insert into 是追加数据,overwrite是覆盖写所有表。 1insert overwrite table t_order_like select * from t_order; 创建分区表 PARTITION(分区)添加一个新字段作为分区字段，在hdfs中表现为在t_order_part文件夹下创建以分区命名的文件夹，只能在创建表的时候就指定好（partitioned关键字必须在row format 之前） 123create table t_order_part (order_sn string, user_id string,amount int,create_time timestamp)partitioned by (month string)row format delimited fields terminated by '\t'; 数据集如下： 2016080910 10086 10 2016-08-19 11:50:50 20160820 2016080911 10086 11 2016-08-19 11:51:22 20160820 2016080912 10000 9 2016-08-19 11:51:42 20160820 2016080913 10000 20 2016-08-19 11:52:12 20160820 2016080914 10010 100 2016-08-19 11:53:59 20160820 2016080910 10086 10 2016-08-19 11:50:50 20160821 2016080911 10086 11 2016-08-19 11:51:22 20160821 2016080912 10000 9 2016-08-19 11:51:42 20160821 2016080913 10000 20 2016-08-19 11:52:12 20160821 2016080914 10010 100 2016-08-19 11:53:59 20160821 加载数据集： 1load data local inpath '/usr/local/order.txt' into table t_order_part partition (month='20160820'); 因为建表的时候没有指定动态分区，静态分区需要在加载数据集的时候手动指定数据插入那个分区。 hive函数 操作符： 关系操作符，如=、!=、&gt;、&lt;、is null、is not null、like、rlike 数学操作符，如+、-、*、/、%、&amp;、|、^、~ 逻辑操作符，如and、or、not、&amp;&amp;、|、! 复杂类型操作符，如array[iter]、map[key]、struct.sub_item 函数： 数学函数，如rand()、ln()、sqrt()、abs()、sin() 字符串函数，如concat_ws()、length()、lower()、ltrim()、reverse() 日期函数，如year()、unix_timestamp() 聚合函数，如count([distinct])、sum()、avg()、max() 条件函数，if(condition, value_true, value_false)、case when a then b when c then d else e end、case a when b then c when d then e else f end 类型转换函数，如binary()、cast() 复杂类型函数，如size()、sort_array() 相关命令行： SHOW FUNCTIONS – 列出目前hive中所有函数 DESCRIBE FUNCTION function_name – 显示函数简单描述 DESCRIBE FUNCTION EXTENDED function_name – 获取函数详细描述]]></content>
      <categories>
        <category>大数据学习</category>
        <category>hive</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（二十六）----ThreadLocal的使用]]></title>
    <url>%2Fposts%2Ff58afb00.html</url>
    <content type="text"><![CDATA[其实ThreadLocal很多接触过多线程的同学都可能会很陌生，他不像current包里面那些耳熟能详的api一样在我们面前经常出现，更多的他作为一个本地类出现在系统设计里面。我们可以说一下Spring，Spring的事务管理器通过AOP切入业务代码，在进入业务代码前，会根据对应的事务管理器提取出相应的事务对象，假如事务管理器是DataSourceTransactionManager，就会从DataSource中获取一个连接对象，通过一定的包装后将其保存在ThreadLocal中。并且Spring也将DataSource进行了包装，重写了其中的getConnection()方法，或者说该方法的返回将由Spring来控制，这样Spring就能让线程内多次获取到的Connection对象是同一个。 为什么要放在ThreadLocal里面呢？因为Spring在AOP后并不能向应用程序传递参数，应用程序的每个业务代码是事先定义好的，Spring并不会要求在业务代码的入口参数中必须编写Connection的入口参数。此时Spring选择了ThreadLocal，通过它保证连接对象始终在线程内部，任何时候都能拿到，此时Spring非常清楚什么时候回收这个连接，也就是非常清楚什么时候从ThreadLocal中删除这个元素 从名字上看我们很容易误解，ThreadLocal，本地线程。local有当地的，本地的，局部的意思，这里说的是局部线程，意思是线程的局部变量。我们知道synchronized是独占锁，同一时间只能有一个线程操作被锁住的代码大家排队等待，典型的以时间换空间的策略。那如果我们空间很足时间不够该怎么办呢，ThreadLocal就该派上用场了。ThreadLocal作为线程的局部变量，会为这个线程创建独立的变量副本，在线程的内部，他所创建的对象相当于全局对象。 说到这里，大家是不是还是没有分清楚ThreadLocal和synchronized有什么区别，下面我们来讲。 ThreadLocal 不是用来解决共享对象的多线程访问问题的，上面说了ThreadLocal是线程的局部变量。一般情况下，通过ThreadLocal.set() 到线程中的对象是该线程自己使用的对象，其他线程是不需要访问的，也访问不到的。各个线程中访问的是不同的对象。 ThreadLocal使得各线程能够保持各自独立的一个对象，并不是通过ThreadLocal.set()来实现的，而是通过每个线程中的new 对象 的操作来创建的对象，每个线程创建一个，不是什么对象的拷贝或副本。通过ThreadLocal.set()将这个新创建的对象的引用保存到各线程的自己的一个map中，每个线程都有这样一个map，执行ThreadLocal.get()时，各线程从自己的map中取出放进去的对象，因此取出来的是各自自己线程中的对象，ThreadLocal实例是作为map的key来使用的。 如果ThreadLocal.set()进去的东西本来就是多个线程共享的同一个对象，那么多个线程的ThreadLocal.get()取得的还是这个共享对象本身，还是有并发访问问题。 我们来看一个例子： 1234567891011121314private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s; &#125; 在getSession()方法中，首先判断当前线程中有没有放进去session，如果还没有，那么通过sessionFactory().openSession()来创建一个session，再将session set到线程中，实际是放到当前线程的ThreadLocalMap这个map中，这时，对于这个session的唯一引用就是当前线程中的那个ThreadLocalMap，而threadSession作为这个值的key，要取得这个session可以通过threadSession.get()来得到，里面执行的操作实际是先取得当前线程中的ThreadLocalMap，然后将threadSession作为key将对应的值取出。上面我们也讲过每个线程进来创建threadSession 的时候，这个threadSession 只属于他一个人所有，别的线程无法共享到他自己创建的ThreadLocal。这就避免了所有线程共享同一个对象的问题。并且该session创建完成之后，我们不必走到哪里都携带着session这个参数，走到哪里传递到哪里。需要使用的时候只需要从threadlocal中取出即可。这也是极其省事的。 我们可以举一个 例子来说明ThreadLocal不是用来解决对象共享访问问题的，而是为了处理在多线程环境中，某个方法处理一个业务，需要递归依赖其他方法时，而要在这些方法中共享参数的问题。例如有方法a()，在该方法中调用了方法b()，而在b方法中又调用了方法c()，即a–&gt;b—&gt;c，如果a，b，c都需要使用用户对象，那么我们常用做法就是a(User user)–&gt;b(User user)—c(User user)。但是如果使用ThreadLocal我们就可以用另外一种方式解决： 在某个接口中定义一个静态的ThreadLocal 对象，例如 public static ThreadLocal threadLocal=new ThreadLocal (); 然后让a，b，c方法所在的类假设是类A，类B，类C都实现1中的接口 在调用a时，使用A.threadLocal.set(user) 把user对象放入ThreadLocal环境 这样我们在方法a，方法b，方法c可以在不用传参数的前提下，在方法体中使用threadLocal.get()方法就可以得到user对象。 上面我们说到ThreadLocal的使用，也说了ThreadLocal里面有一个ThreadLocalMap 用于存储当前线程的对象，下面我们简单的看一下源码来理解一下这个过程。先上类图： ThreadLocal里面有一个内部类ThreadLocalMap，在ThreadLocal内部又装了一个Entry，他继承了WeakReference，我们来看一下Entry： 123456789static class Entry extends WeakReference&lt;ThreadLocal&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal k, Object v) &#123; super(k); value = v; &#125;&#125; Entry对象其实还是ThreadLocal类型的，这里我们看到ThreadLocal用了一个WeakReference包装是为了保证该ThreadLocal对象在没有被引用的时候能够及时的被gc掉。 下面再看一下ThreadLocal的get和set方法： 12345678910111213141516171819202122232425public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;private void set(ThreadLocal key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); ... ... ...&#125; 在set方法中t.threadLocals只要不为空，便创建map对象，我们看到set方法中的key是ThreadLocal，即thread调用ThreadLocal.get()方法既可得到当前thread的threadLocal对象里面的ThreadLocalMap的值！是不是有点绕，是不是不知道为什么当前线程能调用ThreadLocal，我们看一下上面的getMap()方法，返回值是：t.threadLocals，这个t即当前线程，在Thread类里面有一个threadLocals对象，我们可以跟过去看一下，在这里限于篇幅，就只上相关的源码： 123456789public class Thread implements Runnable &#123; ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; Thread parent = currentThread(); if (parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);&#125; 下面方法是ThreadLocal中的： 123static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) &#123; return new ThreadLocalMap(parentMap);&#125; 我们在源码中看到threadLocals并未进行赋值，他一直都是一个空对象，为什么这么做呢，我们接着看下面的get方法： 123456789101112131415161718192021public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) return (T)e.value; &#125; return setInitialValue();&#125;private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 在get方法中，如果一个线程当前并未使用ThreadLocal对象那么getMap(t)必然是空，那我们就得想了，难道在Thread类中创建一个空对象threadLocals就这么空着？哈哈，当然不是啦，我也着急了。所以就进入了下面的setInitialValue()方法啦，这里的getMap(t)当然还是空的，那进入createMap(t, value)呗： 123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 终于在这里拨开云雾见月明！妈妈再也不用担心threadLocals没有人要了！上面分析的比较乱，大家就将就看，用一句话总结那就是： 在Thread类中有一个对象是threadLocals，如果在该线程运行中有ThreadLocal创建threadLocals会去找到他的！获得你在ThreadLocal中存储的值！ 上面我们已经详细分析了ThreadLocal的使用和实现，那么在真实的环境中使用它有什么弊端没呢。其实使用中还真的是有很多问题的。 我们知道ThreadLocal是和当前线程绑定的，即他的生命周期是和当前线程共存，当线程结束，ThreadLocal内部的Entity对象才会被gc回收。 下面我说一个场景大家看会带来什么样的后果：如果现在是线程池对象使用了ThreadLocal来保存变量会发生什么？大家知道线程池的主要目的是为了线程复用，那么线程池中的线程基本不会结束，与jvm的生命周期是一致的。那这个时候谁知道一个携带了ThreadLocal的线程会什么时候结束呢。长久以往必然造成内存泄露。 另外我们再说一个关于忘记释放的问题。如果你在线程刚开始进来的时候就载入了ThreadLocal用来保存变量，假设你的程序设计的不是很健壮，你忘记了写remove()。这个时候事情就来了。再假设你在ThreadLocal中存放了map对象，真实的业务中Map对象也许包含了很多数据，随着时间流逝，内存中的无用对象越来越多，内存泄露是必然的。 关于ThreadLocal的内容我们就讲到这里，其实里面还有很多值得我们深究的东西，慢慢一点点的去看吧！]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（二十四）----(JUC集合)ArrayBlockingQueue和LinkedBlockingQueue介绍]]></title>
    <url>%2Fposts%2Fed05b021.html</url>
    <content type="text"><![CDATA[这一节我们来了解阻塞队列（BlockingQueue），BlockingQueue接口定义了一种阻塞的FIFO queue，每一个BlockingQueue都有一个容量，当容量满时往BlockingQueue中添加数据时会造成阻塞，当容量为空时取元素操作会阻塞。首先我们来看ArrayBlockingQueue和LinkedBlockingQueue. 1 ArrayBlockingQueueArrayBlockingQueue是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证访问者公平的访问队列，所谓公平访问队列是指阻塞的所有生产者线程或消费者线程，当队列可用时，可以按照阻塞的先后顺序访问队列，即先阻塞的生产者线程，可以先往队列里插入元素，先阻塞的消费者线程，可以先从队列里获取元素。通常情况下为了保证公平性会降低吞吐量。 我们看他的构造函数实现： 1234//默认是非公平的，初始指定队列容量public ArrayBlockingQueue(int capacity) &#123; this(capacity, false);&#125; //该构造方法可以设置队列的公平性。当然如果为公平的，则对性能会产生影响//访问者的公平性是使用可重入锁实现的 12345678public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();&#125; 使用很简单我们直接看一个实例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class ProducerConsumerTest &#123; public static void main(String[] args) &#123; final BlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(3); ExecutorService service = Executors.newFixedThreadPool(10); for(int i = 0;i&lt;4;i++)&#123; service.execute(new ProducerAndConsumer(blockingQueue)); &#125; &#125;&#125;class ProducerAndConsumer implements Runnable&#123; private boolean flag = false; private Integer j = 1; private Lock lock = new ReentrantLock(); Condition pro_con = lock.newCondition(); Condition con_con = lock.newCondition(); private BlockingQueue&lt;Integer&gt; blockingQueue; public ProducerAndConsumer(BlockingQueue&lt;Integer&gt; blockingQueue)&#123; this.blockingQueue= blockingQueue; &#125; //生产 public void put()&#123; try &#123; lock.lock(); while(flag) pro_con.await(); System.out.println("正在准备放入数据。。。"); Thread.sleep(new Random().nextInt(10)*100); Integer value = new Random().nextInt(30); blockingQueue.put(value); System.out.println(Thread.currentThread().getName()+" 放入的数据 "+value); flag = true; con_con.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally&#123; lock.unlock(); &#125; &#125; public void get()&#123; try &#123; lock.lock(); while(!flag) con_con.await(); System.out.println("正在准备取数据。。。"); Thread.sleep(new Random().nextInt(10)*1000); System.out.println(Thread.currentThread().getName()+" 取到的数据为"+blockingQueue.take()); flag = false; pro_con.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally&#123; lock.unlock(); &#125; &#125; @Override public void run() &#123; while(true)&#123; if(j==1)&#123; put(); &#125; else&#123; get(); &#125; j=(j+1)%2; &#125; &#125;&#125; 输出为： 正在准备放入数据。。。 正在准备放入数据。。。 正在准备放入数据。。。 正在准备放入数据。。。 pool-1-thread-2 放入的数据 13 正在准备取数据。。。 pool-1-thread-3 放入的数据 4 正在准备取数据。。。 pool-1-thread-3 取到的数据为13 正在准备放入数据。。。 pool-1-thread-1 放入的数据 11 正在准备取数据。。。 pool-1-thread-4 放入的数据 26 正在准备取数据。。。 pool-1-thread-1 取到的数据为4 正在准备放入数据。。。 pool-1-thread-2 取到的数据为11 正在准备放入数据。。。 pool-1-thread-3 放入的数据 18 正在准备取数据。。。 ... ... 2 LinkedBlockingQueueLinkedBlockingQueue是一个用链表实现的有界阻塞队列。此队列的默认和最大长度为Integer.MAX_VALUE。此队列按照先进先出的原则对元素进行排序。先看一下他的构造函数： 123456789public LinkedBlockingQueue() &#123; this(Integer.MAX_VALUE); //MAX_VALUE=2147483647&#125;public LinkedBlockingQueue(int capacity) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; last = head = new Node&lt;E&gt;(null);&#125; 我们还是直接开看一个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class BlockingQueueTest &#123; /** * 定义装苹果的篮子 */ public static class Basket &#123; // 篮子，能够容纳3个苹果 // BlockingQueue&lt;String&gt; basket = new ArrayBlockingQueue&lt;String&gt;(3); BlockingQueue&lt;String&gt; basket = new LinkedBlockingQueue&lt;String&gt;(3); // 生产苹果，放入篮子 public void produce() throws InterruptedException &#123; // put方法放入一个苹果，若basket满了，等到basket有位置 basket.put("An apple"); &#125; // 消费苹果，从篮子中取走 public String consume() throws InterruptedException &#123; // get方法取出一个苹果，若basket为空，等到basket有苹果为止 return basket.take(); &#125; &#125; // 测试方法 public static void testBasket() &#123; // 建立一个装苹果的篮子 final Basket basket = new Basket(); // 定义苹果生产者 class Producer implements Runnable &#123; public String instance = ""; public Producer(String a) &#123; instance = a; &#125; public void run() &#123; try &#123; while (true) &#123; // 生产苹果 System.out.println("生产者准备生产苹果：" + instance); basket.produce(); System.out.println("! 生产者生产苹果完毕：" + instance); // 休眠300ms Thread.sleep(300); &#125; &#125; catch (InterruptedException ex) &#123; &#125; &#125; &#125; // 定义苹果消费者 class Consumer implements Runnable &#123; public String instance = ""; public Consumer(String a) &#123; instance = a; &#125; public void run() &#123; try &#123; while (true) &#123; // 消费苹果 System.out.println("消费者准备消费苹果：" + instance); basket.consume(); System.out.println("! 消费者消费苹果完毕：" + instance); // 休眠1000ms Thread.sleep(1000); &#125; &#125; catch (InterruptedException ex) &#123; &#125; &#125; &#125; ExecutorService service = Executors.newCachedThreadPool(); Producer producer = new Producer("P1"); Producer producer2 = new Producer("P2"); Consumer consumer = new Consumer("C1"); service.submit(producer); service.submit(producer2); service.submit(consumer); // 程序运行3s后，所有任务停止 try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; &#125; service.shutdownNow(); &#125; public static void main(String[] args) &#123; BlockingQueueTest.testBasket(); &#125;&#125; 输出为： 生产者准备生产苹果：P1 消费者准备消费苹果：C1 ! 生产者生产苹果完毕：P1 生产者准备生产苹果：P2 ! 消费者消费苹果完毕：C1 ! 生产者生产苹果完毕：P2 生产者准备生产苹果：P2 ! 生产者生产苹果完毕：P2 生产者准备生产苹果：P1 ! 生产者生产苹果完毕：P1 生产者准备生产苹果：P2 生产者准备生产苹果：P1 消费者准备消费苹果：C1 ! 消费者消费苹果完毕：C1 ! 生产者生产苹果完毕：P2 生产者准备生产苹果：P2 消费者准备消费苹果：C1 ! 消费者消费苹果完毕：C1 ! 生产者生产苹果完毕：P1 生产者准备生产苹果：P1 消费者准备消费苹果：C1 ! 消费者消费苹果完毕：C1 ! 生产者生产苹果完毕：P2 Process finished with exit code 0]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（二十三）----(JUC集合)ConcurrentSkipListMap介绍]]></title>
    <url>%2Fposts%2F31315379.html</url>
    <content type="text"><![CDATA[Queue除了前面介绍的实现外，还有一种双向的Queue实现Deque。这种队列允许在队列头和尾部进行入队出队操作，因此在功能上比Queue显然要更复杂。 1 LinkedBlockingDeque我们来看一下该类中的成员变量： 1234567891011121314151617181920212223public class LinkedBlockingDeque&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingDeque&lt;E&gt;, java.io.Serializable &#123; private static final long serialVersionUID = -387911632671998426L; static final class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; prev; Node&lt;E&gt; next; Node(E x) &#123; item = x; &#125; &#125; transient Node&lt;E&gt; first; transient Node&lt;E&gt; last; private transient int count; private final int capacity; final ReentrantLock lock = new ReentrantLock(); private final Condition notEmpty = lock.newCondition(); private final Condition notFull = lock.newCondition(); &#125; 有一个内部类Node，该类用来标记queue的节点，capacity最大为Integer.MAX_VALUE。然后使用了独占锁和条件机制来保证线程安全和进行阻塞控制。从上面的结构上我们可以看出： 要想支持阻塞功能，队列的容量一定是固定的，否则无法在入队的时候挂起线程。也就是capacity是final类型的。 既然是双向链表，每一个结点就需要前后两个引用，这样才能将所有元素串联起来，支持双向遍历。也即需要prev/next两个引用。 双向链表需要头尾同时操作，所以需要first/last两个节点，当然可以参考LinkedList那样采用一个节点的双向来完成，那样实现起来就稍微麻烦点。 既然要支持阻塞功能，就需要锁和条件变量来挂起线程。这里使用一个锁两个条件变量来完成此功能。 上面对LinkedBlockingDeque的结构做了说明，那么原理就很清晰了，无非是用一个独占锁来保持线程安全，然后用Condition来做阻塞操作。双向链表的操作大家都很熟悉就不做过多解释。 2 ConcurrentLinkedDequeConcurrentLinkedDeque是JSR166y中新增的一个无界并发Deque实现，基于已链接节点的、任选范围的双端队列。在迭代时，队列保持弱一致性，但不会抛出ConcurrentModificationException异常。 我们看一下类的成员变量： 12345678910111213141516171819public class ConcurrentLinkedDeque&lt;E&gt; extends AbstractCollection&lt;E&gt; implements Deque&lt;E&gt;, java.io.Serializable &#123; private transient volatile Node&lt;E&gt; head; private transient volatile Node&lt;E&gt; tail; private static final Node&lt;Object&gt; PREV_TERMINATOR, NEXT_TERMINATOR; @SuppressWarnings("unchecked") Node&lt;E&gt; prevTerminator() &#123; return (Node&lt;E&gt;) PREV_TERMINATOR; &#125; @SuppressWarnings("unchecked") Node&lt;E&gt; nextTerminator() &#123; return (Node&lt;E&gt;) NEXT_TERMINATOR; &#125;&#125; 我们看到成员变量里面有头节点和尾节点，然后是节点的引用PREV_TERMINATOR, NEXT_TERMINATOR，双向链表的结构都是一样的。ConcurrentLinkedDeque不是阻塞队列所以没有用到条件原语。我们在成员变量里面没有看到使用ReentrantLock,因为所有的操作都是使用原子操作，避免了使用独占锁造成性能问题。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（二十三）----(JUC集合)ConcurrentSkipListMap介绍]]></title>
    <url>%2Fposts%2F31315379.html</url>
    <content type="text"><![CDATA[ConcurrentSkipListMap提供了一种线程安全的并发访问的排序映射表。内部是SkipList（跳表）结构实现，在理论上能够在O(log(n))时间内完成查找、插入、删除操作。 1 理解SkipList要想弄明白ConcurrentSkipListMap,我们的先明白他的数据结构实现，先来看SkipList。 Skip List是一种随机化的数据结构，基于并联的链表，其效率可比拟于二叉查找树（对于大多数操作需要O(log n)平均时间）。基本上，跳跃列表是对有序的链表增加上附加的前进链接，增加是以随机化的方式进行的，所以在列表中的查找可以快速的跳过部分列表(因此得名)。所有操作都以对数随机化的时间进行。SkipList可以很好解决有序链表查找特定值的困难。 Skip List定义： 一个跳表，应该具有以下特征： 一个跳表应该有几个层（level）组成； 跳表的第一层包含所有的元素； 每一层都是一个有序的链表； 如果元素x出现在第i层，则所有比i小的层都包含x； 第i层的元素通过一个down指针指向下一层拥有相同值的元素； 在每一层中，-1和1两个元素都出现(分别表示INT_MIN和INT_MAX)； Top指针指向最高层的第一个元素。 构建有序链表： 一个跳表如下： Skip List构造步骤： 给定一个有序的链表。 选择链表中最大和最小的元素，然后从其他元素中按照一定算法（随机）随即选出一些元素，将这些元素组成有序链表。这个新的链表称为一层，原链表称为其下一层。 为刚选出的每个元素添加一个指针域，这个指针指向下一层中值同自己相等的元素。Top指针指向该层首元素 重复2、3步，直到不再能选择出除最大最小元素以外的元素。 从上图可以看到，跳表具有以下几种特性： 由很多层组成，level越高的层节点越少，最后一层level用有所有的节点数据 每一层的节点数据也都是有顺序的 上面层的节点肯定会在下面层中出现 每个节点都有两个指针，分别是同一层的下一个节点指针和下一层节点的指针 使用跳表查询元素的时间复杂度是O(log n)，跟红黑树一样。查询效率还是不错的，但是跳表的存储容量变大了，本来一共只有10个节点的数据，使用跳表之后变成了21个节点。 所以跳表是一种使用”空间换时间”的概念用来提高查询效率的链表，开源软件Redis、LevelDB都使用到了跳表。跳表相比B树，红黑树，AVL树时间复杂度一样，但是耗费更多存储空间，但是跳表的优势就是它相比树，实现简单，不需要考虑树的一些rebalance问题。 2 ConcurrentSkipListMap探索ConcurrentSkipListMap包含了很多内部类，内部类的框架图如下： ConcurrentSkipListMap在原始链表的基础上增加了跳表的结构，所以需要两个额外的内部类来封装链表的节点，以及跳表的节点——Node和Index。 同ConcurrentHashMap的Node节点一样，key为final，是不可变的，value和next通过volatile修饰保证内存可见性。 Index：跳表的节点： 12345static class Index&lt;K,V&gt; &#123; final Node&lt;K,V&gt; node; final Index&lt;K,V&gt; down; volatile Index&lt;K,V&gt; right;&#125; Node：链表的节点： 12345static final class Node&lt;K,V&gt; &#123; final K key; volatile Object value; volatile Node&lt;K,V&gt; next;&#125; Index封装了跳表需要的结构，首先node包装了链表的节点，down指向下一层的节点（不是Node，而是Index），right指向同层右边的节点。node和down都是final的，说明跳表的节点一旦创建，其中的值以及所处的层就不会发生变化（因为down不会变化，所以其下层的down都不会变化，那他的层显然不会变化）。Node和Index内部都提供了用于CAS原子更新的AtomicReferenceFieldUpdater对象，该对象前面讲Atomic原子类的时候已经讲过,原理和机制将不再介绍。 下面我们还是着重介绍ConcurrentSkipListMap的get、put和remove方法。在介绍这三个方法之前我们先看一下这三个方法都会用到的一个辅助方法： 123456789101112131415161718192021222324private Comparable&lt;? super K&gt; comparable(Object key) throws ClassCastException &#123; if (key == null) throw new NullPointerException(); //有两种封装方法，如果在构造时指定了comparator，则使用comparator封装key // 如果没有指定comparator，则key必须是一个继承自Comparable接口的类，否则会抛出ClassCastException // 所以ConcurrentSkipListMap的key要么是继承自Comparable接口的类，如果不是的话需要显示提供comparator进行比较 if (comparator != null) return new ComparableUsingComparator&lt;K&gt;((K)key, comparator); else return (Comparable&lt;? super K&gt;)key; &#125;static final class ComparableUsingComparator&lt;K&gt; implements Comparable&lt;K&gt; &#123; final K actualKey; final Comparator&lt;? super K&gt; cmp; ComparableUsingComparator(K key, Comparator&lt;? super K&gt; cmp) &#123; this.actualKey = key; this.cmp = cmp; &#125; public int compareTo(K k2) &#123; return cmp.compare(actualKey, k2); &#125;&#125; ConcurrentSkipListMap的key必须是能够比较的，这样来确保线程安全。 我们再来看一下get方法： 1234567891011121314151617181920public V get(Object key) &#123; return doGet(key);&#125;private V doGet(Object okey) &#123; Comparable&lt;? super K&gt; key = comparable(okey); /* * Loop needed here and elsewhere in case value field goes * null just as it is about to be returned, in which case we * lost a race with a deletion, so must retry. */ for (;;) &#123; Node&lt;K,V&gt; n = findNode(key); if (n == null) return null; Object v = n.value; if (v != null) return (V)v; &#125;&#125; 可见在get方法中调用了doGet()来进行取值操作，首先调用了comparable（key）方法来确保该次取值的安全性，后面再一个死循环中持续进行 findNode(key)操作。 再看一下put方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public V put(K key, V value) &#123; if (value == null) throw new NullPointerException(); return doPut(key, value, false);&#125;private V doPut(K kkey, V value, boolean onlyIfAbsent) &#123; Comparable&lt;? super K&gt; key = comparable(kkey); for (;;) &#123; // 从跳表中查找最接近指定key的节点：该节点的key小于等于指定key，且处于最底层 Node&lt;K,V&gt; b = findPredecessor(key); Node&lt;K,V&gt; n = b.next; //新节点插入在b与n之间 for (;;) &#123; //n==null则说明b是链表的最后一个节点，则新节点直接插入到链表尾部即可 if (n != null) &#123; Node&lt;K,V&gt; f = n.next; if (n != b.next) // 此处增加判断，避免链表结构已被修改(针对节点b) break; Object v = n.value; if (v == null) &#123; // n节点已经被删除 n.helpDelete(b, f);b和f分别为n的前驱和后继节点 break; &#125; // 这里如果v==n说明n是一个删除标记，用来标记其前继节点已被删除，即b已被删除 if (v == n || b.value == null) // b is deleted break; int c = key.compareTo(n.key); // 如果指定key&gt;n的key，则判断下一个节点，直到n==null，或者指定key&lt;n的key if (c &gt; 0) &#123; b = n; n = f; continue; &#125; // 相等，则更新value即可，更新失败，就再来一次，一直到成功为止 if (c == 0) &#123; if (onlyIfAbsent || n.casValue(v, value)) return (V)v; else break; // restart if lost race to replace value &#125; // else c &lt; 0; fall through &#125; // 创建一个节点，next指向n Node&lt;K,V&gt; z = new Node&lt;K,V&gt;(kkey, value, n); // 将b的next指向新创建的节点，则新的链表为：b--&gt;new--&gt;n，即将新节点插入到b和n之间 if (!b.casNext(n, z)) break; // restart if lost race to append to b // 随机计算一个层级 int level = randomLevel(); if (level &gt; 0) // 将z插入到该层级 insertIndex(z, level); return null; &#125; &#125;&#125; 代码中已经附上了大量的注释，这里再简单的梳理下流程。首先put()方法是调用内部的doPut()方法。Comparable&lt; ? super K&amp;&gt; key = comparable(kkey);这一句将key封装成一个Comparable对象，上面已经介绍了comparable这个方法。接着进入到死循环，循环第一步是调用findPredecessor(key)方法，该方法返回一个key最接近指定key的节点(最接近指的是小于等于)，该节点是处于最底层的，下面介绍下这个方法的逻辑。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/**在跳表中查找节点的key小于指定key，且处于最底层的节点，即找到指定key的前继节点*基本逻辑是从head(跳表的最高层链表的头结点)开始自右开始查找，当找到该层链表的最*接近且小于指定key的节点时，往下开始查找，*最终找到最底层的那个节点*/private Node&lt;K,V&gt; findPredecessor(Comparable&lt;? super K&gt; key) &#123; if (key == null) throw new NullPointerException(); // don't postpone errors for (;;) &#123; // head是跳表的最高层链表的头结点 Index&lt;K,V&gt; q = head; Index&lt;K,V&gt; r = q.right;// head的右边节点 for (;;) &#123; // r==null说明该层链表已经查找到头，且未找到符合条件的节点，需开始往下查找 if (r != null) &#123; Node&lt;K,V&gt; n = r.node;// r的数据节点 K k = n.key; if (n.value == null) &#123;// n的value为null，说明该节点已被删除 // 将该节点从链表移除，通过将其(n)前置节点的right指向其(n)的后置节点 if (!q.unlink(r)) break; // restart r = q.right; // reread r 移除value==null的n节点之后，继续从n的下一个节点查找 continue; &#125; // 比较当前查找的节点的key与指定key，如果小于指定key，则继续查找， // 大于等于key则q即为该层链表最接近指定key的 if (key.compareTo(k) &gt; 0) &#123; q = r; r = r.right; continue; &#125; &#125; // 到这里有两种情况： //1)该层链表已经查找完，仍未找到符号条件的节点 //2)找到一个符合条件的节点 // 开始往下一层链表进行查找 Index&lt;K,V&gt; d = q.down; if (d != null) &#123; // 从下层对应位置继续查找 q = d; r = d.right; &#125; else // 如果无下层链表则直接返回当前节点的node return q.node; &#125; &#125;&#125; 该方法的查找逻辑是：从head(跳表的最高层链表的头结点)开始自右开始查找，当找到该层链表的最接近且小于指定key的节点时，往下开始查找，最终找到最底层的那个节点。具体的代码可以看注释，应该说的挺明白的了，针对Put方法，这个方法返回的节点就是将要插入的节点的前继节点，即新节点将插到该节点后面。下面是查找的示意图: 所有的修改操作都是使用CAS，只要失败就会重试，直至成功，所以就算多线程并发操作也不会出现错误，而且通过CAS避免了使用锁，性能比用锁好很多。 接下来在看一下remove： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public V remove(Object key) &#123; return doRemove(key, null);&#125;final V doRemove(Object okey, Object value) &#123; Comparable&lt;? super K&gt; key = comparable(okey); for (;;) &#123; // 从跳表中查找最接近指定key的节点：该节点的key小于等于指定key，且处于最底层 Node&lt;K,V&gt; b = findPredecessor(key); Node&lt;K,V&gt; n = b.next; for (;;) &#123; if (n == null) return null; //获取n节点的下一个节点 Node&lt;K,V&gt; f = n.next; if (n != b.next) // inconsistent read break; Object v = n.value; if (v == null) &#123; // n is deleted n.helpDelete(b, f); break; &#125; if (v == n || b.value == null) // b is deleted break; int c = key.compareTo(n.key); if (c &lt; 0) return null; if (c &gt; 0) &#123;//将该节点移除 b = n; n = f; continue; &#125; if (value != null &amp;&amp; !value.equals(v)) return null; if (!n.casValue(v, null)) break; if (!n.appendMarker(f) || !b.casNext(n, f)) findNode(key); // Retry via findNode else &#123; findPredecessor(key); // Clean index if (head.right == null) tryReduceLevel(); &#125; return (V)v; &#125; &#125;&#125; 说明：doRemove函数的处理流程如下。 ① 根据key值找到前驱结点，查找的过程会删除一个标记为删除的结点。 ② 从前驱结点往后查找该结点。 ③ 在该结点后面添加一个marker结点，若添加成功，则将该结点的前驱的后继设置为该结点之前的后继。 ④ 头结点的next域是否为空，若为空，则减少层级。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（二十三）----(JUC集合)ConcurrentSkipListMap介绍]]></title>
    <url>%2Fposts%2F31315379.html</url>
    <content type="text"><![CDATA[这一节我们来看一下并发的Map，ConcurrentHashMap和ConcurrentSkipListMap。ConcurrentHashMap通常只被看做并发效率更高的Map，用来替换其他线程安全的Map容器，比如Hashtable和Collections.synchronizedMap。ConcurrentSkipListMap提供了一种线程安全的并发访问的排序映射表。内部是SkipList（跳表）结构实现，在理论上能够在O(log(n))时间内完成查找、插入、删除操作。 1 ConcurrentHashMap简介ConcurrentHashMap是一个线程安全的HashTable，它的主要功能是提供了一组和HashTable功能相同但是线程安全的方法。ConcurrentHashMap可以做到读取数据不加锁，并且其内部的结构可以让其在进行写操作的时候能够将锁的粒度保持地尽量地小，不用对整个ConcurrentHashMap加锁。 为了更好的理解 ConcurrentHashMap 高并发的具体实现，让我们先探索它的结构模型。 ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment。HashEntry 用来封装映射表的键 / 值对；Segment 用来充当锁的角色，每个 Segment 对象守护整个散列映射表的若干个桶。每个桶是由若干个 HashEntry 对象链接起来的链表。一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。 1.1 HashEntry类：HashEntry 用来封装散列映射表中的键值对。在 HashEntry 类中，key，hash 和 next 域都被声明为 final 型，value 域被声明为 volatile 型 ： 1234567891011121314151617181920212223242526272829static final class HashEntry&lt;K, V&gt; &#123; final int hash; final K key; volatile V value; volatile ConcurrentHashMap.HashEntry&lt;K, V&gt; next; static final Unsafe UNSAFE; static final long nextOffset; HashEntry(int var1, K var2, V var3, ConcurrentHashMap.HashEntry&lt;K, V&gt; var4) &#123; this.hash = var1; this.key = var2; this.value = var3; this.next = var4; &#125; final void setNext(ConcurrentHashMap.HashEntry&lt;K, V&gt; var1) &#123; UNSAFE.putOrderedObject(this, nextOffset, var1); &#125; static &#123; try &#123; UNSAFE = Unsafe.getUnsafe(); Class var0 = ConcurrentHashMap.HashEntry.class; nextOffset = UNSAFE.objectFieldOffset(var0.getDeclaredField("next")); &#125; catch (Exception var1) &#123; throw new Error(var1); &#125; &#125; &#125; 1.2 Segment类：Segment继承了ReentrantLock，表明每个segment都可以当做一个锁。Segment 中包含HashEntry 的数组，其可以守护其包含的若干个桶（HashEntry的数组）。Segment 在某些意义上有点类似于 HashMap了，都是包含了一个数组，而数组中的元素可以是一个链表。 12345678910111213141516171819202122static final class Segment&lt;K, V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1?64:1; /** * table 是由 HashEntry 对象组成的数组 * 如果散列时发生碰撞，碰撞的 HashEntry 对象就以链表的形式链接成一个链表 * table 数组的数组成员代表散列映射表的一个桶 * 每个 table 守护整个 ConcurrentHashMap 包含桶总数的一部分 * 如果并发级别为 16，table 则守护 ConcurrentHashMap 包含的桶总数的 1/16 */ transient volatile ConcurrentHashMap.HashEntry&lt;K, V&gt;[] table; transient int count; //Segment中元素的数量 transient int modCount; //对table的大小造成影响的操作的数量（比如put或者remove操作） transient int threshold; //阈值，Segment里面元素的数量超过这个值依旧就会对Segment进行扩容 final float loadFactor; //负载因子，用于确定threshold Segment(float var1, int var2, ConcurrentHashMap.HashEntry&lt;K, V&gt;[] var3) &#123; this.loadFactor = var1; this.threshold = var2; this.table = var3; &#125; &#125; ConcurrentHashMap 的成员变量中，包含了一个 Segment 的数组（final Segment&lt;K,V&gt;[] segments;），而 Segment 是 ConcurrentHashMap 的内部类，然后在 Segment 这个类中，包含了一个 HashEntry 的数组（transient volatile HashEntry&lt;K,V&gt;[] table;）。而 HashEntry 也是 ConcurrentHashMap 的内部类。HashEntry 中，包含了 key 和 value 以及 next 指针（类似于 HashMap 中 Entry），所以 HashEntry 可以构成一个链表。 所以通俗的讲，ConcurrentHashMap 数据结构为一个 Segment 数组，Segment 的数据结构为 HashEntry 的数组，而 HashEntry 存的是我们的键值对，可以构成链表。 1.3 ConcurrentHashMap结构图 ConcurrentHashMap引入了分割，并提供了HashTable支持的所有的功能。在ConcurrentHashMap中，支持多线程对Map做读操作，并且不需要任何的blocking。这得益于CHM将Map分割成了不同的部分，在执行更新操作时只锁住一部分。根据默认的并发级别(concurrency level)，Map被分割成16个部分，并且由不同的锁控制。这意味着，同时最多可以有16个写线程操作Map。试想一下，由只能一个线程进入变成同时可由16个写线程同时进入(读线程几乎不受限制)，性能的提升是显而易见的。但由于一些更新操作，如put(),remove(),putAll(),clear()只锁住操作的部分，所以在检索操作不能保证返回的是最新的结果。 ConcurrentHashMap默认的并发级别是16，但可以在创建CHM时通过构造函数改变。毫无疑问，并发级别代表着并发执行更新操作的数目，所以如果只有很少的线程会更新Map，那么建议设置一个低的并发级别。另外，ConcurrentHashMap还使用了ReentrantLock来对segments加锁。 经过前面的铺垫我们来正式对ConcurrentHashMap的使用进行剖析，重点关注get、put、remove这三个操作。 首先来看一下get的操作： 123456789101112131415161718public V get(Object var1) &#123; int var4 = this.hash(var1); long var5 = (long)((var4 &gt;&gt;&gt; this.segmentShift &amp; this.segmentMask) &lt;&lt; SSHIFT) + SBASE; ConcurrentHashMap.Segment var2; if((var2 = (ConcurrentHashMap.Segment)UNSAFE.getObjectVolatile(this.segments, var5)) != null) &#123; ConcurrentHashMap.HashEntry[] var3 = var2.table; if(var2.table != null) &#123; for(ConcurrentHashMap.HashEntry var7 = (ConcurrentHashMap.HashEntry)UNSAFE.getObjectVolatile(var3, ((long)(var3.length - 1 &amp; var4) &lt;&lt; TSHIFT) + TBASE); var7 != null; var7 = var7.next) &#123; Object var8 = var7.key; if(var7.key == var1 || var7.hash == var4 &amp;&amp; var1.equals(var8)) &#123; return var7.value; &#125; &#125; &#125; &#125; return null;&#125; 根据key，计算出hashCode； 根据步骤1计算出的hashCode定位segment，如果segment不为null &amp;&amp; segment.table也不为null，跳转到步骤3，否则，返回null，该key所对应的value不存在； 根据hashCode定位table中对应的hashEntry，遍历hashEntry，如果key存在，返回key对应的value； 步骤3结束仍未找到key所对应的value，返回null，该key锁对应的value不存在。 ConcurrentHashMap的get操作高效之处在于整个get操作不需要加锁。如果不加锁，ConcurrentHashMap的get操作是如何做到线程安全的呢？原因是volatile，所有的value都定义成了volatile类型，（上面介绍HashEntry类源码中提到：volatile V value）volatile可以保证线程之间的可见性，这也是用volatile替换锁的经典应用场景。 再来看一下put操作： 1234567891011121314public V put(K var1, V var2) &#123; if(var2 == null) &#123; throw new NullPointerException(); &#125; else &#123; int var4 = this.hash(var1); int var5 = var4 &gt;&gt;&gt; this.segmentShift &amp; this.segmentMask; ConcurrentHashMap.Segment var3; if((var3 = (ConcurrentHashMap.Segment)UNSAFE.getObject(this.segments, (long)(var5 &lt;&lt; SSHIFT) + SBASE)) == null) &#123; var3 = this.ensureSegment(var5); &#125; return var3.put(var1, var4, var2, false); &#125;&#125; 我们看到在第7行定义了一个Segment类型的 var3，然后调用了Segment的put方法存入map，我们不妨来看一下Segment的put方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354final V put(K var1, int var2, V var3, boolean var4) &#123; //1.获取锁，保证put操作的线程安全； ConcurrentHashMap.HashEntry var5 = this.tryLock()?null:this.scanAndLockForPut(var1, var2, var3); Object var6; try &#123; ConcurrentHashMap.HashEntry[] var7 = this.table; int var8 = var7.length - 1 &amp; var2; //2.定位到HashEntry数组中具体的HashEntry ConcurrentHashMap.HashEntry var9 = ConcurrentHashMap.entryAt(var7, var8); ConcurrentHashMap.HashEntry var10 = var9; //3.遍历HashEntry链表，假若待插入key已存在： //需要更新key所对应value（!onlyIfAbsent），更新oldValue -&gt; newValue，跳转到步骤5； //否则，直接跳转到步骤5； while(true) &#123; if(var10 == null) &#123; if(var5 != null) &#123; var5.setNext(var9); &#125; else &#123; var5 = new ConcurrentHashMap.HashEntry(var2, var1, var3, var9); &#125; int var15 = this.count + 1; if(var15 &gt; this.threshold &amp;&amp; var7.length &lt; 1073741824) &#123; this.rehash(var5); &#125; else &#123; ConcurrentHashMap.setEntryAt(var7, var8, var5); &#125; ++this.modCount; this.count = var15; var6 = null; break; &#125; //4.遍历完HashEntry链表，key不存在，插入HashEntry节点，oldValue = null，跳转到步骤5 Object var11 = var10.key; if(var10.key == var1 || var10.hash == var2 &amp;&amp; var1.equals(var11)) &#123; var6 = var10.value; if(!var4) &#123; var10.value = var3; ++this.modCount; &#125; break; &#125; var10 = var10.next; &#125; &#125; finally &#123; //5.释放锁，返回oldValue this.unlock(); &#125; return var6;&#125; 上面代码中已经做出解析，需要知道的是Segment的HashEntry数组采用开链法来处理冲突，我们知道散列最大的局限性就是空间利用率低，例如载荷因子为0.7，那么仍有0.3的空间未被利用。使用开链法可以使载荷因子为1，每个链上都挂常数个数据，对于哈希表的开链法来说，其开的空间都是按素数个依次往后开的空间，所以put操作的效率很高。 再来看一下remove操作： 12345public V remove(Object var1) &#123; int var2 = this.hash(var1); ConcurrentHashMap.Segment var3 = this.segmentForHash(var2); return var3 == null?null:var3.remove(var1, var2, (Object)null);&#125; 仍旧是调用了Segment的remove方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748final V remove(Object var1, int var2, Object var3) &#123; //获取锁 if(!this.tryLock()) &#123; this.scanAndLock(var1, var2); &#125; Object var4 = null; try &#123; ConcurrentHashMap.HashEntry[] var5 = this.table; int var6 = var5.length - 1 &amp; var2; ConcurrentHashMap.HashEntry var7 = ConcurrentHashMap.entryAt(var5, var6); ConcurrentHashMap.HashEntry var10; for(ConcurrentHashMap.HashEntry var8 = null; var7 != null; var7 = var10) &#123; // 所有处于待删除节点之后的节点原样保留在链表中 var10 = var7.next; Object var9 = var7.key; //找到要删除的节点 if(var7.key == var1 || var7.hash == var2 &amp;&amp; var1.equals(var9)) &#123; // 所有处于待删除节点之前的节点被克隆到新链表中 Object var11 = var7.value; if(var3 != null &amp;&amp; var3 != var11 &amp;&amp; !var3.equals(var11)) &#123; break; &#125; if(var8 == null) &#123; ConcurrentHashMap.setEntryAt(var5, var6, var10); &#125; else &#123; var8.setNext(var10); &#125; ++this.modCount; --this.count; // 把桶链接到新的头结点 // 新的头结点是原链表中，删除节点之前的那个节点 var4 = var11; break; &#125; var8 = var7; &#125; &#125; finally &#123; this.unlock(); &#125; return var4;&#125; 我们来看两张图，执行删除前的原链表： 删除之后的链表： 从上图可以看出，删除节点 C 之后的所有节点原样保留到新链表中；删除节点 C 之前的每个节点被克隆到新链表中，注意：它们在新链表中的链接顺序被反转了。 在执行 remove 操作时，原始链表并没有被修改，也就是说：读线程不会受同时执行 remove 操作的并发写线程的干扰。 综合上面的分析我们可以看出，写线程对某个链表的结构性修改不会影响其他的并发读线程对这个链表的遍历访问。 总结 ConcurrentHashMap 允许并发的读和线程安全的更新操作 在执行写操作时，ConcurrentHashMap 只锁住部分的Map 并发的更新是通过内部根据并发级别将Map分割成小部分实现的 高的并发级别会造成时间和空间的浪费，低的并发级别在写线程多时会引起线程间的竞争 ConcurrentHashMap 的所有操作都是线程安全 ConcurrentHashMap 返回的迭代器是弱一致性，fail-safe并且不会抛出ConcurrentModificationException异常 ConcurrentHashMap 不允许null的键值 ConcurrentHashMap 是一个并发散列映射表的实现，它允许完全并发的读取，并且支持给定数量的并发更新。相比于 HashTable 和用同步包装器包装的 HashMap（Collections.synchronizedMap(new HashMap())），ConcurrentHashMap 拥有更高的并发性。在 HashTable 和由同步包装器包装的 HashMap 中，使用一个全局的锁来同步不同线程间的并发访问。同一时间点，只能有一个线程持有锁，也就是说在同一时间点，只能有一个线程能访问容器。这虽然保证多线程间的安全并发访问，但同时也导致对容器的访问变成串行化的了。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（二十一）----(JUC集合)CopyOnWriteArraySet和ConcurrentSkipListSet介绍]]></title>
    <url>%2Fposts%2F5ee7a4a7.html</url>
    <content type="text"><![CDATA[这一节我们来接着介绍JUC集合：CopyOnWriteArraySet和ConcurrentSkipListSet。从名字上来看我们知道CopyOnWriteArraySet与上一节讲到的CopyOnWriteArrayList一样是动态数组实现;ConcurrentSkipListSet是线程安全的有序的集合，适用于高并发的场景。下面我们深入细致的分析一下他们的用法。 1 CopyOnWriteArraySet简介它是线程安全的无序的集合，可以将它理解成线程安全的HashSet。对其所有操作使用内部 CopyOnWriteArrayList 的 Set。因此，它共享以下相同的基本属性： 它最适合于具有以下特征的应用程序：set 大小通常保持很小，只读操作远多于可变操作，需要在遍历期间防止线程间的冲突。 它是线程安全的。 因为通常需要复制整个基础数组，所以可变操作（add、set 和 remove 等等）的开销很大。 迭代器不支持可变 remove操作。 使用迭代器进行遍历的速度很快，并且不会与其他线程发生冲突。在构造迭代器时，迭代器依赖于不变的数组快照。 我们看一下CopyOnWriteArraySet的类体： 1234public class CopyOnWriteArraySet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Serializable &#123; private static final long serialVersionUID = 5457747651344034263L; private final CopyOnWriteArrayList&lt;E&gt; al = new CopyOnWriteArrayList();&#125; 该类有一个成员变量CopyOnWriteArrayList。CopyOnWriteArraySet其所有操作使用内部 CopyOnWriteArrayList 的 Set，所以他的所有的方法其实都是引用了CopyOnWriteArrayList的方法来完成的。有关CopyOnWriteArrayList的使用说明我们在上一节里已经介绍的很详细，有兴趣可以查看上一节里的源码介绍。 2 ConcurrentSkipListSet简介ConcurrentSkipListSet是线程安全的有序的集合，适用于高并发的场景。他是一个基于 ConcurrentSkipListMap 的可缩放并发 NavigableSet 实现。下面我们看一下方法体： 12345678910111213public class ConcurrentSkipListSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements NavigableSet&lt;E&gt;, Cloneable, java.io.Serializable &#123; private static final long serialVersionUID = -2479143111061671589L; private final ConcurrentNavigableMap&lt;E,Object&gt; m; public ConcurrentSkipListSet() &#123; m = new ConcurrentSkipListMap&lt;E,Object&gt;(); &#125;&#125; (1) ConcurrentSkipListSet继承于AbstractSet。因此，它本质上是一个集合。 (2) ConcurrentSkipListSet实现了NavigableSet接口。因此，ConcurrentSkipListSet是一个有序的集合。 (3) ConcurrentSkipListSet是通过ConcurrentSkipListMap实现的。它包含一个ConcurrentNavigableMap对象m，而m对象实际上是ConcurrentNavigableMap的实现类ConcurrentSkipListMap的实例。ConcurrentSkipListMap中的元素是key-value键值对；而ConcurrentSkipListSet是集合，它只用到了ConcurrentSkipListMap中的key！ 由源码中我们能看到ConcurrentSkipListSet内部所有操作都是在内部由ConcurrentSkipListMap完成。本节我们先不介绍ConcurrentSkipListMap，下节讲到map的时候再细说。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（十九）----(JUC集合)总体框架介绍]]></title>
    <url>%2Fposts%2Fc00aa264.html</url>
    <content type="text"><![CDATA[本节我们将继续学习JUC包中的集合类，我们知道jdk中本身自带了一套非线程安全的集合类，我们先温习一下java集合包里面的集合类，然后系统的看一下JUC包里面的集合类到底有什么不同。 1 java集合类java集合类里面主要包含两大类：一类是Collection接口下的List、Set和Queue接口，一类是Map接口。 1.1 List的主要实现类包括：ArrayList：数组实现的队列，它是一个动态数组；它不是线程安全的，只适用于单线程； LinkedList：双重链表实现的队列，它也不是线程安全的，只适用于单线程； Stack：表示后进先出（LIFO）的对象堆栈，继承于Vector，他是线程安全的； Vector：可以实现可增长的对象数组，与数组一样，它包含可以使用整数索引进行访问的组件。此类是线程安全的。 1.2 Set的主要实现类包括：HashSet：由哈希表（实际上是一个 HashMap 实例）支持。该集合元素不可重复，它不保证 set 的迭代顺序；特别是它不保证该顺序恒久不变，并且此实现不是同步的； TreeSet：基于 TreeMap 的 NavigableSet 实现，也是一个没有重复元素的集合，不过和HashSet不同的是，TreeSet中的元素是有序的；该类的实现也不是同步的； LinkedHashSet：元素是有序的，维护着一个运行于所有条目的双重链接列表；此实现不是同步的； 1.3 Map的主要实现类包括：HashMap：基于哈希表的 Map 接口的实现。此实现不是同步的； TreeMap：基于红黑树（Red-Black tree）的 NavigableMap 实现，该类的&lt;k,v&gt;是有序的此实现不是同步的； HashTable：与HashMap一样都是基于哈希表的Map实现，但是此类是线程安全的； WeakHashMap：以弱键 实现的基于哈希表的 Map。在 WeakHashMap 中，当某个键不再正常使用时，将自动移除其条目。该类是非线程安全的。 上面这些是传统的java集合类，他们大多数都不是线程安全的，所以在同步并发中对他们的使用率并不高，为了线程安全以及开发人员在使用集合工具的同时不必去维护线程安全，Doug Lea在JUC(java.util.concurrent)包中添加了java集合包中单线程类的对应的支持高并发的类。下面我们一起来看一下这些并发集合类。 2 JUC集合类2.1 List的主要实现类包括： CopyOnWriteArrayList：相当于线程安全的ArrayList，它实现了List接口，他是线程安全的。 2.2 Set的主要实现类包括： CopyOnWriteArraySet：相当于线程安全的HashSet,内部使用 CopyOnWriteArrayList 。 ConcurrentSkipListSet:一个基于 ConcurrentSkipListMap 的可缩放并发 NavigableSet 实现，内部排序是有序的。 2.3 Map的主要实现类包括： ConcurrentHashMap：支持获取的完全并发和更新的所期望可调整并发的哈希表。 ConcurrentSkipListMap：可缩放的并发 ConcurrentNavigableMap 实现，内部排序是有序的Map，该类为线程安全的。 2.4 Queue的主要实现类包括： ArrayBlockingQueue：一个由数组支持的有界阻塞队列。此队列按 FIFO（先进先出）原则对元素进行排序； LinkedBlockingQueue：一个基于已链接节点的、范围任意的 blocking queue。此队列按 FIFO（先进先出）排序元素； LinkedBlockingDeque：一个基于已链接节点的、任选范围的阻塞双端队列； ConcurrentLinkedQueue：一个基于链接节点的无界线程安全队列。此队列按照 FIFO（先进先出）原则对元素进行排序； ConcurrentLinkedDeque：是双向链表实现的无界队列，该队列同时支持FIFO和FILO两种操作方式。 下一节我们将一起详细的来分析JUC中的集合工具的使用和原理。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（十八）----(线程池)java线程池框架Fork-Join]]></title>
    <url>%2Fposts%2F5f5c40c1.html</url>
    <content type="text"><![CDATA[这一节开始我们正式来介绍JUC集合类。我们按照List、Set、Map、Queue的顺序来进行介绍。这一节我们来看一下CopyOnWriteArrayList。 1 CopyOnWriteArrayList介绍CopyOnWriteArrayList是ArrayList 的一个线程安全的变体，其中所有可变操作（add、set 等等）都是通过对底层数组进行一次新的复制来实现的。 与ArrayList不同处就在于是否会拷贝数组和加锁。 CopyOnWriteArrayList顾名思义就是写时复制的ArrayList，其意思就是在修改容器的元素时，并不是直接在原数组上修改，而是先拷贝了一份数组，然后在拷贝的数组上进行修改，修改完后将其引用赋值给原数组的引用。这样体现了读写分离，这样无论在任何时候我们都可以对容器进行读取。 2 CopyOnWriteArrayList源码分析我们看一下CopyOnWriteArrayList的类声明部分： 123456789public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; /** The lock protecting all mutators */ transient final ReentrantLock lock = new ReentrantLock(); /** The array, accessed only via getArray/setArray. */ private volatile transient Object[] array;&#125; 它实现了List接口，所以实现了Collection的功能，另外我们看到还有两个类成员变量lock和array，在后面的源码分析中我们能看到CopyOnWriteArrayList是线程安全的使用动态数组操作机制实现的List。 所谓动态数组操作机制：即通过volatile修饰的Object类型数组来进行数组的CRUD操作。在进行add,set,remove等可变操作的时候，都会先新建一个数组把更新的值赋给该数组，然后再传递给上面的array数组来保持该次操作的可见性。这也是CopyOnWriteArrayList命名的由来。这一般需要很大的开销，但是当遍历操作的数量大大超过可变操作的数量时，即在进行读操作时的效率要远远高于写或是修改操作，这种方法可能比其他替代方法更 有效。 CopyOnWriteArrayList的线程安全实现：我们能看到是通过一个全局的Lock和volatile修饰的array来实现的。在进行add,remove,set等可变操作的时候通过赋值给array我们总能保证该变量的内存可见性，其他的线程每次总能读到最新的array变量；同样在每次进行add,remove,set等可变操作时候都会在操作的一开始加入独占锁，操作结束释放锁，以保证本次操作的安全性。 下面我们就上述分析来看一下他的部分源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public void add(int index, E element) &#123; final ReentrantLock lock = this.lock; //加锁 lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; if (index &gt; len || index &lt; 0) throw new IndexOutOfBoundsException("Index: "+index+", Size: "+len); Object[] newElements; int numMoved = len - index; if (numMoved == 0) //如果是在最后一个位置增加就把该数组赋值一份然后新增一个长度 newElements = Arrays.copyOf(elements, len + 1); else &#123; //否则新建数组，然后将"volatile数组中被删除元素之外的其它元素“拷贝到新数组中；最后，将新数组赋值给”volatile数组"。 newElements = new Object[len + 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index, newElements, index + 1,numMoved); &#125; newElements[index] = element; setArray(newElements); //拷贝 &#125; finally &#123; lock.unlock(); &#125;&#125;public E set(int index, E element) &#123; final ReentrantLock lock = l.lock;//加锁 lock.lock(); try &#123; rangeCheck(index); checkForComodification(); E x = l.set(index+offset, element); expectedArray = l.getArray();//拷贝 return x; &#125; finally &#123; lock.unlock(); &#125;&#125;public E remove(int index) &#123; final ReentrantLock lock = this.lock; //加锁 lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); int numMoved = len - index - 1; // 如果被删除的是最后一个元素，则直接通过Arrays.copyOf()进行处理，而不需要新建数组。 if (numMoved == 0) setArray(Arrays.copyOf(elements, len - 1)); // 否则，新建数组，然后将"volatile数组中被删除元素之外的其它元素“拷贝到新数组中；最后，将新数组赋值给”volatile数组"。 else &#123; Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index,numMoved); setArray(newElements); //拷贝 &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125;&#125; 由上面源码部分我们可以看到CopyOnWriteArrayList在修改原数组的过程中比ArrayList多做了2件事： 1、加锁：保证我在修改数组的时候，其他人不能修改。 2、拷贝数组：无论是哪个方法，发现都需要拷贝数组。 上面的两件事就确保了CopyOnWriteArrayList在多线程的环境下可以应对自如。 我们再来看一下他的迭代器的实现： 123public Iterator&lt;E&gt; iterator() &#123; return new COWIterator&lt;E&gt;(getArray(), 0);&#125; 我们看到迭代器里面调用了COWIterator这个类，下面来看一下他的源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private static class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; &#123; /** Snapshot of the array */ private final Object[] snapshot; /** Index of element to be returned by subsequent call to next. */ private int cursor; private COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; snapshot = elements; &#125; public boolean hasNext() &#123; return cursor &lt; snapshot.length; &#125; public boolean hasPrevious() &#123; return cursor &gt; 0; &#125; @SuppressWarnings("unchecked") public E next() &#123; if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++]; &#125; @SuppressWarnings("unchecked") public E previous() &#123; if (! hasPrevious()) throw new NoSuchElementException(); return (E) snapshot[--cursor]; &#125; public int nextIndex() &#123; return cursor; &#125; public int previousIndex() &#123; return cursor-1; &#125; //不支持remove方法 public void remove() &#123; throw new UnsupportedOperationException(); &#125; //不支持set方法 public void set(E e) &#123; throw new UnsupportedOperationException(); &#125; //不支持add方法 public void add(E e) &#123; throw new UnsupportedOperationException(); &#125;&#125; 我们可以看到COWSubListIterator不支持修改元素的操作。例如，对于remove(),set(),add()等操作，COWSubListIterator都会抛出异常！ CopyOnWriteArrayList的迭代器并不是快速失败的，也就是说并不会抛出ConcurrentModificationException异常。这是因为他在修改的时候，是针对与拷贝数组而言的，对于原数组没有任何影响。我们可以看出迭代器里面没有锁机制，所以只提供读取，而不支持添加修改和删除（抛出UnsupportedOperationExcetion）。 3 CopyOnWriteArrayList使用示例上面我们具体的分析了CopyOnWriteArrayList的线程安全机制和实现机制，我们再来就他的使用做一个相应的说明： 123456789101112131415161718192021222324252627282930313233public class TestCopyOnWriteArrayList &#123; // fixme: list是ArrayList对象时，程序会出错。 private static List&lt;String&gt; list = new ArrayList&lt;String&gt;(); /*private static List&lt;String&gt; list = new CopyOnWriteArrayList&lt;String&gt;();*/ public static void main(String[] args) &#123; ExecutorService executor = Executors.newFixedThreadPool(20); for(int i=0;i&lt;100;i++)&#123; executor.execute(new TestList("aa")); &#125; &#125; private static void printAll() &#123; String value = null; Iterator iter = list.iterator(); while(iter.hasNext()) &#123; value = (String)iter.next(); System.out.print(value+", "); &#125; System.out.println(); &#125; private static class TestList extends Thread &#123; TestList(String name) &#123; super(name); &#125; @Override public void run() &#123; String val = Thread.currentThread().getName(); list.add(val); printAll(); &#125; &#125;&#125; 运行上程序，当list是ArrayList对象时，程序会出错，报出java.util.ConcurrentModificationException类型异常；当使用CopyOnWriteArrayList对象时，程序可以完成iterator遍历操作。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（十八）----(线程池)java线程池框架Fork-Join]]></title>
    <url>%2Fposts%2F5f5c40c1.html</url>
    <content type="text"><![CDATA[还记得我们在初始介绍线程池的时候提到了Executor框架的体系，到现在为止我们只有一个没有介绍，与ThreadPoolExecutor一样继承与AbstractExecutorService的ForkJoinPool.Fork/Join框架是Java7提供了的一个用于并行执行任务的框架， 是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。 我们通过表面的意思去理解ForkJoin框架：Fork即把一个大任务切割成若干部分并行执行，join即把这些被切分的任务的执行结果合并一起汇总，我们可以用下图来表示： Fork / Join的逻辑很简单： （1）将每个大任务分离（fork）为较小的任务; （2）在单独的线程中处理每个任务（如果必要，将它们分离成更小的任务）; （3）加入结果。 Fork/Join框架的核心是由下列两个类组成的。 ①ForkJoinPool：这个类实现了ExecutorService接口和工作窃取算法（Work-Stealing Algorithm）。它管理工作者线程，并提供任务的状态信息，以及任务的执行信息。 ②ForkJoinTask：这个类是一个将在ForkJoinPool中执行的任务的基类。 理解一个概念的最好方法是在实践中体会他，我们先写一个小程序，在此基础上一点一点来分析： 123456789101112131415161718192021222324252627282930313233343536public class ForkJoinPoolTest &#123; public static void main(String[] args) throws InterruptedException &#123; ForkJoinPool pool = new ForkJoinPool(); pool.submit(new PrintTask(1,100)); pool.awaitTermination(2, TimeUnit.SECONDS);//阻塞当前线程直到 ForkJoinPool 中所有的任务都执行结束 pool.shutdown(); &#125;&#125;class PrintTask extends RecursiveAction&#123; private int start; private int end; private int num; final int MAX = 50; public PrintTask(int start, int end) &#123; this.start = start; this.end = end; &#125; @Override protected void compute() &#123; if(end - start &lt; 50)&#123; for(int i = start;i &lt;= end; i++)&#123; num += i; &#125; System.out.println("当前任务结果为： "+num); &#125;else&#123; int mid = (end + start)/2; PrintTask left = new PrintTask(start,mid); PrintTask right = new PrintTask(mid+1,end); left.fork(); right.fork(); &#125; &#125;&#125; 结果为： 1234当前任务结果为： 3775当前任务结果为： 1275Process finished with exit code 0 我们通过结果可以看到当前任务被分裂为两个子任务去执行。而执行任务的类继承了RecursiveAction这个类，那他到底在Fork-Join框架中发挥什么作用呢？我们不妨看一下： 首先我们来看一下Fork-Join框架提交任务的方法仍旧还是submit和execute： void execute(ForkJoinTask&lt;?&gt; task) //安排（异步）执行给定任务 void execute(Runnable task) //在未来的某个时候执行给定的命令 &lt;T&gt; ForkJoinTask&lt;T&gt; submit(Callable&lt;T&gt; task) //执行一个有返回值得任务， 返回一个Future类型的实例代表任务的结果 &lt;T&gt; ForkJoinTask&lt;T&gt; submit(ForkJoinTask&lt;T&gt; task) //提交一个ForkJoinTask类型的任务 ForkJoinTask&lt;?&gt; submit(Runnable task) //提交一个Runnable类型的任务，返回一个 Future类型的实例代表任务结果 &lt;T&gt; ForkJoinTask&lt;T&gt; submit(Runnable task, T result) //提交一个Runnable类型的任务，返回一个Future类型的实例代表任务结果 由execute和submit的参数我们可以看到Fork-join框架可以提交ForkJoinTask，Callable和Runnable类型的任务。这个ForkJoinTask我们之前没见过，先来看一下： 12public abstract class ForkJoinTask&lt;V&gt; implements Future&lt;V&gt;, Serializable &#123;&#125; 我们看到ForkJoinTask实现了Future接口，一个ForkJoinTask是一个轻量级的Future。对ForkJoinTask效率源于一组限制（这只是部分静态强制执行）反映其用途作为计算任务计算纯函数或纯粹孤立的对象操作。主要的协调机制fork()，安排异步执行，而不进行join()，直到任务的结果已经计算。通常我们并不直接继承 ForkJoinTask，它包含了太多的抽象方法。针对特定的问题，我们可以选择 ForkJoinTask 的不同子类来完成任务： RecursiveAction：用于任务没有返回结果的场景。 RecursiveTask：用于任务有返回结果的场景。 上面的例子中我们就是继承了RecursiveAction子类用于没有返回结果的场景，下面我们再看一下RecursiveTask用于有返回结果的场景： 123456789101112131415161718192021222324252627282930313233343536373839404142public class TestRecursiveTask &#123; public static void main(String[] args) &#123; Integer result = 0; ForkJoinPool pool = new ForkJoinPool(); Future&lt;Integer&gt; future = pool.submit(new SumTask(30)); try &#123; result = future.get(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println(result+"==========================="); &#125;&#125;class SumTask extends RecursiveTask&lt;Integer&gt; &#123; int num; public SumTask(int num) &#123; this.num = num; &#125; @Override protected Integer compute() &#123; if(num &lt;= 20)&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("生产完成"+num+"个产品"); return num; &#125;else&#123; SumTask task1 = new SumTask(20); SumTask task2 = new SumTask(num - 20); task1.fork(); task2.fork(); return task1.join() + task2.join(); &#125; &#125;&#125; 结果为： 生产完成20个产品 生产完成10个产品 30=========================== Process finished with exit code 0 我们看到继承RecursiveTask类指定了返回值类型为Integer，在compute方法中的返回值类型即为Integer类型。 从以上的例子中可以看到，通过使用 Fork/Join 模式，软件开发人员能够方便地利用多核平台的计算能力。尽管还没有做到对软件开发人员完全透明，Fork/Join 模式已经极大地简化了编写并发程序的琐碎工作。对于符合 Fork/Join 模式的应用，软件开发人员不再需要处理各种并行相关事务，例如同步、通信等，以难以调试而闻名的死锁和 data race 等错误也就不会出现，提升了思考问题的层次。你可以把 Fork/Join 模式看作并行版本的 Divide and Conquer 策略，仅仅关注如何划分任务和组合中间结果，将剩下的事情丢给 Fork/Join 框架。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（十七）----(线程池)java线程池架构和原理]]></title>
    <url>%2Fposts%2Fb9ed0404.html</url>
    <content type="text"><![CDATA[前面我们简单介绍了线程池的使用，但是对于其如何运行我们还不清楚，Executors为我们提供了简单的线程工厂类，但是我们知道ThreadPoolExecutor是线程池的具体实现类。我们先从他开始分析。 1 ThreadPoolExecutor初探ThreadPoolExecutor一共有3个构造方法，我们来看一下其中看起来比较复杂的这个： 123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 看起来参数是挺多的，我们不妨耐心看看参数都是什么意思： corePoolSize：核心池的大小，默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数，它表示在线程池中最多能创建多少个线程； keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。 unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性： 1234567TimeUnit.DAYS; //天TimeUnit.HOURS; //小时TimeUnit.MINUTES; //分钟TimeUnit.SECONDS; //秒TimeUnit.MILLISECONDS; //毫秒TimeUnit.MICROSECONDS; //微妙TimeUnit.NANOSECONDS; //纳秒 workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择： 123ArrayBlockingQueue;LinkedBlockingQueue;SynchronousQueue; threadFactory：是构造Thread的方法，你可以自己去包装和传递，主要实现newThread方法即可； handler：表示当拒绝处理任务时的策略，也就是参数maximumPoolSize达到后丢弃处理的方法，java提供了4种丢弃处理的方法，当然你也可以自己根据实际情况去重写，主要是要实现接口：RejectedExecutionHandler中的方法： public void rejectedExecution(Runnabler, ThreadPoolExecutor e) java默认的是使用：AbortPolicy，他的作用是当出现这中情况的时候会抛出一个异常；有以下四种取值： ①ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ②ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ③ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ④ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 上面说了ThreadPoolExecutor的构造方法，我们继续看他的类的关系： 123public class ThreadPoolExecutor extends AbstractExecutorService &#123;&#125; 由源码我们看出ThreadPoolExecutor继承了AbstractExecutorService类，我们知道AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。AbstractExecutorService存在的目的是为ExecutorService中的函数接口提供了默认实现。 12public abstract class AbstractExecutorService implements ExecutorService &#123;&#125; 由上我们知道AbstractExecutorService又实现了ExecutorService接口，而ExecutorService是Executor实现类的最直接接口。 12public interface ExecutorService extends Executor &#123;&#125; 由此我们似乎可以明白他们之间的关系： Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)； ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等； 抽象类AbstractExecutorService实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法； ThreadPoolExecutor继承了类AbstractExecutorService，成为线程池的具体实现类。 2 线程池的实现上面我们从ThreadPoolExecutor的构造方法出发提到了线程池的状态，执行，初始化，排队策略等等，下面我们就从这些方面入手，看看线程池的原理。 3 线程池初始化默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务（execute或者submit）之后才会创建线程。在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程 prestartAllCoreThreads()：初始化所有核心线程 下面是这两个方法的实现： 1234567891011121314151617public boolean prestartCoreThread() &#123; return workerCountOf(ctl.get()) &lt; corePoolSize &amp;&amp; addWorker(null, true);&#125;----------------------------------------------------------public int prestartAllCoreThreads() &#123; int n = 0; while (addWorker(null, true)) ++n; return n;&#125;----------------------------------------------------- 我们注意到上面两个方法都调用了addWorker方法，我们看一下实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; final ReentrantLock mainLock = this.mainLock; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); int rs = runStateOf(c); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 这个方法还是挺好理解：上面的retry是对当前线程池状态进行检查，如果当前线程池未初始化或者未分配则返回false； 往下是初始化firstTask，我们看到在56行把初始化的firstTask加入workers集合，该集合定义为： 1private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); 集合中包含当前所有的工作线程。看完addWorker的实现，那么上面的prestartCoreThread和prestartAllCoreThreads我们就很好理解，前一个是向当前工作线程池中加入一个工作线程，后一个是循环N次。 4 线程池的执行通常你得到线程池后，会调用其中的：submit方法或execute方法去操作；其实你会发现，submit方法最终会调用execute方法来进行操作，只是他提供了一个Future来托管返回值的处理而已，当你调用需要有返回值的信息时，你用它来处理是比较好的；这个Future会包装对Callable信息，并定义一个Sync对象（），当你发生读取返回值的操作的时候，会通过Sync对象进入锁，直到有返回值的数据通知。 我们先看一下submit方法的源码： 123456public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125; 我们看到在源码的第4行实际上是调用了execute()方法来处理包装的RunnableFuture。下面是execute方法的源码： 12345678910111213141516171819public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command);&#125; 第一个if为非空判断; 第二个if中的workerCountOf()方法拿到ctl中存储的当前线程总数，如果小于corePoolSize，那么就会走到addWorker()方法中，如果成功创建了Worker的话，那么返回true，直接return，否则重新通过cas拿一次c; 第三个if中判断当前的线程池是否处于RUNNING状态，如果是，并且workQueue.offer加入队列成功话，那么就重新拿出来一次ctl，再判断如果加入队列之后，线程池如果不是处于RUNNING的状态，并且从队列中remove成功的话，那么就会执行reject操作；判断当前线程数是否为0，如果为0的话，那么就调用addWorker(null,false)，否则如果非Running状态或者加入队列失败的话，那么就会调用addWorker(command,false)如果返回false，说明没有添加成功，就会执行reject操作。 5 任务缓存队列我们还记得ThreadPoolExecutor的构造函数中有一个参数workQueue，它用来存放等待执行的任务。workQueue的类型为BlockingQueue，通常可以取下面三种类型： 1）ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小； 2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE； 3）synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。 6 线程池的关闭ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务7 线程池容量的动态调整ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize() setCorePoolSize：设置核心池大小 setMaximumPoolSize：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。 下面我们看一个小例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class ThreadPoolExecutorTest &#123; private static int produceTaskSleepTime = 2; private static int produceTaskMaxNumber = 10; public static void main(String[] args) &#123; // 构造一个线程池 ThreadPoolExecutor threadPool = new ThreadPoolExecutor(2, 4, 3, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(3), new ThreadPoolExecutor.DiscardOldestPolicy()); for (int i = 1; i &lt;= produceTaskMaxNumber; i++) &#123; try &#123; String task = "task-- " + i; System.out.println("创建任务并提交到线程池中：" + task); threadPool.execute(new ThreadPoolTask(task)); System.out.println("线程池中线程数目："+threadPool.getPoolSize()+"，队列中等待执行的任务数目："+ threadPool.getQueue().size()+"，已执行完毕的任务数目："+threadPool.getCompletedTaskCount()); Thread.sleep(produceTaskSleepTime); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;class ThreadPoolTask implements Runnable, Serializable &#123; private Object attachData; ThreadPoolTask(Object tasks) &#123; this.attachData = tasks; &#125; public void run() &#123; System.out.println("开始执行任务：" + attachData); attachData = null; &#125; public Object getTask() &#123; return this.attachData; &#125;&#125;结果为：创建任务并提交到线程池中：task-- 1开始执行任务：task-- 1线程池中线程数目：1，队列中等待执行的任务数目：0，已执行完毕的任务数目：0创建任务并提交到线程池中：task-- 2线程池中线程数目：2，队列中等待执行的任务数目：0，已执行完毕的任务数目：1开始执行任务：task-- 2创建任务并提交到线程池中：task-- 3线程池中线程数目：2，队列中等待执行的任务数目：1，已执行完毕的任务数目：2开始执行任务：task-- 3创建任务并提交到线程池中：task-- 4线程池中线程数目：2，队列中等待执行的任务数目：1，已执行完毕的任务数目：3开始执行任务：task-- 4创建任务并提交到线程池中：task-- 5线程池中线程数目：2，队列中等待执行的任务数目：1，已执行完毕的任务数目：4开始执行任务：task-- 5创建任务并提交到线程池中：task-- 6线程池中线程数目：2，队列中等待执行的任务数目：1，已执行完毕的任务数目：5开始执行任务：task-- 6创建任务并提交到线程池中：task-- 7线程池中线程数目：2，队列中等待执行的任务数目：1，已执行完毕的任务数目：6开始执行任务：task-- 7创建任务并提交到线程池中：task-- 8线程池中线程数目：2，队列中等待执行的任务数目：1，已执行完毕的任务数目：7开始执行任务：task-- 8创建任务并提交到线程池中：task-- 9开始执行任务：task-- 9线程池中线程数目：2，队列中等待执行的任务数目：0，已执行完毕的任务数目：8创建任务并提交到线程池中：task-- 10开始执行任务：task-- 10线程池中线程数目：2，队列中等待执行的任务数目：0，已执行完毕的任务数目：9 由结果我们可以看到当线程池中线程的数目大于2时，便将任务放入任务缓存队列里面，当任务缓存队列满了之后，便创建新的线程。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（十六）----(线程池)java线程池的使用]]></title>
    <url>%2Fposts%2Fe7e539b9.html</url>
    <content type="text"><![CDATA[上节我们简单介绍了线程池，这次我们就来使用一下。Executors提供四种线程池，分别是：newCachedThreadPool，newFixedThreadPool ，newScheduledThreadPool ，newSingleThreadExecutor 。下面我们分别来使用下。 1 newSingleThreadExecutor创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 我们来看一个小例子： 12345678910111213public class newSingleThreadExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService ex = Executors.newSingleThreadExecutor(); for(int i=0;i&lt;10;i++)&#123; ex.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; &#125;); &#125; &#125;&#125; 输出为： pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 由输出结果可以看出始终只有一个线程在工作。 2 newFixedThreadPool创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 我们来看一个小例子： 12345678910111213public class newFixedThreadPoolTest &#123; public static void main(String[] args) &#123; ExecutorService ex = Executors.newFixedThreadPool(5); for(int i=0;i&lt;10;i++)&#123; ex.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; &#125;); &#125; &#125;&#125; 输出为： pool-1-thread-1 pool-1-thread-2 pool-1-thread-2 pool-1-thread-5 pool-1-thread-3 pool-1-thread-3 pool-1-thread-3 pool-1-thread-3 pool-1-thread-3 pool-1-thread-4 我们启动了10个线程，但是池中只有5个线程工作，所以结果中最多只有5个线程。 3 newCachedThreadPool创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。 我们来看一个小例子： 123456789101112131415161718public class newCachedThreadPoolTest &#123; public static void main(String[] args) &#123; ExecutorService ex = Executors.newCachedThreadPool(); for(int i=0;i&lt;10;i++)&#123; ex.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; &#125;); try &#123; Thread.sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 输出为： pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 pool-1-thread-1 线程池为无限大，当执行第二个任务时第一个任务已经完成，会复用执行第一个任务的线程，而不用每次新建线程。但是如果执行第二个任务时第一个任务没有完成则又是另一番景象，我们把上面的例子稍稍改一下就有所不同： 123456789101112131415161718public class newCachedThreadPoolTest &#123; public static void main(String[] args) &#123; ExecutorService ex = Executors.newCachedThreadPool(); for(int i=0;i&lt;10;i++)&#123; ex.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); try &#123; Thread.sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125;&#125; 输出为： pool-1-thread-1 pool-1-thread-3 pool-1-thread-2 pool-1-thread-5 pool-1-thread-4 pool-1-thread-6 pool-1-thread-7 pool-1-thread-8 pool-1-thread-9 pool-1-thread-10 第一个任务在执行的时候等待了6秒，所以此时第二个任务执行的时候则是新建一个线程来执行。 4 newScheduledThreadPool创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 在上一篇类类的关系图中我们可以看到该方法直接实现了ScheduledExecutorService接口，而该接口相当于提供了”延时”和”周期执行”功能的ExecutorService，再来看一下该方法的源码： 1234public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) &#123; return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);&#125; 返回值是ScheduledExecutorService类型的，与其他3个方法不同，需要注意。我们来看一个小例子： 123456789101112131415161718public class newScheduledThreadPoolTest &#123; public static void main(String[] args) &#123; ScheduledExecutorService ex = Executors.newScheduledThreadPool(5); for(int i=0;i&lt;10;i++)&#123; ex.schedule(new Runnable() &#123; //定时执行的线程池 @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); try &#123; Thread.sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,2, TimeUnit.SECONDS); &#125; &#125;&#125; 输出结果为： pool-1-thread-2 pool-1-thread-4 pool-1-thread-1 pool-1-thread-5 pool-1-thread-3 pool-1-thread-2 pool-1-thread-3 pool-1-thread-5 pool-1-thread-1 pool-1-thread-4 启动后会延迟2s之后才开始执行。 我们再来看一个周期性执行的例子： 123456789101112131415161718public class newScheduledThreadPoolTest &#123; public static void main(String[] args) &#123; ScheduledExecutorService ex = Executors.newScheduledThreadPool(5); for(int i=0;i&lt;10;i++)&#123; ex.scheduleAtFixedRate(new Runnable() &#123; //延迟3s后每2s周期性执行一次，不停 @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); try &#123; Thread.sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,3,2, TimeUnit.SECONDS); &#125; &#125;&#125; 输出为： pool-1-thread-3 pool-1-thread-4 pool-1-thread-2 pool-1-thread-5 pool-1-thread-1 ... newScheduledThreadPool中有很多另外3个类中没有的方法，我们来看一下： shedule(Runnable command, long delay, TimeUnit unit): 延迟一定时间后执行Runnable任务； schedule(Callable callable, long delay, TimeUnit unit): 延迟一定时间后执行Callable任务； scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit): 延迟一定时间后，以间隔period时间的频率周期性地执行任务； scheduleWithFixedDelay(Runnable command, long initialDelay, long delay,TimeUnit unit): 与scheduleAtFixedRate()方法很类似，但是不同的是scheduleWithFixedDelay()方法的周期时间间隔是以上一个任务执行结束到下一个任务开始执行的间隔，而scheduleAtFixedRate()方法的周期时间间隔是以上一个任务开始执行到下一个任务开始执行的间隔，也就是这一些任务系列的触发时间都是可预知的。 由上我们看到ScheduledExecutorService在执行定时任务方面还是挺强大的。线程池的使用我们就到这里，其实用了这么多我们只是在调用别人写好的方法，但是对于线程池是如何实现的我们还是未知的，下一节我们就深入的去分析线程池的实现，看看到底有什么高深莫测。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（十五）----(线程池)java线程池简介]]></title>
    <url>%2Fposts%2Fd72ca9c5.html</url>
    <content type="text"><![CDATA[好的软件设计不建议手动创建和销毁线程。线程的创建和销毁是非常耗 CPU 和内存的，因为这需要 JVM 和操作系统的参与。64位 JVM 默认线程栈是大小1 MB。这就是为什么说在请求频繁时为每个小的请求创建线程是一种资源的浪费。线程池可以根据创建时选择的策略自动处理线程的生命周期。重点在于：在资源（如内存、CPU）充足的情况下，线程池没有明显的优势，否则没有线程池将导致服务器崩溃。有很多的理由可以解释为什么没有更多的资源。例如，在拒绝服务（denial-of-service）攻击时会引起的许多线程并行执行，从而导致线程饥饿（thread starvation）。除此之外，手动执行线程时，可能会因为异常导致线程死亡，程序员必须记得处理这种异常情况。这时我们需要一个管理线程的工具—-线程池应运而生。 在 Java 5 之后，并发编程引入了一堆新的启动、调度和管理线程的API。Executor 框架便是 Java 5 中引入的，其内部使用了线程池机制，它在 java.util.cocurrent 包下，通过该框架来控制线程的启动、执行和关闭，可以简化并发编程的操作。因此，在 Java 5之后，通过 Executor 来启动线程比使用 Thread 的 start 方法更好，除了更易管理，效率更好（用线程池实现，节约开销）外，还有关键的一点：有助于避免 this 逃逸问题——如果我们在构造器中启动一个线程，因为另一个任务可能会在构造器结束之前开始执行，此时可能会访问到初始化了一半的对象用 Executor 在构造器中。 1 Executor简介我们先看一下Execotor框架的体系： Executor: 所有线程池的接口,只有一个方法。 void execute(Runnable command); ExecutorService: 增加Executor的行为，是Executor实现类的最直接接口。 AbstractExecutorService：AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。AbstractExecutorService存在的目的是为ExecutorService中的函数接口提供了默认实现。 ScheduledExecutorService：ScheduledExecutorService是一个接口，它继承于ExecutorService。它相当于提供了”延时”和”周期执行”功能的ExecutorService。ScheduledExecutorService提供了相应的函数接口，可以安排任务在给定的延迟后执行，也可以让任务周期的执行。 ForkJoinPool ：ForkJoinPool 是 Java SE 7 新功能“分叉/结合框架”的核心类，专用于需要将一个任务不断分解成子任务（分叉），再不断进行汇总得到最终结果（结合）的计算过程。比起传统的线程池类ThreadPoolExecutor，ForkJoinPool 实现了工作窃取算法，使得空闲线程能够主动分担从别的线程分解出来的子任务，从而让所有的线程都尽可能处于饱满的工作状态，提高执行效率。 ScheduledThreadPoolExecutor：ScheduledThreadPoolExecutor继承于ThreadPoolExecutor，并且实现了ScheduledExecutorService接口。它相当于提供了”延时”和”周期执行”功能的ScheduledExecutorService。ScheduledThreadPoolExecutor类似于Timer，但是在高并发程序中，ScheduledThreadPoolExecutor的性能要优于Timer。 Executors：Executors是个静态工厂类。它通过静态工厂方法返回ExecutorService、ScheduledExecutorService、ThreadFactory 和 Callable 等类的对象。 ThreadPoolExecutor：线程池的具体实现类,一般用的各种线程池都是基于这个类实现的。 构造方法如下： 12345678public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125; 参数： corePoolSize - 池中所保存的线程数，包括空闲线程。 maximumPoolSize - 池中允许的最大线程数。 keepAliveTime - 当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间。 unit - keepAliveTime 参数的时间单位。 workQueue - 执行前用于保持任务的队列。此队列仅保持由 execute 方法提交的 Runnable 任务。 该方法作用为：用给定的初始参数和默认的线程工厂及被拒绝的执行处理程序创建新的 ThreadPoolExecutor。但是使用 Executors 工厂方法比使用此通用构造方法方便得多。（所以一般不用这个方法） 由该方法我们可以看出一般线程池的工作方式为： ①线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。 ②当调用 execute() 方法添加一个任务时，线程池会做如下判断： ⒈如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务； ⒉如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列； ⒊如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务； ⒋如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常RejectExecutionException。 ⒌当一个线程完成任务时，它会从队列中取下一个任务来执行。 ⒍当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。 2 线程池2.1 线程池的作用：线程池作用就是限制系统中执行线程的数量。 根据系统的环境情况，可以自动或手动设置线程数量，达到运行的最佳效果；少了浪费了系统资源，多了造成系统拥挤效率不高。用线程池控制线程数量，其他线程排队等候。一个任务执行完毕，再从队列的中取最前面的任务开始执行。若队列中没有等待进程，线程池的这一资源处于等待。当一个新任务需要运行时，如果线程池中有等待的工作线程，就可以开始运行了；否则进入等待队列。 2.2 为什么要用线程池:1.减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。 2.可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。 要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。 1.newSingleThreadExecutor 创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 2.newFixedThreadPool 创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 3.newCachedThreadPool 创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。 4.newScheduledThreadPool创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 下节我们分别介绍这些工厂类。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（十四）----(JUC原子类)对象的属性修改类型介绍]]></title>
    <url>%2Fposts%2F58721c94.html</url>
    <content type="text"><![CDATA[今天我们介绍原子类的最后一个类型—-对象的属性修改类型: AtomicIntegerFieldUpdater,AtomicLongFieldUpdater,AtomicReferenceFieldUpdater。有了这几个方法，普通的变量也能享受原子操作了。 1 开胃菜由API我们知道AtomicIntegerFieldUpdater，AtomicLongFieldUpdater，AtomicReferenceFieldUpdater通过反射原子更新对象的字段,既然他们的作用是更新字段我们知道有些类型的字段是不可被更新的，所以被更新的字段是有一定的要求： 1. 必须是volatile类型（volatile是线程可见变量，保存在Jvm的主内存中，而不是线程的工作内存里面），2. 字段的描述类型（修饰符public/protected/default/private）是调用者与操作对象字段的关系一致，3. 只能是实例变量，不能是类变量，也就是说不能加static关键字，4. 只能是可修改变量，不能使final变量，因为final的语义就是不可修改。实际上final的语义和volatile是有冲突的，这两个关键字不能同时存在，5. 对于AtomicIntegerFieldUpdater和AtomicLongFieldUpdater只能修改int/long类型的字段，不能修改其包装类型（Integer/Long）。如果要修改包装类型就需要使用AtomicReferenceFieldUpdater。 2 使用它上面我们说了这几个类的作用是让普通类型的字段也能享受到原子操作，假如原本有一个变量是int型，并且很多地方都应用了这个变量，但是在某个场景下，想让int型变成AtomicInteger，但是如果直接改类型，就要改其他地方的应用。AtomicIntegerFieldUpdater就是为了解决这样的问题产生的。 AtomicIntegerFieldUpdater，AtomicLongFieldUpdater分别是对int和long类型的字段操作，AtomicReferenceFieldUpdater是对引用型的对象操作，并且在API中他们的操作方法与普通的AtomicInteger差不多，所以方法我就不再罗列，我们就直接使用吧。 我们来看AtomicIntegerFieldUpdater的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/*** allscore 如果和 score 的结果相同则说明线程是安全的*/public class AtomicIntegerFieldUpdaterTest &#123; public final static AtomicIntegerFieldUpdater&lt;AA&gt; vv = AtomicIntegerFieldUpdater.newUpdater(AA.class, "score"); //newUpdater方法为AA类中的score 对象创造一个更新器 public static AtomicInteger allscore = new AtomicInteger(0); public static void main(String[] args) throws InterruptedException &#123; final AA stu = new AA(); Thread[] t = new Thread[10000]; for (int i = 0; i &lt; 10000; i++) &#123; t[i] = new Thread() &#123; @Override public void run() &#123; if(Math.random()&gt;0.4) &#123; vv.incrementAndGet(stu); allscore.incrementAndGet(); &#125; &#125; &#125;; t[i].start(); &#125; for (int i = 0; i &lt; 10000; i++) &#123; t[i].join(); &#125; System.out.println("score="+stu.getScore()); System.out.println("allscore="+allscore); &#125;&#125;class AA&#123; int id; volatile int score; public int getScore() &#123; return score; &#125; public void setScore(int score) &#123; this.score = score; &#125;&#125; 输出结果： score=6032 allscore=6032 AtomicIntegerFieldUpdater包装过的int类型的score与 AtomicInteger 的allscore输出的值是一样的，足以见他们所起到的作用是一样。 我们说了AtomicIntegerFieldUpdater,那么AtomicLongFieldUpdater与它的用法大同小异，就不再说明。我们说这几个类是基于反射的实用工具，那么到底是怎么个反射法呢，我们不妨看看源码体验一下，上面用到了AtomicIntegerFieldUpdater.newUpdater()方法来指定类中的字段，我们不妨看看这个newUpdater是怎么执行的： newUpdater（）方法： 1234@CallerSensitivepublic static &lt;U&gt; AtomicIntegerFieldUpdater&lt;U&gt; newUpdater(Class&lt;U&gt; tclass, String fieldName) &#123; return new AtomicIntegerFieldUpdaterImpl&lt;U&gt;(tclass, fieldName, Reflection.getCallerClass());&#125; 我们看到在newUpdater方法上有一个注解：@CallerSensitive，关于这个注解我们可以探究一天的，暂时先埋一个伏笔哈，我们直接跟进去AtomicIntegerFieldUpdaterImpl方法： 12345678910111213141516171819202122232425AtomicIntegerFieldUpdaterImpl(Class&lt;T&gt; tclass, String fieldName, Class&lt;?&gt; caller) &#123; Field field = null; int modifiers = 0; try &#123; field = tclass.getDeclaredField(fieldName); modifiers = field.getModifiers(); sun.reflect.misc.ReflectUtil.ensureMemberAccess( caller, tclass, null, modifiers); sun.reflect.misc.ReflectUtil.checkPackageAccess(tclass); &#125; catch (Exception ex) &#123; throw new RuntimeException(ex); &#125; Class fieldt = field.getType(); if (fieldt != int.class) throw new IllegalArgumentException("Must be integer type"); if (!Modifier.isVolatile(modifiers)) throw new IllegalArgumentException("Must be volatile type"); this.cclass = (Modifier.isProtected(modifiers) &amp;&amp; caller != tclass) ? caller : null; this.tclass = tclass; offset = unsafe.objectFieldOffset(field);&#125; 我们能看到该类里面都是我们常见到的反射的机制，除了sun.reflect.misc.ReflectUtil这个包里面的我们没用到以外。 我们再看一下AtomicReferenceFieldUpdater的使用： 123456789101112131415161718192021222324252627282930313233343536373839404142public class AtomicReferenceFieldUpdaterTest &#123; public static void main(String[] args) &#123; TestAA testAA = new TestAA("xiaoming","nv",12); AtomicReferenceFieldUpdater Updater = AtomicReferenceFieldUpdater.newUpdater(TestAA.class,String.class,"name")； Updater.compareAndSet(testAA,testAA.name,"liming"); System.out.println(testAA.getName()); &#125;&#125;class TestAA&#123; volatile String name; volatile String sex; volatile int age; public TestAA(String name, String sex, int age) &#123; this.name = name; this.sex = sex; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getSex() &#123; return sex; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 输出为： liming Process finished with exit code 0]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（十三）----(JUC原子类)引用类型介绍（CAS和ABA的介绍）]]></title>
    <url>%2Fposts%2F579efe75.html</url>
    <content type="text"><![CDATA[这一节我们将探讨引用类型原子类：AtomicReference, AtomicStampedRerence, AtomicMarkableReference。AtomicReference的使用非常简单，根据API我们就可以知道如何用，但是后两个从名字上看起来感觉是很难的样子，其实只是他的样子长得有点吓人，并且确实发挥了很大的作用（解决了ABA问题）。所以并没有那么可怕，就让我们一起来克服困难吧。 1 AtomicReference简介AtomicReference的使用非常简单，首先我们来看一下他的方法： 构造函数： AtomicReference() //使用 null 初始值创建新的 AtomicReference。 AtomicReference(V initialValue) //使用给定的初始值创建新的 AtomicReference。 方法： boolean compareAndSet(V expect, V update) //如果当前值 == 预期值，则以原子方式将该值设置为给定的更新值。 V get() //获取当前值。 V getAndSet(V newValue) //以原子方式设置为给定值，并返回旧值。 void lazySet(V newValue) //最终设置为给定值。 void set(V newValue) //设置为给定值。 String toString() //返回当前值的字符串表示形式。 boolean weakCompareAndSet(V expect, V update) // 如果当前值 == 预期值，则以原子方式将该值设置为给定的更新值。 下面我们看一个例子来了解下使用方法： 1234567891011121314151617public class AtomicReferenceTest &#123; public static void main(String[] args) &#123; AtomicReference atomic1 = new AtomicReference(); atomic1.set("aaa"); atomic1.set(new StringBuffer("str")); Map map = new HashMap(); map.put("name","xiaoming"); atomic1.set(map); System.out.println(atomic1.get()); String[] s = &#123;"aa","bb","cc"&#125;; AtomicReference atomic2 = new AtomicReference(s); System.out.println(atomic2.get()); atomic2.set(atomic1); System.out.println(atomic2.get()); &#125;&#125; 输出结果： {name=xiaoming} [Ljava.lang.String;@766e119d {name=xiaoming} Process finished with exit code 0 由上面程序我们可以看到：AtomicReference可以set任何类型的值并且都是以原子的形式操作的。 2 CAS和ABA在介绍AtomicStampedRerence, AtomicMarkableReference之前我们的先谈一谈CAS和ABA的问题，因为这两个类的设计就是为了避免CAS操作中的ABA问题而设计的. 2.1 CAS 原子操作的基石我们知道之前我们学过的Synchronized是一种独占锁。一个线程获得该锁，那么其余的线程只能等待该线程释放锁才能获得。这其实是一种悲观锁的形式。那么乐观锁是如何实现的呢？乐观锁是每次都不加锁，假设完成某项任务没有冲突。如果因为冲突失败那就重试，直到成功为止。 今天我们要说的CAS就是乐观锁的实现机制。可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性产生的数据不一致问题。 该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值。 CAS:Compare and Swap，这个操作用C语言来描述就是下面这个样子（代码来自Wikipedia的Compare And Swap词条）： 1234567int compare_and_swap (int* reg, int oldval, int newval)&#123; int old_reg_val = *reg; if (old_reg_val == oldval) *reg = newval; return old_reg_val;&#125; 意思就是说，看一看内存*reg里的值是不是oldval，如果是的话，则对其赋值newval。 CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。 在使用上，通常会记录下某块内存中的旧值，通过对旧值进行一系列的操作后得到新值，然后通过CAS操作将新值与旧值进行交换。如果这块内存的值在这期间内没被修改过，则旧值会与内存中的数据相同，这时CAS操作将会成功执行 使内存中的数据变为新值。如果内存中的值在这期间内被修改过，则一般来说旧值会与内存中的数据不同，这时CAS操作将会失败，新值将不会被写入内存。 2.2 原子操作虽然我们是在用java语言去执行原子操作，但是最终还是对应到处理器上去执行。那么在处理器上是如何执行原子操作的呢？ 32位IA-32处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。 第一个机制是通过总线锁保证原子性。。如果多个处理器同时对共享变量进行读改写（i++就是经典的读改写操作）操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致，举个例子：如果i=1,我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2。 原因是有可能多个处理器同时从各自的缓存中读取变量i，分别进行加一操作，然后分别写入系统内存当中。那么想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。 处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住,那么该处理器可以独占使用共享内存。 第二个机制是通过缓存锁定保证原子性。在同一时刻我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，最近的处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。 上面说了cpu的原子操作是如何实现的，那么在java中一定也有相应的方法去驱动处理器来实现原子操作。JUC包中的原子类都是基于CAS来实现的，我们不妨以AtomicInteger为例来跟踪一下，看看到底是如何实现原子操作的。 首先我们能看到在AtomicInteger中的value值是这样定义的： 1private volatile int value; 我们再来看他的get方法： 123public final int get() &#123; return value;&#125; 直接返回value值，说明在无锁的情况下，通过volatile来做控制，保证值是可见的。 下面我们接着看一下i++在原子类中是怎么实现的： 1234567public final int getAndSet(int newValue) &#123; for (;;) &#123; int current = get(); if (compareAndSet(current, newValue)) return current; &#125;&#125; 能看到，首先把volatile修饰的内存中的原始值赋值给当前变量，为了下面compareAndSet方法拿内存中的值和新值比较进行CAS操作。所以关键就在于这个compareAndSet（）方法，我们接着进入这个方法： 123public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 我们看到compareAndSet方法中返回的是unsafe类的方法，我们知道java不能直接访问操作系统底层，而是通过本地方法来访问。Unsafe类提供了硬件级别的原子操作，这就与硬件相挂钩了。由此我们从java到处理器的通道就打通了。 具体的compareAndSwapInt()方法的实现属于JDK底层的实现，我们在此不多做说明，有兴趣的可以查阅相关资料，看java的底层c语言源码。大致的过程我们可以说明如下：CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。” Java并发包(java.util.concurrent)中大量使用了CAS操作,涉及到并发的地方都调用了sun.misc.Unsafe类方法进行CAS操作。 2.3 ABA问题上面我们结合着处理器对原子操作的处理机制一起讲了java对原子操作的处理方式，那么难道这种方式就一定是完美的吗。下面我们举出一种情况大家分析看看： 进程P1在共享变量中读到值为A P1被抢占了，进程P2执行 P2把共享变量里的值从A改成了B，再改回到A，此时被P1抢占。 P1回来看到共享变量里的值没有被改变，于是继续执行。 你觉得这会出现什么问题呢？我们知道java底层代码都是用c语言实现的，虽然java中没有指针，但不代表java底层代码中没有使用。虽然P1以为变量值没有改变，继续执行了，但是这个会引发一些潜在的问题。ABA问题最容易发生在lock free 的算法中的，CAS首当其冲，因为CAS判断的是指针的地址（c语言的特性）。如果这个地址被重用了呢，问题就很大了。 现有一个用单向链表实现的堆栈，栈顶为A，这时线程T1已经知道A.next为B，然后希望用CAS将栈顶替换为B: 在T1执行上面这条指令之前，线程T2介入，将A、B出栈，再pushD、C、A，此时堆栈结构如下图，而对象B此时已经出栈： 在CAS中c语言的堆栈实现过程大致如下： 123456789101112131415161718push(node): curr := head old := curr node-&gt;next = curr while (old != (curr = CAS(&amp;head, curr, node))) &#123; old = curr node-&gt;next = curr &#125;pop(): curr := head old := curr next = curr-&gt;next while (old != (curr = CAS(&amp;head, curr, next))) &#123; old = curr next = curr-&gt;next &#125; return curr 假如，在pop函数中，next = curr-&gt;next 和 while之间，线程被切换走，此时轮到线程T1执行CAS操作，检测发现栈顶仍为A，所以CAS成功，栈顶变为B，但实际上B.next为null，即while此时还没有执行呢，所以此时的情况变为： 其中堆栈中只有B元素的引用地址，C和D组成的链表不再存在于堆栈中，平白无故就把C、D丢掉了。 如果这个例子你没有看懂的话，我可以再举出一个生活中的例子： 你拿着一个装满钱的手提箱在飞机场，此时过来了一个火辣性感的美女，然后她很暖昧地挑逗着你，并趁你不注意的时候，把用一个一模一样的手提箱和你那装满钱的箱子调了个包，然后就离开了，你看到你的手提箱还在那，于是就提着手提箱去赶飞机去了。 以上就是ABA问题。 3 解决ABA问题之道因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。 为了避免CAS过程中的ABA问题，并发包提供了两个类，AtomicStampedReference和AtomicMarkableReference。前者相当于一个[引用,integer]的二元组，后者相当于一个[引用,boolean]的二元组。AtomicStampedReference可用来作为带版本号的原子引用，而AtomicMarkableReference可用于表示已删除的节点。 这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 我们先来看一下AtomicStampedReference的方法，AtomicStampedReference 维护带有整数“标志”的对象引用，可以用原子方式对其进行更新： 构造方法： AtomicStampedReference(V initialRef, int initialStamp) //创建具有给定初始值的新 AtomicStampedReference 方法： boolean attemptStamp(V expectedReference, int newStamp) //如果当前引用 == 预期引用，则以原子方式将该标志的值设置为给定的更新值。 boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) //如果当前引用 == 预期引用，并且当前标志等于预期标志， 则以原子方式将该引用和该标志的值设置为给定的更新值。 V get(int[] stampHolder) //返回该引用和该标志的当前值。 V getReference() //返回该引用的当前值。 int getStamp() // 返回该标志的当前值。 void set(V newReference, int newStamp) // 无条件地同时设置该引用和标志的值。 boolean weakCompareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) //如果当前引用 == 预期引用，并且当前标志等于预期标志，则以原子方式将该引用和该标志的值设置为给定的更新值。 看来看一下AtomicMarkableReference的方法： 构造方法： AtomicMarkableReference(V initialRef, boolean initialMark) //创建具有给定初始值的新 AtomicMarkableReference。 方法： boolean attemptMark(V expectedReference, boolean newMark) //如果当前引用 == 预期引用，则以原子方式将该标记的值设置为给定的更新值。 boolean compareAndSet(V expectedReference, V newReference, boolean expectedMark, boolean newMark) //如果当前引用 == 预期引用，并且当前标记等于预期标记，那么以原子方式将引用和标记的值设置为给定的更新值。 V get(boolean[] markHolder) // 返回该引用和该标记的当前值。 V getReference() //返回该引用的当前值。 boolean isMarked() //返回该标记的当前值。 void set(V newReference, boolean newMark) //无条件地同时设置该引用和标记的值。 boolean weakCompareAndSet(V expectedReference, V newReference, boolean expectedMark, boolean newMark) //如果当前引用 == 预期引用，并且当前标记等于预期标记，那么以原子方式将引用和标记的值设置为给定的更新值。 AtomicMarkableReference类描述的一个(Object,Boolean)的对，可以原子的修改Object或者Boolean的值，这种数据结构在一些缓存或者状态描述中比较有用。这种结构在单个或者同时修改Object/Boolean的时候能够有效的提高吞吐量。 AtomicStampedReference类维护带有整数“标志”的对象引用，可以用原子方式对其进行更新。对比AtomicMarkableReference类的(Object,Boolean)，AtomicStampedReference维护的是一种类似(Object,int)的数据结构，其实就是对对象（引用）的一个并发计数。但是与AtomicInteger不同的是，此数据结构可以携带一个对象引用（Object），并且能够对此对象和计数同时进行原子操作。 下面我们就AtomicStampedReference 的使用举一个例子： 1234567891011121314151617181920212223242526public class AtomicStampedReferenceTest &#123; public static void main(String[] args) &#123; AtomicInteger atomicInt = new AtomicInteger(100); atomicInt.compareAndSet(100, 101); atomicInt.compareAndSet(101, 100); System.out.println("new value = " + atomicInt.get()); boolean result1 = atomicInt.compareAndSet(100, 101); System.out.println(result1); // result:true AtomicInteger v1 = new AtomicInteger(100); AtomicInteger v2 = new AtomicInteger(101); AtomicStampedReference&lt;AtomicInteger&gt; stampedRef = new AtomicStampedReference&lt;AtomicInteger&gt;(v1, 0); int stamp = stampedRef.getStamp(); stampedRef.compareAndSet(v1, v2, stampedRef.getStamp(), stampedRef.getStamp() + 1); System.out.println(stampedRef.getStamp()); stampedRef.compareAndSet(v2, v1, stampedRef.getStamp(), stampedRef.getStamp() + 1); System.out.println("new value = " + stampedRef.getReference()); boolean result2 = stampedRef.compareAndSet(v1, v2, stamp, stamp + 1); System.out.println(result2); // result:false &#125;&#125; 输出结果为： new value = 100 true 1 new value = 100 false Process finished with exit code 0 上面的输出结果可以看到AtomicInteger 执行cas操作成功，AtomicStampedReference执行cas操作失败。我们可以看到在24行compareAndSet(v1, v2, stamp, stamp + 1)中第三个参数期待的标志位值为1，但是经过上面两次的值变更，stampedRef.getStamp()已经是2了，所以此刻期待值与内存中的标志位值不符，操作失败。 AtomicMarkableReference的使用方法也是类似，在此就不另做介绍，大家可以多多使用才会知道这些类所带来的好处。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（十二）----(JUC原子类)数组类型介绍]]></title>
    <url>%2Fposts%2Ff9388b3f.html</url>
    <content type="text"><![CDATA[上一节我们介绍过三个基本类型的原子类，这次我们来看一下数组类型： AtomicIntegerArray, AtomicLongArray, AtomicReferenceArray。其中前两个的使用方式差不多，AtomicReferenceArray因为他的参数为引用数组，所以跟前两个的使用方式有所不同。 1 AtomicLongArray介绍对于AtomicLongArray, AtomicIntegerArray我们还是只介绍一个，另一个使用方式大同小异。 我们先来看看AtomicLongArray的构造函数和方法： 构造函数： AtomicLongArray(int length) //创建给定长度的新 AtomicLongArray。 AtomicLongArray(long[] array) //创建与给定数组具有相同长度的新 AtomicLongArray，并从给定数组复制其所有元素。 方法： long addAndGet(int i, long delta) //以原子方式将给定值添加到索引 i 的元素。 boolean compareAndSet(int i, long expect, long update) //如果当前值 == 预期值，则以原子方式将该值设置为给定的更新值。 long decrementAndGet(int i) //以原子方式将索引 i 的元素减1。 long get(int i) //获取位置 i 的当前值。 long getAndAdd(int i, long delta) //以原子方式将给定值与索引 i 的元素相加。 long getAndDecrement(int i) //以原子方式将索引 i 的元素减 1。 long getAndIncrement(int i) //以原子方式将索引 i 的元素加 1。 long getAndSet(int i, long newValue) //以原子方式将位置 i 的元素设置为给定值，并返回旧值。 long incrementAndGet(int i) // 以原子方式将索引 i 的元素加1。 void lazySet(int i, long newValue)// 最终将位置 i 的元素设置为给定值。 int length() //返回该数组的长度。 void set(int i, long newValue) //将位置 i 的元素设置为给定值。 String toString() //返回数组当前值的字符串表示形式。 2 使用方式：我们可以发现AtomicLongArray的使用方式和上一篇介绍的基本类型的原子类差不多，无非是换成了数组类型，另外方法里面的etAndAdd与ncrementAndGet我们要注意使用方式。 3 AtomicReferenceArray介绍我们来看一下他的方法： 构造方法： AtomicReferenceArray(E[] array) //创建与给定数组具有相同长度的新 AtomicReferenceArray，并从给定数组复制其所有元素。 AtomicReferenceArray(int length) // 创建给定长度的新 AtomicReferenceArray。 方法: boolean compareAndSet(int i, E expect, E update) //如果当前值 == 预期值，则以原子方式将位置 i 的元素设置为给定的更新值。 E get(int i) //获取位置 i 的当前值。 E getAndSet(int i, E newValue) // 以原子方式将位置 i 的元素设置为给定值，并返回旧值。 void lazySet(int i, E newValue) //最终将位置 i 的元素设置为给定值。 int length() //返回该数组的长度。 void set(int i, E newValue) // 将位置 i 的元素设置为给定值。 String toString() //返回数组当前值的字符串表示形式。 boolean weakCompareAndSet(int i, E expect, E update) // 如果当前值 == 预期值，则以原子方式将位置 i 的元素设置为给定的更新值。 由上我们可以看到AtomicReferenceArray与前两个的方法相比少了很多。 下面我们通过一个小例子来看一下他的使用： 1234567891011121314151617public class AtomicReferenceArrayTest &#123; public static void main(String[] args) &#123; Long[] l = new Long[4]; String[] s = new String[4]; int[] i = new int[4]; Integer[] in = new Integer[4]; AtomicReferenceArray atomicReferenceArray = new AtomicReferenceArray(l); System.out.println(atomicReferenceArray.length()); System.out.println(atomicReferenceArray.get(2)); AtomicReferenceArray atomic = new AtomicReferenceArray(4); atomic.set(0,432141); atomic.set(2,"fsafefeq"); atomic.set(3,i); System.out.println(atomic.toString()); &#125;&#125; 输出结果为： exclude patterns: 4 null [432141, null, fsafefeq, [I@357b2b99] Process finished with exit code 0 说明： 1.当我们使用AtomicReferenceArray(E[] array)这个构造方法传入一个数组对象时，该数组对象必须是引用类型，int[]不可以，但是Integer[]的可以。 2.当我们使用AtomicReferenceArray(int length)这个构造函数的时候，只要为他指定了数组大小之后，你为数组的每一位设置什么值是没有要求的，类似于Map的形式。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（十一）----(JUC原子类)基本类型介绍]]></title>
    <url>%2Fposts%2F8ca24763.html</url>
    <content type="text"><![CDATA[上一节我们说到了基本原子类的简单介绍，这一节我们先来看一下基本类型: AtomicInteger, AtomicLong, AtomicBoolean。AtomicInteger和AtomicLong的使用方法差不多，AtomicBoolean因为比较简单所以方法比前两个都少，那我们这节主要挑AtomicLong来说，会使用一个，其余的大同小异。 1 原子操作与一般操作异同我们在说原子操作之前为了有个对比为什么需要这些原子类而不是普通的基本数据类型就能满足我们的使用要求，那就不得不提原子操作不同的地方。 当你在操作一个普通变量时，你在Java实现的每个操作，在程序编译时会被转换成几个机器能读懂的指令。例如，当你分配一个值给变量，在Java你只使用了一个指令，但是当你编译这个程序时，这个指令就被转换成多个JVM 语言指令。这样子的话当你在操作多个线程且共享一个变量时，就会导致数据不一致的错误。 为了避免这样的问题，Java引入了原子变量。当一个线程正在操作一个原子变量时，即使其他线程也想要操作这个变量，类的实现中含有一个检查那步骤操作是否完成的机制。 基本上，操作获取变量的值，改变本地变量值，然后尝试以新值代替旧值。如果旧值还是一样，那么就改变它。如果不一样，方法再次开始操作。这个操作称为 Compare and Set（简称CAS，比较并交换的意思）。 原子变量不使用任何锁或者其他同步机制来保护它们的值的访问。他们的全部操作都是基于CAS操作。它保证几个线程可以同时操作一个原子对象也不会出现数据不一致的错误，并且它的性能比使用受同步机制保护的正常变量要好。 2 AtomicLong简介由字面意义我们可以知道AtomicLong可以用原子方式更新的 long 值，下面我们看一下他的构造方法和一般方法： 构造方法： AtomicLong() //创建具有初始值 0 的新 AtomicLong。 AtomicLong(long initialValue) //创建具有给定初始值的新 AtomicLong。 方法： long addAndGet(long delta) //以原子方式将给定值添加到当前值。 boolean compareAndSet(long expect, long update) //如果当前值 == 预期值，则以原子方式将该值 设置为给定的更新值。 long decrementAndGet() //以原子方式将当前值减 1。 double doubleValue() //以 double 形式返回指定的数值。 float floatValue() //以 float 形式返回指定的数值。 long get() //获取当前值。 long getAndAdd(long delta) //以原子方式将给定值添加到当前值。 long getAndDecrement() //以原子方式将当前值减 1。 long getAndIncrement() //以原子方式将当前值加 1。 long getAndSet(long newValue)// 以原子方式设置为给定值，并返回旧值。 long incrementAndGet() //以原子方式将当前值加 1。 int intValue() // 以 int 形式返回指定的数值。 void lazySet(long newValue) //最后设置为给定值。 long longValue() // 以 long 形式返回指定的数值。 void set(long newValue) //设置为给定值。 String toString() // 返回当前值的字符串表示形式。 boolean weakCompareAndSet(long expect, long update) //如果当前值 == 预期值，则以原子方式将该值设置为给定的更新值。 3 使用AtomicLong3.1 创建AtomicLong创建AtomicLong的过程如下： 1AtomicLong atomicLong = new AtomicLong（）; 此示例创建一个初始值为0的AtomicLong 。 如果你想创建一个带有初始值的AtomicLong ，你可以这样做： 1AtomicLong atomicLong = new AtomicLong（123）; 此示例将值123作为参数传递给AtomicLong装订器，该装置将AtomicLong实例的初始值设置为123 。 3.2 获取AtomicLong值您可以通过get()方法get() AtomicLong实例的值。 这里是一个AtomicLong.get()示例： 12AtomicLong atomicLong = new AtomicLong（123）;long theValue = atomicLong.get（）; 设置AtomicLong值 您可以通过set()方法set() AtomicLong实例的值。 这里是一个AtomicLong.set()示例： 123AtomicLong atomicLong = new AtomicLong（123）; atomicLong.set（234）; 此示例创建一个初始值为123的AtomicLong示例，然后在下一行中将其值设置为234 。 3.3 比较并设置AtomicLong值AtomicLong类也有一个原子compareAndSet()方法。 此方法将AtomicLong实例的当前值与AtomicLong进行比较，如果这两个值相等， AtomicLong实例设置新值。 这里是一个AtomicLong.compareAndSet()示例： 1234AtomicLong atomicLong = new AtomicLong（123）;long expectedValue = 123;long newValue = 234;atomicLong.compareAndSet（expectedValue，newValue）; 此示例首先创建一个初始值为123的AtomicLong实例。 然后，它将AtomicLong的值与期望值123进行比较，如果它们相等，则AtomicLong的新值变为234 ; 3.4 添加到AtomicLong值AtomicLong类包含几个方法，您可以使用这些方法向AtomicLong添加值并返回其值。这里我们要重点关注一下，因为这几个方法会如果我们使用不当会造成歧义。 这些方法是： addAndGet() getAndAdd() getAndIncrement() incrementAndGet() 第一种方法addAndGet()向AtomicLong添加一个数字，并在添加后返回其值。 第二种方法getAndAdd()还向AtomicLong添加一个数字，但返回AtomicLong在添加值之前的值。 您应该使用这两种方法中的哪一种取决于您的用例。 这里有两个例子： 123AtomicLong atomicLong = new AtomicLong（）;System.out.println（atomicLong.getAndAdd（10））;System.out.println（atomicLong.addAndGet（10））; 此示例将打印出值0和20 。 首先，示例在添加10之前获取AtomicLong的值。 它的值在加法之前为0.然后示例将10添加到AtomicLong ，并获取添加后的值。 该值现在为20。 您也可以通过这两种方法向AtomicLong添加负数。 结果实际上是一个减法。 方法getAndIncrement()和incrementAndGet()工作原理像getAndAdd()和addAndGet()但只是添加1到AtomicLong的值。 3.5 从AtomicLong值中减去AtomicLong类还包含一些用于从AtomicLong值中以AtomicLong值的方法。 这些方法是： decrementAndGet() getAndDecrement() decrementAndGet()从AtomicLong值中减去1，并在AtomicLong后返回其值。 getAndDecrement()也从AtomicLong值中减去1，但返回AtomicLong在AtomicLong之前的值。 由上我们大致知道了AtomicLong的用法，AtomicBoolean，AtomicInteger也与它的用法差不多，我们看一下API他们各自的方法就知道该如何使用。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（十）----JUC原子类介绍]]></title>
    <url>%2Fposts%2Fdb147845.html</url>
    <content type="text"><![CDATA[今天我们来看一下JUC包中的原子类，所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程），原子操作可以是一个步骤，也可以是多个操作步骤，但是其顺序不可以被打乱，也不可以被切割而只执行其中的一部分。将整个操作视作一个整体是原子性的核心特征。 在atomic包中的这些原子类我们可以大致给他分类为： 基本类型: AtomicInteger, AtomicLong, AtomicBoolean ; 数组类型: AtomicIntegerArray, AtomicLongArray, AtomicReferenceArray ; 引用类型: AtomicReference, AtomicStampedRerence, AtomicMarkableReference ; 对象的属性修改类型: AtomicIntegerFieldUpdater, AtomicLongFieldUpdater, AtomicReferenceFieldUpdater 。 下一节我们详细的分析这些原子类。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（九）----(JUC)CyclicBarrier]]></title>
    <url>%2Fposts%2Ff5e73779.html</url>
    <content type="text"><![CDATA[上一篇我们介绍了CountDownlatch，我们知道CountDownlatch是“在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待”，即CountDownLatch的作用是允许1或N个线程等待其他线程完成执行，而我们今天要介绍的CyclicBarrier则是允许N个线程相互等待。 1 CyclicBarrier简介CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。 在JDK中对CyclicBarrier是这样说的“允许一组线程全部等待彼此到达公共屏障点的同步辅助。 循环障碍在涉及必须偶尔彼此等待的固定大小的线程程序中是有用的。屏障称为循环 ，因为它可以在等待线程释放后重新使用”。CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。 我们先来看一下他的构造方法和使用方式： 构造函数： CyclicBarrier(int parties) //其参数表示屏障拦截的线程数量，每个线程调用await方法告 诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。 CyclicBarrier (int parties, Runnable barrierAction) //创建一个新的CyclicBarrier ， 当给定数量的参与者（线程）等待它时，它将跳闸，当障碍跳闸时，它 将执行 给定的障碍动作(Runnable参数提供)，由最后一个线程进入障碍。 方法： int await() //在所有参与者都已经在此 barrier 上调用 await 方法之前，将一直等待。 方法之前将一直等待,或者超出了指定的等待时间。 int getNumberWaiting() //返回当前在屏障处等待的参与者数目。 int getParties() //返回要求启动此 barrier 的参与者数目。 boolean isBroken() //查询此屏障是否处于损坏状态。 void reset() //将屏障重置为其初始状态。 下面我们来看一个小程序了解一下CyclicBarrier的使用方式： 123456789101112131415161718192021222324public class CyclicBarrierTest &#123; static CyclicBarrier c = new CyclicBarrier(2); public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; c.await(); &#125; catch (Exception e) &#123; &#125; System.out.println(Thread.currentThread().getName()+"正在等待..."); &#125; &#125;).start(); try &#123; c.await(); &#125; catch (Exception e) &#123; &#125; System.out.println(Thread.currentThread().getName()+"正在等待..."); System.out.println("人够了，出发吧 当前有 "+c.getParties()+" 个人参与比赛"); &#125;&#125; 输出结果为： Thread-0正在等待... main正在等待... 人够了，出发吧 当前有 2 个人参与比赛 Process finished with exit code 0 在上面程序中如果我们把”static CyclicBarrier c = new CyclicBarrier(2);”中的参数2修改为3的话改程序中的线程Thread-0和main则会一直等待下去，因为CyclicBarrier是让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，而这最后一个线程迟迟不来，所以屏障也不会被打开。 CyclicBarrier还提供一个更高级的构造函数CyclicBarrier(int parties, Runnable barrierAction)，用于在线程到达屏障时，优先执行barrierAction，方便处理更复杂的业务场景。我们来看一下示例： 12345678910111213141516171819202122232425262728293031public class CyclicBarrierTest &#123; static CyclicBarrier c = new CyclicBarrier(2,new PrioExecut()); public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; c.await(); &#125; catch (Exception e) &#123; &#125; System.out.println(Thread.currentThread().getName()+"正在等待..."); &#125; &#125;).start(); try &#123; c.await(); &#125; catch (Exception e) &#123; &#125; System.out.println(Thread.currentThread().getName()+"正在等待..."); System.out.println("人够了，出发吧 当前有 "+c.getParties()+" 个人参与比赛"); &#125;&#125; class PrioExecut implements Runnable&#123; @Override public void run() &#123; System.out.println("我会先跑5秒，不管你信不信！"); &#125;&#125; 执行结果为： 我会先跑5秒，不管你信不信！ Thread-0正在等待... main正在等待... 人够了，出发吧 当前有 2 个人参与比赛 Process finished with exit code 0 我们可以看到构造方法中的参数：new PrioExecut()中的线程会优先执行。 2 CyclicBarrier的应用场景CyclicBarrier可以用于多线程计算数据，最后合并计算结果的应用场景。比如在支付业务中，我们可以按照事先划分好的片区的形式来统计日收支流水，然后根据片区的计算结果，使用Runnable barrierAction来进行汇总这是一个很好的实现。 3 CyclicBarrier和CountDownLatch的区别在javadoc里面的描述是这样的： CountDownLatch: A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes. CyclicBarrier : A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point. 根据我的理解：对于CountDownLatch来说，重点是那个“一个线程”, 它在等待其余线程执行完毕他才能执行，而另外那N的线程在把“某个事情”做完之后可以继续等待，可以终止。比如上文说的跑步的例子，只有5位跑步者同时准备好了，裁判才能下令开始跑步；CyclicBarrier强调的是n个线程，大家相互等待，只要有一个没完成，所有人都得等着。 CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以使用reset() 方法重置。所以CyclicBarrier能处理更为复杂的业务场景，比如如果计算发生错误，可以重置计数器，并让线程们重新执行一次。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（七）----（JUC）ReadWriteLock]]></title>
    <url>%2Fposts%2Fde2aa32e.html</url>
    <content type="text"><![CDATA[前面我们已经分析过JUC包里面的Lock锁，ReentrantLock锁和semaphore信号量机制。Lock锁实现了比synchronized更灵活的锁机制，Reentrantlock是Lock的实现类，是一种可重入锁，都是每次只有一次线程对资源进行处理；semaphore实现了多个线程同时对一个资源的访问；今天我们要讲的ReadWriteLock锁将实现另外一种很重要的功能：读写分离锁。 假设你的程序中涉及到对一些共享资源的读和写操作，且写操作没有读操作那么频繁。在没有写操作的时候，两个线程同时读一个资源没有任何问题，所以应该允许多个线程能在同时读取共享资源。但是如果有一个线程想去写这些共享资源，就不应该再有其它线程对该资源进行读或写，也就是说：读-读能共存，读-写不能共存，写-写不能共存。这就需要一个读/写锁来解决这个问题。 1 ReadWriteLock简介我们在JUC包可以看到ReadWriteLock是一个接口，他有一个实现类：ReentrantReadWriteLock，先让我们对读写访问资源的条件做个概述： - 读取： 没有线程正在做写操作，且没有线程在请求写操作。 - 写入： 没有线程正在做读写操作。 如果某个线程想要读取资源，只要没有线程正在对该资源进行写操作且没有线程请求对该资源的写操作即可。同样当有线程想要写资源，但是此刻有线程正在读取资源，那么此刻写资源的操作是不能继续下去的。我们来看一个例子: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public class ReadWriteLockTest2 &#123; public static void main(String[] args) &#123; final int threadCount = 2; final ExecutorService exService = Executors.newFixedThreadPool(threadCount); final ScoreBoard scoreBoard = new ScoreBoard(); exService.execute(new ScoreUpdateThread(scoreBoard)); exService.execute(new ScoreHealthThread(scoreBoard)); exService.shutdown(); &#125;&#125; class ScoreBoard &#123; private boolean scoreUpdated = false; private int score = 0; String health = "不可用"; final ReentrantReadWriteLock rrwl = new ReentrantReadWriteLock(); public String getMatchHealth() &#123; rrwl.readLock().lock(); if (scoreUpdated) &#123; rrwl.readLock().unlock(); rrwl.writeLock().lock(); try &#123; if (scoreUpdated) &#123; score = fetchScore(); scoreUpdated = false; &#125; rrwl.readLock().lock(); &#125; finally &#123; rrwl.writeLock().unlock(); &#125; &#125; try &#123; if (score % 2 == 0) &#123; health = "Bad Score"; &#125; else &#123; health = "Good Score"; &#125; &#125; finally &#123; rrwl.readLock().unlock(); &#125; return health; &#125; public void updateScore() &#123; try &#123; rrwl.writeLock().lock(); scoreUpdated = true; &#125; finally &#123; rrwl.writeLock().unlock(); &#125; &#125; private int fetchScore() &#123; Calendar calender = Calendar.getInstance(); return calender.get(Calendar.MILLISECOND); &#125;&#125;class ScoreHealthThread implements Runnable &#123; private ScoreBoard scoreBoard; public ScoreHealthThread(ScoreBoard scoreTable) &#123; this.scoreBoard = scoreTable; &#125; @Override public void run() &#123; for(int i= 0; i&lt; 5; i++) &#123; System.out.println("Match Health: "+ scoreBoard.getMatchHealth()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;class ScoreUpdateThread implements Runnable &#123; private ScoreBoard scoreBoard; public ScoreUpdateThread(ScoreBoard scoreTable) &#123; this.scoreBoard = scoreTable; &#125; @Override public void run() &#123; for(int i= 0; i &lt; 5; i++) &#123; System.out.println("Score Updated."); scoreBoard.updateScore(); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 打印结果： Score Updated. Match Health: Good Score Score Updated. Match Health: Good Score Score Updated. Match Health: Good Score Score Updated. Match Health: Good Score Score Updated. Match Health: Good Score 基本用法见上例，读写分离锁很好的控制了多个线程对同一个资源的访问。 2 ReentrantReadWriteLock由名字我们可以看到读写锁也有可重入的实现类。ReentrantReadWriteLock具有关联的读取和写入锁定，可以重新获取锁定。它可表现为公平和不公平的模式两者。 默认行为是不公平的。 非公平锁的性能更好，虽然有可能读写器或写入器锁可以被推迟许多次，并且持续地尝试锁定。 在公平锁定的情况下，锁定请求按照最长等待的单个写入器锁或读取锁定组请求的顺序来完成，无论谁具有最长等待时间将获得对共享资源的锁定。 在重入ReentrantReadWriteLock可以写入锁定降级读锁。 这意味着如果线程已经获得写锁定，它可以将其锁从写降级到读锁。 顺序将是首先获得写锁定，执行写操作，然后获取读锁，然后解锁写锁，并且在读操作后最终解锁读锁。 ReentrantReadWriteLock 也是基于 AbstractQueuedSynchronizer 实现的，它具有下面这些属性： 获取顺序 此类不会将读取者优先或写入者优先强加给锁访问的排序。但是，它确实支持可选的公平 策略。 1.非公平模式（默认） 当非公平地（默认）构造时，未指定进入读写锁的顺序，受到 reentrancy 约束的限制。连续竞争的非公平锁可能无限期地推迟一个或多个 reader 或 writer 线程，但吞吐量通常要高于公平锁。 2.公平模式 当公平地构造线程时，线程利用一个近似到达顺序的策略来争夺进入。当释放当前保持的锁时，可以为等待时间最长的单个 writer 线程分配写入锁，如果有一组等待时间大于所有正在等待的 writer 线程 的 reader 线程，将为该组分配写入锁。 如果保持写入锁，或者有一个等待的 writer 线程，则试图获得公平读取锁（非重入地）的线程将会阻塞。直到当前最旧的等待 writer 线程已获得并释放了写入锁之后，该线程才会获得读取锁。当然，如果等待 writer 放弃其等待，而保留一个或更多 reader 线程为队列中带有写入锁自由的时间最长的 waiter，则将为那些 reader 分配读取锁。 试图获得公平写入锁的（非重入地）的线程将会阻塞，除非读取锁和写入锁都自由（这意味着没有等待线程）。（注意，非阻塞 ReentrantReadWriteLock.ReadLock.tryLock() 和 ReentrantReadWriteLock.WriteLock.tryLock() 方法不会遵守此公平设置，并将获得锁（如果可能），不考虑等待线程）。 重入 此锁允许 reader 和 writer 按照 ReentrantLock 的样式重新获取读取锁或写入锁。在写入线程保持的所有写入锁都已经释放后，才允许重入 reader 使用它们。 此外，writer 可以获取读取锁，但反过来则不成立。在其他应用程序中，当在调用或回调那些在读取锁状态下执行读取操作的方法期间保持写入锁时，重入很有用。如果 reader 试图获取写入锁，那么将永远不会获得成功。 锁降级 重入还允许从写入锁降级为读取锁，其实现方式是：先获取写入锁，然后获取读取锁，最后释放写入锁。但是，从读取锁升级到写入锁是不可能的。 锁获取的中断 读取锁和写入锁都支持锁获取期间的中断。 Condition 支持 写入锁提供了一个 Condition 实现，对于写入锁来说，该实现的行为与 ReentrantLock.newCondition() 提供的 Condition 实现对 ReentrantLock 所做的行为相同。当然，此 Condition 只能用于写入锁。读取锁不支持 Condition，readLock().newCondition() 会抛出 UnsupportedOperationException。 监测 此类支持一些确定是保持锁还是争用锁的方法。这些方法设计用于监视系统状态，而不是同步控制。 此类行为的序列化方式与内置锁的相同：反序列化的锁处于解除锁状态，无论序列化该锁时其状态如何。 下面的代码展示了如何利用重入来执行升级缓存后的锁降级（为简单起见，省略了异常处理）： 1234567891011121314151617181920212223242526class CachedData &#123; Object data; volatile boolean cacheValid; ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() &#123; rwl.readLock().lock(); if (!cacheValid) &#123; // 在获得写锁之前必须释放读锁 rwl.readLock().unlock(); rwl.writeLock().lock(); // Recheck state because another thread might have acquired // write lock and changed state before we did. if (!cacheValid) &#123; data = ... cacheValid = true; &#125; //通过在释放写锁之前获得读锁来降级 rwl.readLock().lock(); rwl.writeLock().unlock(); // 解锁写锁，但是任然持有读锁 &#125; use(data); rwl.readLock().unlock(); &#125;&#125; 3 与互斥锁对比互斥锁一次只允许一个线程访问共享数据，哪怕进行的是只读操作；读写锁允许对共享数据进行更高级别的并发访问：对于写操作，一次只有一个线程（write线程）可以修改共享数据，对于读操作，允许任意数量的线程同时进行读取。 与互斥锁相比，使用读写锁能否提升性能则取决于读写操作期间读取数据相对于修改数据的频率，以及数据的争用——即在同一时间试图对该数据执行读取或写入操作的线程数。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（七）----（JUC）ReadWriteLock]]></title>
    <url>%2Fposts%2Fde2aa32e.html</url>
    <content type="text"><![CDATA[CountDownLatch 是一个非常实用的多线程控制工具类。” Count Down “ 在英文中意为倒计数， Latch 为门问的意思。如果翻译成为倒计数门阀， 我想大家都会觉得不知所云吧! 因此，这里简单地称之为倒计数器。在这里， 门问的含义是:把门锁起来，不让里面的线程跑出来。因此，这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束， 再开始执行。 CountDown Latch 的构造函数接收一个整数作为参数，即当前这个计数器的计数个数。 1public CountDownLatch(int count) CountDownLatch是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。一个CountDownLatch初始化为给定的计数 。 调用await方法阻塞，直到当前计数为零，在调用countDown()方法之后，所有等待的线程被释放，任何后续调用await立即返回。 这是一次性的现象 - 计数不能重置。 如果需要重置计数，考虑使用CyclicBarrier ，CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。 主要方法： // 使当前线程在锁存器倒计数至零之前一直等待，除非线程被中断。 void await() // 使当前线程在锁存器倒计数至零之前一直等待，除非线程被中断或超出了指定的等待时间。 boolean await(long timeout, TimeUnit unit) // 递减锁存器的计数，如果计数到达零，则释放所有等待的线程。 void countDown() // 返回当前计数。 long getCount() 我们来看一个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class TestCountDownLatch &#123; private static final int RUNNER_NUMBER = 5; // 运动员个数 private static final Random RANDOM = new Random(); public static void main(String[] args) &#123; // 用于判断发令之前运动员是否已经完全进入准备状态，需要等待5个运动员，所以参数为5 CountDownLatch readyLatch = new CountDownLatch(RUNNER_NUMBER); // 用于判断裁判是否已经发令，只需要等待一个裁判，所以参数为1 CountDownLatch startLatch = new CountDownLatch(1); for (int i = 0; i &lt; RUNNER_NUMBER; i++) &#123; Thread t = new Thread(new Runner((i + 1) + "号运动员", readyLatch, startLatch)); t.start(); &#125; try &#123; readyLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; startLatch.countDown(); System.out.println("裁判：所有运动员准备完毕，开始..."); &#125; static class Runner implements Runnable &#123; private CountDownLatch readyLatch; private CountDownLatch startLatch; private String name; public Runner(String name, CountDownLatch readyLatch, CountDownLatch startLatch) &#123; this.name = name; this.readyLatch = readyLatch; this.startLatch = startLatch; &#125; public void run() &#123; int readyTime = RANDOM.nextInt(1000); System.out.println(name + "：我需要" + readyTime + "秒时间准备."); try &#123; Thread.sleep(readyTime); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(name + "：我已经准备完毕."); readyLatch.countDown(); try &#123; startLatch.await(); // 等待裁判发开始命令 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(name + "：开跑..."); &#125; &#125;&#125; 打印结果： 1号运动员：我需要547秒时间准备. 2号运动员：我需要281秒时间准备. 4号运动员：我需要563秒时间准备. 5号运动员：我需要916秒时间准备. 3号运动员：我需要461秒时间准备. 2号运动员：我已经准备完毕. 3号运动员：我已经准备完毕. 1号运动员：我已经准备完毕. 4号运动员：我已经准备完毕. 5号运动员：我已经准备完毕. 裁判：所有运动员准备完毕，开始... 3号运动员：开跑... 2号运动员：开跑... 1号运动员：开跑... 4号运动员：开跑... 5号运动员：开跑... Process finished with exit code 0 注意：计数器必须大于等于0，只是等于0时候，计数器就是零，调用await方法时不会阻塞当前线程。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（六）----（JUC）Semaphore]]></title>
    <url>%2Fposts%2F7afb7337.html</url>
    <content type="text"><![CDATA[Semaphore,从字面意义上我们知道他是信号量的意思。在java中，一个计数信号量维护了一个许可集。Semaphore 只对可用许可的号码进行计数，并采取相应的行动。拿到信号量的线程可以进入代码，否则就等待。通过acquire()和release()获取和释放访问许可。 信号量Semaphore是一个控制访问多个共享资源的计数器，它本质上是一个“共享锁”。 Java并发提供了两种加锁模式：共享锁和独占锁。前面介绍的ReentrantLock就是独占锁。对于独占锁而言，它每次只能有一个线程持有，而共享锁则不同，它允许多个线程并行持有锁，并发访问共享资源。 独占锁它所采用的是一种悲观的加锁策略， 对于写而言为了避免冲突独占是必须的，但是对于读就没有必要了，因为它不会影响数据的一致性。如果某个只读线程获取独占锁，则其他读线程都只能等待了，这种情况下就限制了不必要的并发性，降低了吞吐量。而共享锁则不同，它放宽了加锁的条件，采用了乐观锁机制，它是允许多个读线程同时访问同一个共享资源的。 举一个生活中的例子，有一条单行道路口有一红绿灯在正常的绿灯时间内如果骑车速度都很平均只能过去20辆车，这就意味着排在前面的20辆肯定能过去红绿灯，后面的就只能等下一个绿灯了。但是如果这个时候有车不想过去这个路口它驶向了边上别的路，那么后面的车就有机会。下面我们来看一个简单的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class TestSemaphore &#123; public static void main(String[] args) &#123; final Semaphore semaphore = new Semaphore(5); ExecutorService executorService = Executors.newCachedThreadPool(); for(int i = 0;i&lt;10;i++)&#123; int j = 0; executorService.submit(new A("car"+(j++),semaphore),"Thread"+(j++)); //new Thread(new A("car"+(j++),semaphore),"Thread"+(j++)).start(); if(i == 5)&#123; try &#123; Thread.sleep(1000); System.out.println("最后还有"+semaphore.availablePermits()+"个许可可用"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; System.out.println("最后还有"+semaphore.availablePermits()+"个许可可用"); &#125; &#125;class A implements Runnable&#123; String carName; private Semaphore semaphore; public A(String carName, Semaphore semaphore)&#123; this.carName = carName; this.semaphore = semaphore; &#125; public void getWay()&#123; System.out.println("this car is get the way" + Thread.currentThread().getName()); &#125; public void run() &#123; try &#123; if(semaphore.availablePermits() &gt; 0)&#123; semaphore.acquire(); getWay(); semaphore.release(); &#125;else&#123; System.out.println("请等待========"); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（五）----（JUC）ReentrantLock]]></title>
    <url>%2Fposts%2Fd68e6b33.html</url>
    <content type="text"><![CDATA[上一节我们了解了Lock接口的一些简单的说明，知道Lock锁的常用形式，那么这节我们正式开始进入JUC锁（java.util.concurrent包下的锁，简称JUC锁）。下面我们来看一下Lock最常用的实现类ReentrantLock。 1 ReentrantLock简介由单词意思我们可以知道这是可重入的意思。那么可重入对于锁而言到底意味着什么呢？简单来说，它有一个与锁相关的获取计数器，如果拥有锁的某个线程再次得到锁，那么获取计数器就加1，然后锁需要被释放两次才能获得真正释放。这模仿了 synchronized 的语义；如果线程进入由线程已经拥有的监控器保护的 synchronized 块，就允许线程继续进行，当线程退出第二个（或者后续） synchronized 块的时候，不释放锁，只有线程退出它进入的监控器保护的第一个 synchronized 块时，才释放锁。 1.1 公平锁与非公平锁我们查看ReentrantLock的源码可以看到无参构造函数是这样的： 123public ReentrantLock() &#123; sync = new NonfairSync();&#125; NonfairSync()方法为一个非公平锁的实现方法，另外Reentrantlock还有一个有参的构造方法： 123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 它允许您选择想要一个 公平（fair）锁，还是一个 不公平（unfair）锁。公平锁使线程按照请求锁的顺序依次获得锁；而不公平锁则允许直接获取锁，在这种情况下，线程有时可以比先请求锁的其他线程先得到锁。 为什么我们不让所有的锁都公平呢？毕竟，公平是好事，不公平是不好的，不是吗？（当孩子们想要一个决定时，总会叫嚷“这不公平”。我们认为公平非常重要，孩子们也知道。）在现实中，公平保证了锁是非常健壮的锁，有很大的性能成本。要确保公平所需要的记帐（bookkeeping）和同步，就意味着被争夺的公平锁要比不公平锁的吞吐率更低。作为默认设置，应当把公平设置为 false ，除非公平对您的算法至关重要，需要严格按照线程排队的顺序对其进行服务。 下面我们先来看一个例子： 12345678910111213141516171819202122232425262728public class TestReentrantLock implements Runnable&#123; ReentrantLock lock = new ReentrantLock(); public void get() &#123; lock.lock(); System.out.println(Thread.currentThread().getId()); set(); lock.unlock(); &#125; public void set() &#123; lock.lock(); System.out.println(Thread.currentThread().getId()); lock.unlock(); &#125; @Override public void run() &#123; get(); &#125; public static void main(String[] args) &#123; TestReentrantLock ss = new TestReentrantLock(); new Thread(ss).start(); new Thread(ss).start(); new Thread(ss).start(); &#125;&#125; 运行结果： 10 10 12 12 11 11 Process finished with exit code 0 由结果我们可以看出同一个线程进入了同一个ReentrantLock锁两次。 2 condition条件变量我们知道根类 Object 包含某些特殊的方法，用来在线程的 wait() 、 notify() 和 notifyAll() 之间进行通信。那么为了在对象上 wait 或 notify ，您必须持有该对象的锁。就像 Lock 是同步的概括一样， Lock 框架包含了对 wait 和 notify 的概括，这个概括叫作 条件（Condition）。 Condition 的方法与 wait 、 notify 和 notifyAll 方法类似，分别命名为 await 、 signal 和signalAll ，因为它们不能覆盖 Object 上的对应方法。 首先我们来计算一道题：我们要打印1到9这9个数字，由A线程先打印1，2，3，然后由B线程打印4,5,6，然后再由A线程打印7，8，9. 这道题有很多种解法，我们先用Object的wait，notify方法来实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class WaitNotifyDemo &#123; private volatile int val = 1; private synchronized void printAndIncrease() &#123; System.out.println(Thread.currentThread().getName() +"prints " + val); val++; &#125; // print 1,2,3 7,8,9 public class PrinterA implements Runnable &#123; @Override public void run() &#123; while (val &lt;= 3) &#123; printAndIncrease(); &#125; // print 1,2,3 then notify printerB synchronized (WaitNotifyDemo.this) &#123; System.out.println("PrinterA printed 1,2,3; notify PrinterB"); WaitNotifyDemo.this.notify(); &#125; try &#123; while (val &lt;= 6) &#123; synchronized (WaitNotifyDemo.this) &#123; System.out.println("wait in printerA"); WaitNotifyDemo.this.wait(); &#125; &#125; System.out.println("wait end printerA"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; while (val &lt;= 9) &#123; printAndIncrease(); &#125; System.out.println("PrinterA exits"); &#125; &#125; // print 4,5,6 after printA print 1,2,3 public class PrinterB implements Runnable &#123; @Override public void run() &#123; while (val &lt; 3) &#123; synchronized (WaitNotifyDemo.this) &#123; try &#123; System.out .println("printerB wait for printerA printed 1,2,3"); WaitNotifyDemo.this.wait(); System.out .println("printerB waited for printerA printed 1,2,3"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; while (val &lt;= 6) &#123; printAndIncrease(); &#125; System.out.println("notify in printerB"); synchronized (WaitNotifyDemo.this) &#123; WaitNotifyDemo.this.notify(); &#125; System.out.println("notify end printerB"); System.out.println("PrinterB exits."); &#125; &#125; public static void main(String[] args) &#123; WaitNotifyDemo demo = new WaitNotifyDemo(); demo.doPrint(); &#125; private void doPrint() &#123; PrinterA pa = new PrinterA(); PrinterB pb = new PrinterB(); Thread a = new Thread(pa); a.setName("printerA"); Thread b = new Thread(pb); b.setName("printerB"); // 必须让b线程先执行，否则b线程有可能得不到锁，执行不了wait，而a线程一直持有锁，会先notify了 b.start(); a.start(); &#125;&#125; 运行结果为： printerB wait for printerA printed 1,2,3 printerA prints 1 printerA prints 2 printerA prints 3 PrinterA printed 1,2,3; notify PrinterB wait in printerA printerB waited for printerA printed 1,2,3 printerB prints 4 printerB prints 5 printerB prints 6 notify in printerB notify end printerB wait end printerA printerA prints 7 printerA prints 8 printerA prints 9 PrinterA exits PrinterB exits. Process finished with exit code 0 我们来分析一下上面的程序： 首先在main方法中我们看到是先启动了B线程，因为B线程持有wait()对象，而A线程则持有notify(),如果先启动A有可能会造成死锁的状态。B线程启动以后进入run()方法： while (val &lt; 3) { synchronized (WaitNotifyDemo.this) { try { System.out.println(&quot;printerB wait for printerA printed 1,2,3&quot;); WaitNotifyDemo.this.wait(); System.out.println(&quot;printerB waited for printerA printed 1,2,3&quot;); } catch (InterruptedException e) { e.printStackTrace(); } } } while (val &lt;= 6) { printAndIncrease(); } 这里有一个while循环，如果val的值小于3，那么在WaitNotifyDemo的实例的同步块中调用WaitNotifyDemo.this.wait()方法，这里要注意无论是wait，还是notify，notifyAll方法都需要在其实例对象的同步块中执行，这样当前线程才能获得同步实例的同步控制权，如果不在同步块中执行wait或者notify方法会出java.lang.IllegalMonitorStateException异常。另外还要注意在wait方法两边的同步块会在wait执行完毕之后释放对象锁。 这样PrinterB就进入了等待状态，我们再看下PrinterA的run方法： 123456789101112131415161718192021while (val &lt;= 3) &#123; printAndIncrease(); &#125;// print 1,2,3 then notify printerBsynchronized (WaitNotifyDemo.this) &#123; System.out.println("PrinterA printed 1,2,3; notify PrinterB"); WaitNotifyDemo.this.notify();&#125;try &#123; while (val &lt;= 6) &#123; synchronized (WaitNotifyDemo.this) &#123; System.out.println("wait in printerA"); WaitNotifyDemo.this.wait(); &#125; &#125; System.out.println("wait end printerA");&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; 这里首先打印了1、2、3，然后在同步块中调用了WaitNotifyDemo实例的notify方法，这样PrinterB就得到了继续执行的通知，然后PrinterA进入等待状态，等待PrinterB通知。 我们再看下PrinterB run方法剩下的代码： 12345678910while (val &lt;= 6) &#123; printAndIncrease();&#125;System.out.println("notify in printerB");synchronized (WaitNotifyDemo.this) &#123; WaitNotifyDemo.this.notify();&#125;System.out.println("notify end printerB");System.out.println("PrinterB exits."); PrinterB首先打印了4、5、6，然后在同步块中调用了notify方法，通知PrinterA开始执行。 PrinterA得到通知后，停止等待，打印剩下的7、8、9三个数字，如下是PrinterA run方法中剩下的代码： 123while (val &lt;= 9) &#123; printAndIncrease();&#125; 整个程序就分析完了，下面我们再来使用Condition来做这道题： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class TestCondition &#123; static class NumberWrapper &#123; public int value = 1; &#125; public static void main(String[] args) &#123; //初始化可重入锁 final Lock lock = new ReentrantLock(); //第一个条件当屏幕上输出到3 final Condition reachThreeCondition = lock.newCondition(); //第二个条件当屏幕上输出到6 final Condition reachSixCondition = lock.newCondition(); //NumberWrapper只是为了封装一个数字，一边可以将数字对象共享，并可以设置为final //注意这里不要用Integer, Integer 是不可变对象 final NumberWrapper num = new NumberWrapper(); //初始化A线程 Thread threadA = new Thread(new Runnable() &#123; @Override public void run() &#123; //需要先获得锁 lock.lock(); try &#123; System.out.println("threadA start write"); //A线程先输出前3个数 while (num.value &lt;= 3) &#123; System.out.println(num.value); num.value++; &#125; //输出到3时要signal，告诉B线程可以开始了 reachThreeCondition.signal(); &#125; finally &#123; lock.unlock(); &#125; lock.lock(); try &#123; //等待输出6的条件 reachSixCondition.await(); System.out.println("threadA start write"); //输出剩余数字 while (num.value &lt;= 9) &#123; System.out.println(num.value); num.value++; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;); Thread threadB = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; lock.lock(); while (num.value &lt;= 3) &#123; //等待3输出完毕的信号 reachThreeCondition.await(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; try &#123; lock.lock(); //已经收到信号，开始输出4，5，6 System.out.println("threadB start write"); while (num.value &lt;= 6) &#123; System.out.println(num.value); num.value++; &#125; //4，5，6输出完毕，告诉A线程6输出完了 reachSixCondition.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;); //启动两个线程 threadB.start(); threadA.start(); &#125;&#125; 基本思路就是首先要A线程先写1，2，3，这时候B线程应该等待reachThredCondition信号，而当A线程写完3之后就通过signal告诉B线程“我写到3了，该你了”，这时候A线程要等嗲reachSixCondition信号，同时B线程得到通知，开始写4，5，6，写完4，5，6之后B线程通知A线程reachSixCondition条件成立了，这时候A线程就开始写剩下的7，8，9了。 我们可以看到上例中我们创建了两个Condition,在不同的情况下可以使用不同的Condition，与wait和notify相比提供了更细致的控制。 3 线程阻塞原语–LockSupport我们一再提线程、锁等概念，但锁是如果实现的呢？又是如何知道当前阻塞线程的又是哪个对象呢？LockSupport是JDK中比较底层的类，用来创建锁和其他同步工具类的基本线程阻塞原语。 java锁和同步器框架的核心 AQS: AbstractQueuedSynchronizer，就是通过调用 LockSupport .park()和 LockSupport .unpark()实现线程的阻塞和唤醒 的。 LockSupport 很类似于二元信号量(只有1个许可证可供使用)，如果这个许可还没有被占用，当前线程获取许可并继 续 执行；如果许可已经被占用，当前线 程阻塞，等待获取许可。LockSupport是针对特定线程来进行阻塞和解除阻塞操作的；而Object的wait()/notify()/notifyAll()是用来操作特定对象的等待集合的。LockSupport的两个主要方法是park()和Unpark()，我们来看一下他们的实现： 123456789101112131415public static void park(Object blocker) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); unsafe.park(false, 0L); setBlocker(t, null);&#125;public static void park() &#123; unsafe.park(false, 0L);&#125;public static void unpark(Thread thread) &#123; if (thread != null) unsafe.unpark(thread);&#125; 由源码我们可见在park方法内部首先获得当前线程然后阻塞当前线程，unpark方法传入一个可配置的线程来为该线程解锁。以“线程”作为方法的参数， 语义更清晰，使用起来也更方便。而wait/notify的实现使得“线程”的阻塞/唤醒对线程本身来说是被动的，要准确的控制哪个线程、什么时候阻塞/唤醒很困难， 要不随机唤醒一个线程（notify）要不唤醒所有的（notifyAll）。 下面我们来看一个例子： 1234567891011121314151617181920212223242526272829public class TestLockSupport &#123; public static Object u = new Object(); static ChangeObjectThread t1 = new ChangeObjectThread("t1"); static ChangeObjectThread t2 = new ChangeObjectThread("t2"); public static class ChangeObjectThread extends Thread &#123; public ChangeObjectThread(String name) &#123; super.setName(name); &#125; public void run() &#123; synchronized (u) &#123; System.out.println("in" + getName()); LockSupport.park(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; t1.start(); Thread.sleep(2000); t2.start(); LockSupport.unpark(t1); LockSupport.unpark(t2); t1.join(); t2.join(); &#125;&#125; 当我们把”LockSupport.unpark(t1);”这一句注掉的话我们会发现程序陷入死锁。而且我们看到再main方法中unpark是在t1和t2启动之后才执行，但是为什么t1启动之后，t2也启动了呢？注意，unpark函数可以先于park调用。比如线程B调用unpark函数，给线程A发了一个“许可”，那么当线程A调用park时，它发现已经有“许可”了，那么它会马上再继续运行。unpark函数为线程提供“许可(permit)”，线程调用park函数则等待“许可”。这个有点像信号量，但是这个“许可”是不能叠加的，“许可”是一次性的。比如线程B连续调用了三次unpark函数，当线程A调用park函数就使用掉这个“许可”，如果线程A再次调用park，则进入等待状态。 除了有定时阻塞的功能外,还支持中断影响,但是和其他接收中断函数不一样,他不会抛出InterruptedException异常,他只会默默的返回,但是我们可以从Thread.Interrupted()等方法获得中断标记.我们来看一个例子： 123456789101112131415161718192021222324252627282930public class TestLockSupport &#123; public static Object u = new Object(); static ChangeObjectThread t1 = new ChangeObjectThread("t1"); static ChangeObjectThread t2 = new ChangeObjectThread("t2"); public static class ChangeObjectThread extends Thread &#123; public ChangeObjectThread(String name) &#123; super.setName(name); &#125; public void run() &#123; synchronized (u) &#123; System.out.println("in " + getName()); LockSupport.park(); if (Thread.interrupted()) &#123; System.out.println(getName() + " 被中断了!"); &#125; &#125; System.out.println(getName() + " 执行结束"); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; t1.start(); Thread.sleep(100); t2.start(); t1.interrupt(); LockSupport.unpark(t2); &#125;&#125; 输出： in t1 t1 被中断了! t1 执行结束 in t2 t2 执行结束 Process finished with exit code 0 由run方法中的终端异常捕获我们可以看到线程在中断时并没有抛出异常而是正常执行下去了。关于LockSupport其实要介绍的东西还是很多，因为这个类实现了底层的一些方法，各种的锁实现都是这个基础上发展而来的。以后会专门用一个篇章来学习jdk内部的阻塞机制。说前面我们讲到Object的wait和notify，讲到Condition条件，讲到jdk中不对外部暴露的LockSupport阻塞原语，那么在JUC包中还有另外一个阻塞机制—信号量机制（Semaphore），下一节我们一起探讨一下。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（四）----（JUC）Lock锁初探]]></title>
    <url>%2Fposts%2Ff4331185.html</url>
    <content type="text"><![CDATA[首先我们来回忆一下上一节讲过的synchronized关键字，该关键字用于给代码段或方法加锁，使得某一时刻它修饰的方法或代码段只能被一个线程访问。那么试想，当我们遇到这样的情况：当synchronized修饰的方法或代码段因为某种原因（IO异常或是sleep方法）被阻塞了，但是锁有没有被释放，那么其他线程除了等待以外什么事都做不了。当我们遇到这种情况该怎么办呢？我们今天讲到的Lock锁将有机会为此行使他的职责。 1 为什么需要Locksynchronized 是Java 语言层面的，是内置的关键字；Lock 则是JDK 5 的J.U.C(java/util/currrent)包中出现的一个类，在使用时，synchronized 同步的代码块可以由JVM自动释放；Lock 需要程序员在finally块中手工释放；synchronized是比较古老的实现机制，设计较早，有一些功能上的限制： ——它无法中断一个正在等候获得锁的线程 ——也无法通过投票得到锁，如果不想等下去，也就没法得到锁。 ——同步还要求锁的释放只能在与获得锁所在的堆栈帧相同的堆栈帧中进行 而且对多线程环境中，使用synchronized后，线程要么获得锁，执行相应的代码，要么无法获得锁处于等待状态，对于锁的处理不灵活。而Lock提供了多种基于锁的处理机制，比如： void lock()，获取一个锁，如果锁当前被其他线程获得，当前的线程将被休眠。 boolean tryLock()，尝试获取一个锁，如果当前锁被其他线程持有，则返回false，不会使当前线程休眠。 boolean tryLock(long timeout,TimeUnit unit)，如果获取了锁定立即返回true，如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false。 void lockInterruptibly()，如果获取了锁定立即返回，如果没有获取锁定，当前线程处于休眠状态，直到或者锁定，或者当前线程被别的线程中断。 可见lock比synchronized提供了更细的粒度、更灵活的控制。 2 初探Lock在jdk1.5之后，并发包中新增了Lock接口(以及相关实现类)用来实现锁功能，其实真正的实现Lock接口的类就三个，ReentrantLock和ReentrantReadWriteLock的两个内部类（ReadLock和WriteLock实现了Lock的接口），下面我们来看一下Lock的类图： ReentrantLock：一个可重入的互斥锁，为lock接口的主要实现。 ReentrantReadWriteLock： ReadWriteLock、ReadWriteLock 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。 Semaphore：一个计数信号量。 Condition:锁的关联条件，目的是允许线程获取锁并且查看等待的某一个条件是否满足。 CyclicBarrier：一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点。 ①首先我们来看一下Lock的用法： 123456789Lock lock = new ReentrantLock();lock.lock();try&#123;//处理任务&#125;catch(Exception ex)&#123; &#125;finally&#123;lock.unlock(); //释放锁&#125; 正常使用Lock的用法最多就是这样，ReentrantLock是Lock的实现类们也是最常使用的。如果采用Lock，必须主动去释放锁，并且在发生异常时，不会自动释放锁。因此一般来说，使用Lock必须在try{}catch{}块中进行，并在finally块释放锁，以保证锁一定被被释放，防止死锁的发生。 ②我们也可以这样使用Lock： 123456789101112Lock lock = new ReentrantLock();if(lock.tryLock()) &#123; try&#123; //处理任务 &#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁 &#125; &#125;else &#123; //如果不能获取锁，则直接做其他事情 &#125; tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取）则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。 这一节我们简单了解一下Lock接口，由于Lock锁的内容实在是太多，包括互斥锁，公平锁，非公平锁，共享锁以及相关的条件机制，信号量机制等等，我会一点点的把他们都啃下来，下面才是我们的重头戏。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习(三）-Netty重要接口讲解]]></title>
    <url>%2Fposts%2Fd48afec7.html</url>
    <content type="text"><![CDATA[上一节我们写了一个HelloWorld，对于Netty的运行有了一定的了解，知道Netty是如何启动客户端和服务器端。这一节我们简要的讲解一下几个重要的接口，初步探讨Netty的运行机制，当然刚学Netty就深入原理肯定是很枯燥的，所以我们就点到为止。 1 ChannelPipeLine和ChannelHandler在上一篇中我们在ChannelInitializer类的initChannel方法中使用了ChannelPipeline，然后在ChannelPipeline中使用了handler来处理业务逻辑。 ChannelPipeline是ChannelHandler的容器，它负责ChannelHandler的管理和事件拦截与调度。Netty的ChannelPipeline和ChannelHandler机制类似于Servlet 和Filter 过滤器，这类拦截器实际上是职责链模式的一种变形，主要是为了方便事件的拦截和用户业务逻辑的定制。 Netty的channel运用机制和Filter过滤器机制一样，它将Channel 的数据管道抽象为ChannelPipeline. 消息在ChannelPipeline中流动和传递。ChannelPipeline 持有I/O事件拦截器ChannelHandler 的链表，由ChannelHandler 对I/0 事件进行拦截和处理，可以方便地通过新增和删除ChannelHandler 来实现小同的业务逻辑定制，不需要对已有的ChannelHandler进行修改，能够实现对修改封闭和对扩展的支持。 通过一张图我们来看一下他们之间的关系： 一个Channel中包含一个ChannelPipeline，用来处理Channel中的事件，一个ChannelPipeline中可以包含很多个handler，第二节的示例代码中我们也看到了，使用各种handler来处理通信信息。 同时我们也注意到在hadler中继承了ChannelInboundHandlerAdapter类并实现了他的一些方法，比如：channelRead，channelActive，channelInactive等等，我们看到这些方法中都有一个参数：ChannelHandlerContext ctx。这个ChannelHandlerContext就是handler的上下文对象，有了这个ChannelHandlerContext你就获得了一切，你可以获得通道，获得事件的控制权。 事实上，用户不需要自己创建pipeline，因为使用ServerBootstrap 或者Bootstrap 启动服务端或者客户端时， Netty 会为每个Channel 连接创建一个独立的pipeline。 12345678ChannelPipeline pipeline = socketChannel.pipeline();pipeline.addLast("framer", new DelimiterBasedFrameDecoder(8192,Delimiters.lineDelimiter()));pipeline.addLast("decoder", new StringDecoder());pipeline.addLast("encoder", new StringEncoder());// 客户端的逻辑pipeline.addLast("handler", new HelloWorldClientHandler()); ChannelPipeline 是线程安全的， 这意味着N个业务线程可以并发地操作ChannelPipeline而不存在多线程并发问题。但是，ChannelHandler却不是线程安全的，这意味着尽管ChannelPipeline 是线程去全的， 但是仍然需要自己保证ChannelHandler的线程安全。 Netty 中的事件分为inbound 事件和outbound 事件。inbound 事件通常由I/O线程触发，例如TCP 链路建立事件、链路关闭事件、读事件、异常通知事件等。Outbound 事件通常是I/O 用户主动发起的网络I/O 操作，例如用户发起的连接操作、绑定操作、消息发送等操作。 我们常用的inbound事件有： ChannelHandlerContext fireChannelRegistered() //channel注册事件 ChannelHandlerContext fireChannelActive() //channel激活事件 ChannelHandlerContext fireExceptionCaught(Throwable var1) //channel异常处理事件 ChannelHandlerContext fireUserEventTriggered(Object var1) //用户自定义事件 ChannelHandlerContext fireChannelRead(Object var1) //读事件 pipeline 中以fireXXX命名的方法都是从I/O 线程流向用户业务Handler的inbound 事件，它们的实现因功能而异，但是处理步骤类似： 调用HeadHandler对应的fireXXX 方法 执行事件相关的逻辑操作 常用的outbound事件有： ChannelFuture bind(SocketAddress var1, ChannelPromise var2) //绑定地址 ChannelFuture connect(SocketAddress var1, ChannelPromise var2) //连接服务器 ChannelFuture write(Object var1) //发送事件 ChannelHandlerContext flush() //刷新事件 上面我们说到事件，netty的事件机制是由前至后的，一般来说，都是一个channel的ChannnelActive方法中调用fireChannelActive来触发调用下一个handler中的ChannelActive方法，即你在ChannelPipeline中添加handler的时候，要在第一个handler的channelActive方法中调用fireChannelActive，以此来触发下一个事件。我们再来写一个案例说明一下： 客户端： 12345678910111213141516171819202122232425262728293031323334public class HWClient &#123; private int port; private String address; public HWClient(int port, String address) &#123; this.port = port; this.address = address; &#125; public void start()&#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new ClientChannelInitializer()); try &#123; ChannelFuture future = bootstrap.connect(address,port).sync(); future.channel().writeAndFlush("Hello Netty Server ,I am a common client"); future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HWClient client = new HWClient(7788,"127.0.0.1"); client.start(); &#125;&#125; 客户端ClientChannelInitializer： 1234567891011121314public class ClientChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast("decoder", new StringDecoder()); pipeline.addLast("encoder", new StringEncoder()); // 客户端的handler //先调用handler在ChannnelActive方法中调用fireChannelActive会激活handler1 pipeline.addLast("handler", new HWClientHandler()); pipeline.addLast("handler1", new BaseClientHandler()); &#125;&#125; 客户端handler： 123456789101112131415161718public class HWClientHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println("server say : "+msg.toString()); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("Handler1"); ctx.fireChannelActive(); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("Client is close"); &#125;&#125; 客户端的第二个handler： 12345678910111213public class BaseClientHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("Handler2"); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125;&#125; 服务端： 12345678910111213141516171819202122232425262728293031public class HWServer &#123; private int port; public HWServer(int port) &#123; this.port = port; &#125; public void start()&#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); ServerBootstrap server = new ServerBootstrap().group(bossGroup,workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ServerChannelInitializer()); try &#123; ChannelFuture future = server.bind(port).sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HWServer server = new HWServer(7788); server.start(); &#125;&#125; 服务端ServerChannelInitializer: 12345678910111213public class ServerChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); // 字符串解码 和 编码 pipeline.addLast("decoder", new StringDecoder()); pipeline.addLast("encoder", new StringEncoder()); // 自己的逻辑Handler pipeline.addLast("handler", new HWServerHandler()); &#125;&#125; 服务端handler： 1234567891011121314151617181920public class HWServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("channelActive"); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(ctx.channel().remoteAddress()+"===&gt;server: "+msg.toString()); ctx.write("received your msg"); ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; super.exceptionCaught(ctx, cause); ctx.close(); &#125;&#125; 我们启动服务端和客户端，会发现客户端的两个handler都通过了。 先调用HWClientHandler，打印出：HWClientHandler channelActive；继而调用了BaseClientHandler ，打印出：BaseClient1Handler channelActive.]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件和JMS介绍(一)]]></title>
    <url>%2Fposts%2Fc0d0b105.html</url>
    <content type="text"><![CDATA[在一个公司创立初期，他可能只有几个应用，系统之间的关联也不是那么大，A系统调用B系统就直接调用B提供的API接口；后来这个公司做大了，他一步步发展有了几十个系统，这时候A系统要调用B系统的接口，但是B系统前几天刚改了一下接口A并不知情。所以A发现调不通于是给B系统管理员打电话，小王啊，改了接口咋不告诉我呢。我还以为我们系统出错了呢。弄得小王一顿尴尬，我这自己改个东西还的通知这个通知那个的。 #### 1 中间件介绍我们看到上面的故事中的小王他真的是很累啊。自己修改一个接口还的给所有调用接口的系统管理员打电话告知API发生变化。说到这个问题啊，还是的说我们系统之间的耦合。对于一个小公司来说是无所谓，但是对于一个大公司这种情况简直是致命的。于是最近几年这些越来越大的互联网公司在这种挑战下提出了中间件这个概念：中间件在操作系统软件，网络和数据库之上，应用软件之下，总的作用是为处于自己上层的软件提供灵活的开发环境。因而中间件是指一类软件，是基于分布式处理的软件，最突出的特点是其网络通信功能。也可认为中间件是位于平台和应用之间的通用服务，这些服务具有标准的程序接口和协议。针对不同的操作系统和硬件平台，可以有符合接口和协议的多种实现。 ##### 1.1 中间件分类中间件可以分为六类： 1) 终端仿真/屏幕转换 2) 数据访问中间件（UDA） 3) 远程过程调用中间件（RPC） 4) 消息中间件（MOM） 5) 交易中间件（TPM） 6) 对象中间件 然而在实际应用中，一般将中间件分为两大类： 一类是底层中间件，用于支撑单个应用系统或解决一类问题，包括交易中间件、应用服务器、消息中间件、数据访问中间件等； 另一类是高层中间件，更多的用于系统整合，包括企业应用集成中间件、工作流中间件、门户中间件等，他们通常会与多个应用系统打交道，在系统中层次较高，并大多基于前一类的底层中间件运行。 终端仿真/屏幕转换 此类中间件用于实现客户机图形用户接口与已有的字符接口方式的服务器应用程序之间的互操作，应用与早期的大型机系统，现在已很少使用。 数据访问中间件 此类中间件是为了建立数据应用资源互操作的模式，对异构环境下的数据库或文件系统实现联接。 远程过程调用中间件 此类中间件可以使开发人员在需要时调用位于远端服务器上的过程，屏蔽了在调用过程中的通信细节。一个应用程序使用RPC来远程执行一个位于不同地址空间里的过程，在效果上看和执行本地调用相同。 交易中间件 此类中间件是专门针对联机交易系统而设计的。联机交易系统需要处理大量并发进程，处理并发涉及到操作系统，文件系统，编程语言，数据通信，数据库系统，系统管理，应用软件等。而交易中间件根据分布式交易处理的标准及参考模型，对资源管理，交易管理和应用进行了实现，从而使得基于交易中间件开发应用程序更为简单。交易中间件基本上只适用于联机交易系统，是一种较为专用的中间件。 消息中间件 此类中间件是指利用高效可靠的消息传递机制进行平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息排队模型，它可以在分布式环境下扩展进程间的通信。 消息中间件可以即支持同步方式，又支持异步方式。异步中间件比同步中间件具有更强的容错性，在系统故障时可以保证消息的正常传输。异步中间件技术又分为两类：广播方式和发布/订阅方式。由于发布/订阅方式可以指定哪种类型的用户可以接受哪种类型的消息，更加有针对性，事实上已成为异步中间件的非正式标准。目前主流的消息中间件产品有IBM的MQSeries，BEA的MessageQ和Sun的JMS等[1]。 对象中间件 传统的对象技术通过封装、继承及多态提供了良好的代码重用功能。但这些对象只存在与一个程序中，外界并不知道它们的存在，也无法访问它们。对象中间件提供了一个标准的构建框架，能使不同厂家的软件通过不同的地址空间，网络和操作系统实现交互访问。对象中间件的目标是为软件用户及开发者提供一种应用级的即插即用的互操作性。目前主流的对象中间件有OMG的CORBA，Microsoft 的COM以及IBM的SOM，Sun的RMI等。 中间件的特点 一般来讲，中间件具有以下一些特点：满足大量应用的需求，运行于多种硬件和操作系统平台，支持分布式计算，支持标准接口和协议。开发人员通过调用中间件提供的大量API，实现异构环境的通信，从而屏蔽异构系统中复杂的操作系统和网络协议。 由于标准接口对于可移植性和标准协议对于互操作性的重要性，中间件已成为许多标准化工作的主要部分。分布式应用软件借助中间件可以在不同的技术之间共享资源。 总的来说，中间件屏蔽了底层操作系统的复杂性，使程序开发人员面对一个简单而统一的开发环境，减少了程序设计的复杂性，将注意力集中与自己的业务上，不必再为程序在不同软件系统上的移植而重复工作，从而大大减少了技术上的负担。 2 消息中间件面向消息的中间件（MOM），提供了以松散耦合的灵活方式集成应用程序的一种机制。它们提供了基于存储和转发的应用程序之间的异步数据发送，即应用程序彼此不直接通信，而是与作为中介的MOM通信。MOM提供了有保证的消息发送（至少是在尽可能地做到这一点），应用程序开发人员无需了解远程过程调用（RPC）和网络/通信协议的细节。 消息队列技术是分布式应用间交换信息的一种技术。消息队列可驻留在内存或磁盘上,队列存储消息直到它们被用程序读走。通过消息队列，应用程序可独立地执行–它们不需要知道彼此的位置、或在继续执行前不需要等待接收程序接收此消息。在分布式计算环境中，为了集成分布式应用，开发者需要对异构网络环境下的分布式应用提供有效的通信手段。为了管理需要共享的信息，对应用提供公共的信息交换机制是重要的。设计分布式应用的方法主要有：远程过程调用(RPC)–分布式计算环境(DCE)的基础标准成分之一；对象事务监控(OTM)–基于CORBA的面向对象工业标准与事务处理(TP)监控技术的组合；消息队列(MessageQueue)–构造分布式应用的松耦合方法。 MOM将消息路由给应用程B，这样消息就可以存在于完全不同的计算机上，MOM负责处理网络通信。如果网络连接不可用，MOM会存储消息，直到连接变得可用时，再将消息转发给应用程序B。 灵活性的另一方面体现在，当应用程序A发送其消息时，应用程序B甚至可以不处于执行状态。MOM将保留这个消息，直到应用程序B开始执行并试着检索消息为止。这还防止了应用程序A因为等待应用程序B检索消息而出现阻塞。这种异步通信要求应用程序的设计与现在大多数应用程序不同，不过，对于时间无关或并行处理，它可能是一个极其有用的方法。 2.1 消息中间件的传递模式消息中间件一般有两种传递模式：点对点模式(P2P)和发布-订阅模式(Pub/Sub)。 点对点模式 Point-to-Point(P2P)我们很容易理解，即生产者和消费者之间的消息往来。 每个消息都被发送到特定的消息队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。 P2P的特点： 每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中)； 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列； 接收者在成功接收消息之后需向队列应答成功。 发布-订阅模式(Pub/Sub) 我们可以联想到卖报纸的过程：印刷厂把当天的报纸印好然后送到邮递员手里，邮递员风雨兼程的把报纸送到每一位订阅者手里。由此我们可以看到发布-订阅模式的一些特点： 每个消息可以有多个消费者； 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息，而且为了消费消息，订阅者必须保持运行的状态； 由上介绍我们可以看出这两种模式各有千秋，如果你需要点对点的发送消息那么使用P2P更专注，如果你是群发消息，显然pub/sub模式更适合。 3 基于多种协议的消息传递机制目前市场上对于网络消息传递的协议版本很多，不同的协议有不同的规范，我们在使用时要比对实现不同协议的产品。下面我们看一下目前主流的消息传递协议： 3.1 AMQP协议AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。AMQP协议是一种二进制协议，提供客户端应用与消息中间件之间异步、安全、高效地交互。 AMQP是一个应用层的异步消息传递协议，为面向消息的中间件而设计。其目的是通过协议使应用模块之间或应用程序与中间件等进行充分解耦。而在设计初期，AMQP的原始用途只是为金融界提供一个可以彼此协作的消息协议。现在已经有相当一部分遵循AMQP的服务器和客户端供使用。其中RabbitMQ是AMQP的一款开源标准实现。 支持所有消息中间件的功能：消息交换、文件传输、流传输、远程进程调用等。 AMQP的服务器(Broker)主要由交换器、消息、队列组成。Broker的主要功能是消息的路由和缓存。对于需要保障可靠性的消息，RabbitMQ可以将消息、队列和交换器的数据写入本地硬盘。而对于响应时间敏感的消息，RabbitMQ可以不配置持久化机制。 解决的问题： 1）信息的发送者和接收者如何维持这个连接，如果一方的连接中断，这期间的数据如何防止丢失？ 2）如何降低发送者和接收者的耦合度？ 3）如何让Priority高的接收者先接到数据？ 4）如何做到load balance？有效均衡接收者的负载？ 5）如何有效的将数据发送到相关的接收者？也就是说将接收者subscribe 不同的数据，如何做有效的filter。 6）如何做到可扩展，甚至将这个通信模块发到cluster上？ 7）如何保证接收者接收到了完整，正确的数据？ AMQP协议解决了以上的问题，而RabbitMQ实现了AMQP。 3.2 STOMP协议STOMP即Simple (or Streaming) Text Orientated Messaging Protocol，简单(流)文本定向消息协议。 它提供了一个可互操作的连接格式，允许STOMP客户端与任意STOMP消息代理（Broker）进行交互。STOMP协议由于设计简单，易于开发客户端，因此在多种语言和多种平台上得到广泛地应用。 STOMP协议的前身是TTMP协议（一个简单的基于文本的协议），专为消息中间件设计。 STOMP是一个非常简单和容易实现的协议，其设计灵感源自于HTTP的简单性。尽管STOMP协议在服务器端的实现可能有一定的难度，但客户端的实现却很容易。例如，可以使用Telnet登录到任何的STOMP代理，并与STOMP代理进行交互。 STOMP是除AMQP开放消息协议之外地另外一个选择, 实现了被用在JMS brokers中特定的有线协议，比如OpenWire。它仅仅是实现通用消息操作中的一部分，并非想要覆盖全面的消息API。 STOMP server就好像是一系列的目的地, 消息会被发送到这里。STOMP协议把目的地当作不透明的字符串，其语法是服务端具体的实现。 此外STOMP没有定义目的地的交付语义是什么，语义的目的地可以从服务器到服务器，甚至从目的地到目的地。这使得服务器有可创造性的语义，去支持STOMP。 STOMP client的用户代理可以充当两个角色(可能同时)： 作为生产者，通过SENDframe发送消息到server 作为消费者，发送SUBSCRIBEframe到目的地并且通过MESSAGEframe从server获取消息。 STOMP协议工作于TCP协议之上，使用了下列命令： SEND 发送 SUBSCRIBE 订阅 UNSUBSCRIBE 退订 BEGIN 开始 COMMIT 提交 ABORT 取消 ACK 确认 DISCONNECT 断开 目前最流行的STOMP消息代理是Apache ActiveMQ。 3.3 JMS协议JMS是Java Message Service的缩写，即Java消息服务。 在大型互联网中，我们采用消息中间件可以进行应用之间的解耦以及操作的异步，这是消息中间件两个最基础的特点，也正是我们所需要的。在此基础上，我们着重思考的是消息的顺序保证、扩展性、可靠性、业务操作与消息发送一致性，以及多集群订阅者等方面的问题。当然，这些我们要思考的东西，JMS都已经想到了，先看下JMS能帮开发者做什么： 1、定义一组消息公用概念和实用工具 所有Java应用程序都可以使用JMS中定义的API去完成消息的创建、接收与发送，任何实现了JMS标准的MOM都可以作为消息的中介，完成消息的存储转发 2、最大化消息应用程序的可移植性 MOM提供了有保证的消息发送，应用程序开发人员无需了解远程过程调用（RPC）和网络/通信协议的细节，提供了程序的可移植性 3、最大化降低应用程序与应用程序之间的耦合度 由于MOM的存在，各个应用程序只关心和MOM之间如何进行消息的接收与发送，而无须关注MOM的另一边，其他程序是如何接收和发送的 JMS定义了一套通用的接口和相关语义，提供了诸如持久、验证和事务的消息服务，它最主要的目的是允许Java应用程序访问现有的消息中间件。JMS规范没有指定在消息节点间所使用的通讯底层协议，来保证应用开发人员不用与其细节打交道，一个特定的JMS实现可能提供基于TCP/IP、HTTP、UDP或者其它的协议。 由于没有统一的规范和标准，基于消息中间件的应用不可移植，不同的消息中间件也不能互操作，这大大阻碍了消息中间件的发展。 Java Message Service(JMS, Java消息服务)是SUN及其伙伴公司提出的旨在统一各种消息中间件系统接口的规范。 目前许多厂商采用并实现了JMS API，现在，JMS产品能够为企业提供一套完整的消息传递功能，目前我们看到的比较流行的JMS商业软件和开源产品：WebLogic、SonicMQ、ActiveMQ、OpenJMS都是基于JMS规范的实现。 4 JMS介绍在 JMS 之前，每一家 MOM 厂商都用专有 API 为应用程序提供对其产品的访问，通常可用于许多种语言，其中包括 Java 语言。JMS 通过 MOM 产品为 Java 程序提供了一个发送和接收消息的标准的、便利的方法。用 JMS 编写的程序可以在任何实现 JMS 标准的 MOM 上运行。 JMS 可移植性的关键在于：JMS API 是由 Sun 作为一组接口而提供的。提供了 JMS 功能的产品是通过提供一个实现这些接口的提供者来做到这一点的。开发人员可以通过定义一组消息和一组交换这些消息的客户机应用程序建立 JMS 应用程序。 JMS 支持两种消息类型P2P 和Pub/Sub，在JMS消息模型中，根据点对点模式和发布/订阅模式，这些要素由扩展出了各自的内容： JMS标准 点对点模式 发布/订阅模式 ConnectionFactory QueueConnectionFactory TopicConnectionFactory Connection QueueConnection TopicConnection Destination Queue Topic Session QueueSession TopicSession MessageProducer QueueSender TopicPublisher MessageConsumer QueueReceiver TopicSubscriber JMS为发开者提供了很多的要素，看一下比较重要的几个： 要 素 作 用 Destination 表示消息所走通道的目标定义，用来定义消息从发送端发出后要走的通道，而不是接收方。Destination属于管理类对象 ConnectionFactory 顾名思义，用于创建连接对象，ConnectionFactory属于管理类的对象 Connection 连接接口，所负责的重要工作时创建Session Session 会话接口，这是一个非常重要的对象，消息发送者、消息接收者以及消息对象本身，都是通过这个会话对象创建的 MessageConsumer 消息的消费者，也就是订阅消息并处理消息的对象 MessageProducer 消息的生产者，也就是用来发送消息的对象 XXXMessage 指各种类型的消息对象，包括ByteMesage、ObjectMessage、StreamMessage和TextMessage这5种 JMS消息模型 JMS 消息由以下几部分组成：消息头，属性，消息体。 消息头（header）：JMS消息头包含了许多字段，它们是消息发送后由JMS提供者或消息发送者产生，用来表示消息、设置优先权和失效时间等等，并且为消息确定路由。 属性（property）：由消息发送者产生，用来添加删除消息头以外的附加信息。 消息体（body）：由消息发送者产生，JMS中定义了5种消息体：ByteMessage、MapMessage、ObjectMessage、StreamMessage和TextMessage。 JMS编程模型 一般来说我们在开发基于JMS协议的客户端由一下几部构成： 1) 用JNDI 得到ConnectionFactory对象； 2) 用JNDI 得到目标队列或主题对象，即Destination对象； 3) 用ConnectionFactory创建Connection 对象； 4) 用Connection对象创建一个或多个JMS Session； 5) 用Session 和Destination 创建MessageProducer和MessageConsumer； 6) 通知Connection 开始传递消息。 因为jms需要使用到J2EE服务器，我们平常用的tomcat属于J2SE类型的服务器，常见的J2EE服务器包括：Geronimo,JBoss 4, GlassFish,WebLogic 。我们在这里使用glassfish 容器。安装和使用有很多教程，在此就不贴了。首先我们进去glassfish的控制台，设置一下我们的发送者和接受者对象： 下面我们用oracle提供的jms接口来写一个服务端，我们先来写一个P2P模式的例子： MySender.java import java.io.BufferedReader; import java.io.InputStreamReader; import javax.naming.*; import javax.jms.*; public class MySender { public static void main(String[] args) { try { //1)创建一个connection InitialContext ctx=new InitialContext(); QueueConnectionFactory f=(QueueConnectionFactory)ctx.lookup(&quot;myQueueConnectionFactory&quot;); QueueConnection con=f.createQueueConnection(); con.start(); //2) 创建一个会话接口 QueueSession ses=con.createQueueSession(false, Session.AUTO_ACKNOWLEDGE); //3) 获取会话接口对象 Queue t=(Queue)ctx.lookup(&quot;myQueue&quot;); //4)创建一个发送者对象 QueueSender sender=ses.createSender(t); //5) 创建一个消息对象 TextMessage msg=ses.createTextMessage(); //6) 把我们的消息写入msg对象中 BufferedReader b=new BufferedReader(new InputStreamReader(System.in)); while(true) { System.out.println(&quot;Enter Msg, end to terminate:&quot;); String s=b.readLine(); if (s.equals(&quot;end&quot;)) break; msg.setText(s); //7) 发送消息 sender.send(msg); System.out.println(&quot;Message successfully sent.&quot;); } //8) 关闭连接 con.close(); }catch(Exception e){System.out.println(e);} } } MyReceiver.java import javax.jms.*; import javax.naming.InitialContext; public class MyReceiver { public static void main(String[] args) { try{ //1) 创建一个connection InitialContext ctx=new InitialContext(); QueueConnectionFactory f=(QueueConnectionFactory)ctx.lookup(&quot;myQueueConnectionFactory&quot;); QueueConnection con=f.createQueueConnection(); con.start(); //2) 创建一个会话接口 QueueSession ses=con.createQueueSession(false, Session.AUTO_ACKNOWLEDGE); //3) 获取会话接口对象 Queue t=(Queue)ctx.lookup(&quot;myQueue&quot;); //4)创建一个发送者对象 QueueReceiver receiver=ses.createReceiver(t); //5) 创建一个消监听对象 MyListener listener=new MyListener(); //6) 将监听器注册到receiver，用来监听receiver receiver.setMessageListener(listener); System.out.println(&quot;Receiver1 is ready, waiting for messages...&quot;); System.out.println(&quot;press Ctrl+c to shutdown...&quot;); while(true){ Thread.sleep(1000); } }catch(Exception e){System.out.println(e);} } } MyListener.java import javax.jms.*; public class MyListener implements MessageListener { public void onMessage(Message m) { try{ TextMessage msg=(TextMessage)m; System.out.println(&quot;following message is received:&quot;+msg.getText()); }catch(JMSException e){System.out.println(e);} } } Pub/Sub模式： MySender.java import javax.jms.*; import javax.naming.InitialContext; import java.io.BufferedReader; import java.io.InputStreamReader; public class MySender { public static void main(String[] args) { try { //1)创建一个connection InitialContext ctx=new InitialContext(); TopicConnectionFactory f=(TopicConnectionFactory)ctx.lookup(&quot;myTopicConnectionFactory&quot;); TopicConnection con=f.createTopicConnection(); con.start(); //2) 创建一个会话接口 TopicSession ses=con.createTopicSession(false, Session.AUTO_ACKNOWLEDGE); //3) 获取会话接口对象 Topic t=(Topic)ctx.lookup(&quot;myTopic&quot;); //4)创建一个发送者对象 TopicPublisher publisher=ses.createPublisher(t); //5) 创建一个消息对象 TextMessage msg=ses.createTextMessage(); //6) 把我们的消息写入msg对象中 BufferedReader b=new BufferedReader(new InputStreamReader(System.in)); while(true) { System.out.println(&quot;Enter Msg, end to terminate:&quot;); String s=b.readLine(); if (s.equals(&quot;end&quot;)) break; msg.setText(s); //7) 发送消息 publisher.publish(msg); System.out.println(&quot;Message successfully sent.&quot;); } //8) 关闭连接 con.close(); }catch(Exception e){System.out.println(e);} } } MyReceiver.java import javax.jms.*; import javax.naming.InitialContext; public class MyReceiver { public static void main(String[] args) { try{ //1) 创建一个connection InitialContext ctx=new InitialContext(); TopicConnectionFactory f=(TopicConnectionFactory)ctx.lookup(&quot;myTopicConnectionFactory&quot;); TopicConnection con=f.createTopicConnection(); //2) 创建一个会话接口 TopicSession ses=con.createTopicSession(false, Session.AUTO_ACKNOWLEDGE); //3) 获取会话接口对象 Topic t=(Topic)ctx.lookup(&quot;myTopic&quot;); //4)创建一个发送者对象 TopicSubscriber receiver=ses.createSubscriber(t); //5) 创建一个消监听对象 MyListener listener=new MyListener(); //6) 将监听器注册到receiver，用来监听receiver receiver.setMessageListener(listener); System.out.println(&quot;Receiver1 is ready, waiting for messages...&quot;); System.out.println(&quot;press Ctrl+c to shutdown...&quot;); while(true){ Thread.sleep(1000); } }catch(Exception e){System.out.println(e);} } } MyListener.java import javax.jms.JMSException; import javax.jms.Message; import javax.jms.MessageListener; import javax.jms.TextMessage; public class MyListener implements MessageListener { public void onMessage(Message m) { try{ TextMessage msg=(TextMessage)m; System.out.println(&quot;following message is received:&quot;+msg.getText()); }catch(JMSException e){System.out.println(e);} } } 上面两个案例我们运行可以看到消息成功的发送出去了。熟悉了JMS的语法，使用起来还是很简单。 上面我们介绍到了JMS，JMS是一个用于提供消息服务的技术规范，它制定了在整个消息服务提供过程中的所有数据结构和交互流程。JMS即Java消息服务（Java Message Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM）的API。 Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。 下面我们引入另一个概念：MQ（Message Queue）。 应用程序通过写和检索出入列队的针对应用程序的数据（消息）来通信，而无需专用连接来链接它们。消息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信，直接调用通常是用于诸如远程过程调用的技术。排队指的是应用程序通过队列来通信。队列的使用除去了接收和发送应用程序同时执行的要求。 MQ和JMS类似，但不同的是JMS是SUN Java消息中间件服务的一个标准和API定义，而MQ则是遵循了AMQP协议的具体实现和产品。JMS是一个用于提供消息服务的技术规范，它制定了在整个消息服务提供过程中的所有数据结构和交互流程。而MQ则是消息队列服务，是面向消息中间件（MOM）的最终实现，是真正的服务提供者；MQ的实现可以基于JMS，也可以基于其他规范或标准。MQ 有很多产品：IBM的，rabbitmq, activemq 等，rabbitmq 只支持点对点的方式。所以没有完全实现JMS的标准，所以说它不是一个JMS产品，而rabitmq 和Jobss JMS 它们实现了JMS的各项标准，是开源的JMS产品。目前完全实现JMS协议的mq是activemq，所以接下来我们先重点看一下activemq。从activemq入手去探索javaEE的世界。]]></content>
      <categories>
        <category>activeMQ</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习(四)-TCP粘包和拆包]]></title>
    <url>%2Fposts%2F278c909d.html</url>
    <content type="text"><![CDATA[我们都知道TCP是基于字节流的传输协议。那么数据在通信层传播其实就像河水一样并没有明显的分界线，而数据具体表示什么意思什么地方有句号什么地方有分号这个对于TCP底层来说并不清楚。应用层向TCP层发送用于网间传输的、用8位字节表示的数据流，然后TCP把数据流分区成适当长度的报文段，之后TCP把结果包传给IP层，由它来通过网络将包传送给接收端实体的TCP层。所以对于这个数据拆分成大包小包的问题就是我们今天要讲的粘包和拆包的问题。 1 TCP粘包拆包问题说明粘包和拆包这两个概念估计大家还不清楚，通过下面这张图我们来分析一下： 假设客户端分别发送两个数据包D1,D2个服务端，但是发送过程中数据是何种形式进行传播这个并不清楚，分别有下列4种情况： 服务端一次接受到了D1和D2两个数据包，两个包粘在一起，称为粘包； 服务端分两次读取到数据包D1和D2，没有发生粘包和拆包； 服务端分两次读到了数据包，第一次读到了D1和D2的部分内容，第二次读到了D2的剩下部分，这个称为拆包； 服务器分三次读到了数据部分，第一次读到了D1包，第二次读到了D2包的部分内容，第三次读到了D2包的剩下内容。 2. TCP粘包产生原因我们知道在TCP协议中，应用数据分割成TCP认为最适合发送的数据块，这部分是通过“MSS”（最大数据包长度）选项来控制的，通常这种机制也被称为一种协商机制，MSS规定了TCP传往另一端的最大数据块的长度。这个值TCP协议在实现的时候往往用MTU值代替（需要减去IP数据包包头的大小20Bytes和TCP数据段的包头20Bytes）所以往往MSS为1460。通讯双方会根据双方提供的MSS值得最小值确定为这次连接的最大MSS值。 tcp为提高性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了之后，再将缓冲中的数据发送到接收方。同理，接收方也有缓冲区这样的机制，来接收数据。 发生粘包拆包的原因主要有以下这些： 应用程序写入数据的字节大小大于套接字发送缓冲区的大小将发生拆包； 进行MSS大小的TCP分段。MSS是TCP报文段中的数据字段的最大长度，当TCP报文长度-TCP头部长度&gt;mss的时候将发生拆包； 应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上,将发生粘包； 数据包大于MTU的时候将会进行切片。MTU即(Maxitum Transmission Unit) 最大传输单元,由于以太网传输电气方面的限制，每个以太网帧都有最小的大小64bytes最大不能超过1518bytes,刨去以太网帧的帧头14Bytes和帧尾CRC校验部分4Bytes,那么剩下承载上层协议的地方也就是Data域最大就只能有1500Bytes这个值我们就把它称之为MTU。这个就是网络层协议非常关心的地方，因为网络层协议比如IP协议会根据这个值来决定是否把上层传下来的数据进行分片。 3. 如何解决TCP粘包拆包我们知道tcp是无界的数据流，且协议本身无法避免粘包，拆包的发生，那我们只能在应用层数据协议上，加以控制。通常在制定传输数据时，可以使用如下方法： 设置定长消息，服务端每次读取既定长度的内容作为一条完整消息； 使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容； 设置消息边界，服务端从网络流中按消息边界分离出消息内容。比如在消息末尾加上换行符用以区分消息结束。 当然应用层还有更多复杂的方式可以解决这个问题，这个就属于网络层的问题了，我们还是用java提供的方式来解决这个问题。我们先看一个例子看看粘包是如何发生的。 服务端： 12345678910111213141516171819202122232425262728293031public class HelloWordServer &#123; private int port; public HelloWordServer(int port) &#123; this.port = port; &#125; public void start()&#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); ServerBootstrap server = new ServerBootstrap().group(bossGroup,workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ServerChannelInitializer()); try &#123; ChannelFuture future = server.bind(port).sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HelloWordServer server = new HelloWordServer(7788); server.start(); &#125;&#125; 服务端Initializer： 12345678910111213public class ServerChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); // 字符串解码 和 编码 pipeline.addLast("decoder", new StringDecoder()); pipeline.addLast("encoder", new StringEncoder()); // 自己的逻辑Handler pipeline.addLast("handler", new HelloWordServerHandler()); &#125;&#125; 服务端handler： 1234567891011121314public class HelloWordServerHandler extends ChannelInboundHandlerAdapter &#123; private int counter; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String body = (String)msg; System.out.println("server receive order : " + body + ";the counter is: " + ++counter); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; super.exceptionCaught(ctx, cause); &#125;&#125; 客户端： 123456789101112131415161718192021222324252627282930313233public class HelloWorldClient &#123; private int port; private String address; public HelloWorldClient(int port,String address) &#123; this.port = port; this.address = address; &#125; public void start()&#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new ClientChannelInitializer()); try &#123; ChannelFuture future = bootstrap.connect(address,port).sync(); future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HelloWorldClient client = new HelloWorldClient(7788,"127.0.0.1"); client.start(); &#125;&#125; 客户端Initializer： 123456789101112public class ClientChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast("decoder", new StringDecoder()); pipeline.addLast("encoder", new StringEncoder()); // 客户端的逻辑 pipeline.addLast("handler", new HelloWorldClientHandler()); &#125;&#125; 客户端handler： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class HelloWorldClientHandler extends ChannelInboundHandlerAdapter &#123; private byte[] req; private int counter; public BaseClientHandler() &#123; req = ("Unless required by applicable law or agreed to in writing, software\n" + " distributed under the License is distributed on an \"AS IS\" BASIS,\n" + " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n" + " See the License for the specific language governing permissions and\n" + " limitations under the License.This connector uses the BIO implementation that requires the JSSE\n" + " style configuration. When using the APR/native implementation, the\n" + " penSSL style configuration is required as described in the APR/native\n" + " documentation.An Engine represents the entry point (within Catalina) that processes\n" + " every request. The Engine implementation for Tomcat stand alone\n" + " analyzes the HTTP headers included with the request, and passes them\n" + " on to the appropriate Host (virtual host)# Unless required by applicable law or agreed to in writing, software\n" + "# distributed under the License is distributed on an \"AS IS\" BASIS,\n" + "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n" + "# See the License for the specific language governing permissions and\n" + "# limitations under the License.# For example, set the org.apache.catalina.util.LifecycleBase logger to log\n" + "# each component that extends LifecycleBase changing state:\n" + "#org.apache.catalina.util.LifecycleBase.level = FINE" ).getBytes(); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ByteBuf message; //将上面的所有字符串作为一个消息体发送出去 message = Unpooled.buffer(req.length); message.writeBytes(req); ctx.writeAndFlush(message); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String buf = (String)msg; System.out.println("Now is : " + buf + " ; the counter is : "+ (++counter)); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125;&#125; 运行客户端和服务端我们能看到： 我们看到这个长长的字符串被截成了2段发送，这就是发生了拆包的现象。同样粘包我们也很容易去模拟，我们把BaseClientHandler中的channelActive方法里面的： 123message = Unpooled.buffer(req.length);message.writeBytes(req);ctx.writeAndFlush(message); 这几行代码是把我们上面的一长串字符转成的byte数组写进流里发送出去，那么我们可以在这里把上面发送消息的这几行循环几遍这样发送的内容增多了就有可能在拆包的时候把上一条消息的一部分分配到下一条消息里面了，修改如下： 12345for (int i = 0; i &lt; 3; i++) &#123; message = Unpooled.buffer(req.length); message.writeBytes(req); ctx.writeAndFlush(message);&#125; 改完之后我们再运行一下，输出太长不好截图，我们在输出结果中能看到循环3次之后的消息服务端收到的就不是之前的完整的一条了，而是被拆分了4次发送。 对于上面出现的粘包和拆包的问题，Netty已有考虑，并且有实施的方案：LineBasedFrameDecoder。我们重新改写一下ServerChannelInitializer： 123456789101112131415public class ServerChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(new LineBasedFrameDecoder(2048)); // 字符串解码 和 编码 pipeline.addLast("decoder", new StringDecoder()); pipeline.addLast("encoder", new StringEncoder()); // 自己的逻辑Handler pipeline.addLast("handler", new BaseServerHandler()); &#125;&#125; 新增：pipeline.addLast(new LineBasedFrameDecoder(2048))。同时，我们还得对上面发送的消息进行改造BaseClientHandler： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class BaseClientHandler extends ChannelInboundHandlerAdapter &#123; private byte[] req; private int counter; req = ("Unless required by applicable dfslaw or agreed to in writing, software" + " distributed under the License is distributed on an \"AS IS\" BASIS," + " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied." + " See the License for the specific language governing permissions and" + " limitations under the License.This connector uses the BIO implementation that requires the JSSE" + " style configuration. When using the APR/native implementation, the" + " penSSL style configuration is required as described in the APR/native" + " documentation.An Engine represents the entry point (within Catalina) that processes" + " every request. The Engine implementation for Tomcat stand alone" + " analyzes the HTTP headers included with the request, and passes them" + " on to the appropriate Host (virtual host)# Unless required by applicable law or agreed to in writing, software" + "# distributed under the License is distributed on an \"AS IS\" BASIS," + "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied." + "# See the License for the specific language governing permissions and" + "# limitations under the License.# For example, set the org.apache.catalina.util.LifecycleBase logger to log" + "# each component that extends LifecycleBase changing state:" + "#org.apache.catalina.util.LifecycleBase.level = FINE\n" ).getBytes(); @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ByteBuf message; message = Unpooled.buffer(req.length); message.writeBytes(req); ctx.writeAndFlush(message); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String buf = (String)msg; System.out.println("Now is : " + buf + " ; the counter is : "+ (++counter)); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125;&#125; 去掉所有的”\n”,只保留字符串末尾的这一个。原因稍后再说。channelActive方法中我们不必再用循环多次发送消息了，只发送一次就好(第一个例子中发送一次的时候是发生了拆包的)，然后我们再次运行，大家会看到这么长一串字符只发送了一串就发送完毕。程序输出我就不截图了。下面来解释一下LineBasedFrameDecoder。 LineBasedFrameDecoder的工作原理是它依次遍历ByteBuf 中的可读字节，判断看是否有”\n” 或者” \r\n”，如果有，就以此位置为结束位置，从可读索引到结束位置区间的字节就组成了一行。它是以换行符为结束标志的解码器。支持携带结束符或者不携带结束符两种解码方式，同时支持配置单行的最大长度。如果连续读取到最大长度后仍然没有发现换行符，就会抛出异常，同时忽略掉之前读到的异常码流。这个对于我们确定消息最大长度的应用场景还是很有帮助。 对于上面的判断看是否有”\n” 或者” \r\n”以此作为结束的标志我们可能回想，要是没有”\n” 或者” \r\n”那还有什么别的方式可以判断消息是否结束呢。别担心，Netty对于此已经有考虑，还有别的解码器可以帮助我们解决问题，下节我们继续学习。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习(五)-DelimiterBasedFrameDecoder]]></title>
    <url>%2Fposts%2F87e472dc.html</url>
    <content type="text"><![CDATA[上一节我们说了LineBasedframeDecoder来解决粘包拆包的问题，TCP以流的方式进行数据传输，上层应用协议为了对消息进行区分，一般采用如下4种方式： 消息长度固定，累计读取到消息长度总和为定长Len的报文之后即认为是读取到了一个完整的消息。计数器归位，重新读取。 将回车换行符作为消息结束符。 将特殊的分隔符作为消息分隔符，回车换行符是他的一种。 通过在消息头定义长度字段来标识消息总长度。 LineBasedframeDecoder属于第二种，今天我们要说的DelimiterBasedFrameDecoder和FixedLengthFrameDecoder属于第三种和第一种。DelimiterBasedFrameDecoder用来解决以特殊符号作为消息结束符的粘包问题，FixedLengthFrameDecoder用来解决定长消息的粘包问题。下面首先来用DelimiterBasedFrameDecoder来写一个例子，我们看一下效果然后接着分析用法。 1. DelimiterBasedFrameDecoder使用服务端： 12345678910111213141516171819202122232425262728293031public class HelloWordServer &#123; private int port; public HelloWordServer(int port) &#123; this.port = port; &#125; public void start()&#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); ServerBootstrap server = new ServerBootstrap().group(bossGroup,workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ServerChannelInitializer()); try &#123; ChannelFuture future = server.bind(port).sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HelloWordServer server = new HelloWordServer(7788); server.start(); &#125;&#125; 服务端ServerChannelInitializer： 123456789101112131415public class ServerChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); ByteBuf delimiter = Unpooled.copiedBuffer("\t".getBytes()); pipeline.addLast("framer", new DelimiterBasedFrameDecoder(2048,delimiter)); // 字符串解码 和 编码 pipeline.addLast("decoder", new StringDecoder()); pipeline.addLast("encoder", new StringEncoder()); // 自己的逻辑Handler pipeline.addLast("handler", new ServerHandler()); &#125;&#125; 服务端handler： 1234567891011121314public class ServerHandler extends ChannelInboundHandlerAdapter &#123; private int counter; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String body = (String)msg; System.out.println("server receive order : " + body + ";the counter is: " + ++counter); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; super.exceptionCaught(ctx, cause); &#125;&#125; 客户端： 123456789101112131415161718192021222324252627282930313233public class HelloWorldClient &#123; private int port; private String address; public HelloWorldClient(int port,String address) &#123; this.port = port; this.address = address; &#125; public void start()&#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new ClientChannelInitializer()); try &#123; ChannelFuture future = bootstrap.connect(address,port).sync(); future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HelloWorldClient client = new HelloWorldClient(7788,"127.0.0.1"); client.start(); &#125;&#125; 客户端ClientChannelInitializer： 12345678910111213141516171819public class ClientChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); /* * 这个地方的 必须和服务端对应上。否则无法正常解码和编码 * * */ ByteBuf delimiter = Unpooled.copiedBuffer("\t".getBytes()); pipeline.addLast("framer", new DelimiterBasedFrameDecoder(2048,delimiter)); pipeline.addLast("decoder", new StringDecoder()); pipeline.addLast("encoder", new StringEncoder()); // 客户端的逻辑 pipeline.addLast("handler", new ClientHandler()); &#125;&#125; 客户端handler： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ClientHandler extends ChannelInboundHandlerAdapter &#123; private byte[] req; private int counter; public ClientHandler() &#123; req = ("Unless required by applicable law or agreed to in writing, software\t" + " distributed under the License is distributed on an \"AS IS\" BASIS,\t" + " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\t" + " See the License for the specific language governing permissions and\t" + " limitations under the License.This connector uses the BIO implementation that requires the JSSE\t" + " style configuration. When using the APR/native implementation, the\t" + " penSSL style configuration is required as described in the APR/native\t" + " documentation.An Engine represents the entry point (within Catalina) that processes\t" + " every request. The Engine implementation for Tomcat stand alone\t" + " analyzes the HTTP headers included with the request, and passes them\t" + " on to the appropriate Host (virtual host)# Unless required by applicable law or agreed to in writing, software\t" + "# distributed under the License is distributed on an \"AS IS\" BASIS,\t" + "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\t" + "# See the License for the specific language governing permissions and\t" + "# limitations under the License.# For example, set the org.apache.catalina.util.LifecycleBase logger to log\t" + "# each component that extends LifecycleBase changing state:\t" + "#org.apache.catalina.util.LifecycleBase.level = FINE\t" ).getBytes(); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ByteBuf message; message = Unpooled.buffer(req.length); message.writeBytes(req); ctx.writeAndFlush(message); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String buf = (String)msg; System.out.println("Now is : " + buf + " ; the counter is : "+ (++counter)); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125;&#125; 输出如下： server receive order : Unless required by applicable law or agreed to in writing, software;the counter is: 1 server receive order : distributed under the License is distributed on an &quot;AS IS&quot; BASIS,;the counter is: 2 server receive order : WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.;the counter is: 3 server receive order : See the License for the specific language governing permissions and;the counter is: 4 server receive order : limitations under the License.This connector uses the BIO implementation that requires the JSSE;the counter is: 5 server receive order : style configuration. When using the APR/native implementation, the;the counter is: 6 server receive order : penSSL style configuration is required as described in the APR/native;the counter is: 7 server receive order : documentation.An Engine represents the entry point (within Catalina) that processes;the counter is: 8 server receive order : every request. The Engine implementation for Tomcat stand alone;the counter is: 9 server receive order : analyzes the HTTP headers included with the request, and passes them;the counter is: 10 server receive order : on to the appropriate Host (virtual host)# Unless required by applicable law or agreed to in writing, software;the counter is: 11 server receive order : # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,;the counter is: 12 server receive order : # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.;the counter is: 13 server receive order : # See the License for the specific language governing permissions and;the counter is: 14 server receive order : # limitations under the License.# For example, set the org.apache.catalina.util.LifecycleBase logger to log;the counter is: 15 server receive order : # each component that extends LifecycleBase changing state:;the counter is: 16 server receive order : #org.apache.catalina.util.LifecycleBase.level = FINE;the counter is: 17 启动服务端和客户端，我们能看到服务端接收客户端发过来的消息一共分17次接收。那么为什么是17次呢？而且我们并没有使用在上一篇中解决拆包和粘包问题的LineBasedFrameDecoder，并且这次我们的消息每一行的末尾也换成了”\t”。下面就来讲解一下DelimiterBasedFrameDecoder的使用。 DelimiterBasedFrameDecoder是将特殊的字符作为消息的分隔符，本例中用到的是”\t”。而LineBasedFrameDecoder是默认将换行符”\n”作为消息分隔符。首先我们注意到在ServerChannelInitializer中我们在添加解码器时跟以前有点不一样： 12ByteBuf delimiter = Unpooled.copiedBuffer("\t".getBytes());pipeline.addLast("framer", new DelimiterBasedFrameDecoder(2048, delimiter)); 这里我们添加DelimiterBasedFrameDecoder解码器并且手动指定消息分隔符为：”\t”。我们可以看一下DelimiterBasedFrameDecoder的构造方法： 123public DelimiterBasedFrameDecoder(int maxFrameLength, boolean stripDelimiter, ByteBuf delimiter) &#123; this(maxFrameLength, stripDelimiter, true, delimiter);&#125; maxFrameLength：解码的帧的最大长度 stripDelimiter：解码时是否去掉分隔符 failFast：为true，当frame长度超过maxFrameLength时立即报TooLongFrameException异常，为false，读取完整个帧再报异常 delimiter：分隔符 这个时候大家应该明白了为什么服务端分17次收到消息。我们在消息的每一行都加了一个”\t”,自然解码器在度消息时遇到”\t”就会认为这是一条消息的结束。用这种方式我们可以把”\t”换成任何我们自定义的字符对象。换成”\n”也是可以的。 2. FixedLengthFrameDecoder使用FixedLengthFrameDecoder是固定长度解码器，它能够按照指定的长度对消息进行自动解码。使用它也没有什么特别费力的事情，在ServerChannelInitializer类中添加： pipeline.addLast(new FixedLengthFrameDecoder(23));//参数为一次接受的数据长度 即可，同时也别忘了把刚才使用的DelimiterBasedFrameDecoder注释掉啊，不然达不到效果。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习(七)-Netty编解码技术以及ProtoBuf和Thrift的介绍]]></title>
    <url>%2Fposts%2Ff693139f.html</url>
    <content type="text"><![CDATA[在前几节我们学习过处理粘包和拆包的问题，用到了Netty提供的几个解码器对不同情况的问题进行处理。功能很是强大。我们有没有去想这么强大的功能是如何实现的呢？背后又用到了什么技术？这一节我们就来处理这个问题。了解一下编码解码到底是如何处理的。 通常说的编码(Encoder)也就是发生在发送消息的时候需要将消息编译成字节对象，在Netty中即编译成ByteBuf对象。在java中我们将这种编译称之为序列化(Serializable),即将对象序列化为字节数组，然后用于传输或是持久化啊之类的。那么自然解码（Decoder）就是一个反序列化的过程，使用相应的编码格式对接收到的对做一个解码，以正确解析该对象。 1. java序列化的弱点谈到序列化我们自然想到java提供的Serializable接口，在java中我们如果需要序列化只需要继承该接口就可以通过输入输出流进行序列化和反序列化。但是在提供很用户简单的调用的同时他也存在很多问题： 无法跨语言。当我们进行跨应用之间的服务调用的时候如果另外一个应用使用c语言来开发，这个时候我们发送过去的序列化对象，别人是无法进行反序列化的因为其内部实现对于别人来说完全就是黑盒。 序列化之后的码流太大。这个我们可以做一个实验还是上一节中的Message类，我们分别用java的序列化和使用二进制编码来做一个对比，下面我写了一个测试类： 123456789101112131415161718192021222324252627282930@Testpublic void testSerializable()&#123; String str = "哈哈,我是一条消息"; Message msg = new Message((byte)0xAD,35,str); ByteArrayOutputStream out = new ByteArrayOutputStream(); try &#123; ObjectOutputStream os = new ObjectOutputStream(out); os.writeObject(msg); os.flush(); byte[] b = out.toByteArray(); System.out.println("jdk序列化后的长度： "+b.length); os.close(); out.close(); ByteBuffer buffer = ByteBuffer.allocate(1024); byte[] bt = msg.getMsgBody().getBytes(); buffer.put(msg.getType()); buffer.putInt(msg.getLength()); buffer.put(bt); buffer.flip(); byte[] result = new byte[buffer.remaining()]; buffer.get(result); System.out.println("使用二进制序列化的长度："+result.length); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 输出结果为： 我们可以看到差距是挺大的，目前的主流编解码框架序列化之后的码流也都比java序列化要小太多。 序列化效率差，这个我们也可以做一个对比，还是上面写的测试代码我们循环跑100000次对比一下时间： 123456789101112131415161718192021222324252627282930313233343536373839@Testpublic void testSerializable()&#123; String str = "哈哈,我是一条消息"; Message msg = new Message((byte)0xAD,35,str); ByteArrayOutputStream out = new ByteArrayOutputStream(); try &#123; long startTime = System.currentTimeMillis(); for(int i = 0;i &lt; 100000;i++)&#123; ObjectOutputStream os = new ObjectOutputStream(out); os.writeObject(msg); os.flush(); byte[] b = out.toByteArray(); /*System.out.println("jdk序列化后的长度： "+b.length);*/ os.close(); out.close(); &#125; long endTime = System.currentTimeMillis(); System.out.println("jdk序列化100000次耗时：" +(endTime - startTime)); long startTime1 = System.currentTimeMillis(); for(int i = 0;i &lt; 100000;i++)&#123; ByteBuffer buffer = ByteBuffer.allocate(1024); byte[] bt = msg.getMsgBody().getBytes(); buffer.put(msg.getType()); buffer.putInt(msg.getLength()); buffer.put(bt); buffer.flip(); byte[] result = new byte[buffer.remaining()]; buffer.get(result); /*System.out.println("使用二进制序列化的长度："+result.length);*/ &#125; long endTime1 = System.currentTimeMillis(); System.out.println("使用二进制序列化100000次耗时：" +(endTime1 - startTime1)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 结果为： 结果为毫秒数，这个差距也是不小的。 结合以上我们看到：目前的序列化过程中使用java本身的肯定是不行，使用二进制编码的话又的我们自己去手写，所以为了让我们少搬砖前辈们早已经写好了工具让我们调用，目前社区比较活跃的有google的Protobuf和Apache的Thrift。 2. Protobuf序列化的使用我们先来使用Protobuf进行序列化，他和XML，json一样都有自己的语法，xml的后缀是.xml，json文件的后缀是.json，自然Protobuf文件的后缀就是.proto（哈哈，当然不是全称）。 下面我们使用Protobuf来封装一段消息，通过一个案例简单介绍一下它的使用。 首先我们用Protobuf的语法格式来写一段需要序列化的对象，命名格式为：Msg.proto 1234567891011121314option java_package = "cn.edu.hust.netty.demo10";option java_outer_classname = "MessageProto";message RequestMsg&#123; required bytes msgType = 1; required string receiveOne = 2; required string msg = 3;&#125;message ResponseMsg&#123; required bytes msgType = 1; required string receiveOne = 2; required string msg = 3;&#125; 关于Message.proto中的语法格式，详情大家google一下相关的说明，网上很多介绍，再次简单就上面的语法说明一下： option java_package：表示生成的.java文件的包名 option java_outer_classname：生成的java文件的文件名 message ： 为他的基本类型，如同java中的class一样 字段修饰符： required：一个格式良好的消息一定要含有1个这种字段。表示该值是必须要设置的； optional：消息格式中该字段可以有0个或1个值（不超过1个）。 repeated：在一个格式良好的消息中，这种字段可以重复任意多次（包括0次）。重复的值的顺序会被保留。表示该值可以重复，相当于java中的List。 字符类型稍微有些不同：double,float,int32,int64,bool(boolean),string,bytes。稍微有些不同，String，boolean，int有差别。 另外我们看到上面3个字段分别赋值了，这个值是什么意思呢？消息定义中，每个字段都有唯一的一个数字标识符。这些标识符是用来在消息的二进制格式中识别各个字段的，一旦开始使用就不能够再改变。注：[1,15]之内的标识号在编码的时候会占用一个字节。[16,2047]之内的标识号则占用2个字节。所以应该为那些频繁出现的消息元素保留 [1,15]之内的标识号。 关于Protobuf 的语法我们就简单的介绍这么多，更多细节大家自己去查阅文档吧。下面我们开始使用Protobuf 来进行序列化。 首先我们的在工程中引入protobuf的jar包，目前官方版本最高3.2，我们用3.0的吧： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt;&lt;/dependency&gt; Protobuf的文件已经定义好了，下就需要把它编译成java代码，这里我们的借助到google为我们提供的脚本工具protoc，链接在这里，点击下载这里提供的是protoc-3.0.2。要注意protoc的版本需要和Protobuf的版本对应上，不然不同的版本之间会有一些差异解析可能会有问题。现在知道我们为啥非得选用protobuf3.0.2版本吧，因为我没有找到别的版本的protoc。。。 下载好了我们解压缩然后把刚才写好的Msg.proto文件复制进去。 接着我们进cmd输入如下命令： 主要是第三句命令。如果你输入没有报错的话你的proto文件夹应该会生成一个子文件夹： 进去该文件夹你会看到已经生成了MessageProto.java文件，恭喜你，这时候你已经完成了protobuf序列化文件的生成。然后你把该文件拷贝至工程目录下。接下来我们用生成的文件去发消息吧。还是老套路服务端和客户端。 服务端： 12345678910111213141516171819202122232425262728293031public class ProtoBufServer &#123; private int port; public ProtoBufServer(int port) &#123; this.port = port; &#125; public void start()&#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); ServerBootstrap server = new ServerBootstrap().group(bossGroup,workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ServerChannelInitializer()); try &#123; ChannelFuture future = server.bind(port).sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; ProtoBufServer server = new ProtoBufServer(7788); server.start(); &#125;&#125; 服务端Initializer： 12345678910public class ServerChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(new ProtobufVarint32FrameDecoder()); pipeline.addLast(new ProtobufDecoder(MessageProto.RequestMsg.getDefaultInstance())); pipeline.addLast(new ProtoBufServerHandler()); &#125;&#125; 服务端handler： 123456789101112131415161718192021222324public class ProtoBufServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; MessageProto.ResponseMsg.Builder builder = MessageProto.ResponseMsg.newBuilder(); builder.setMsgType(ByteString.copyFromUtf8("CBSP")); builder.setReceiveOne("小红"); builder.setMsg("你好，你有啥事"); ctx.writeAndFlush(builder.build()); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; MessageProto.RequestMsg m = (MessageProto.RequestMsg)msg; System.out.println("Client say: "+m.getReceiveOne()+","+m.getMsg()); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; super.exceptionCaught(ctx, cause); ctx.close(); &#125;&#125; 客户端： 12345678910111213141516171819202122232425262728293031323334public class ProtoBufClient &#123; private int port; private String address; public ProtoBufClient(int port, String address) &#123; this.port = port; this.address = address; &#125; public void start()&#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new ClientChannelInitializer()); try &#123; ChannelFuture future = bootstrap.connect(address,port).sync(); future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; ProtoBufClient client = new ProtoBufClient(7788,"127.0.0.1"); client.start(); &#125;&#125; 客户端Initializer： 12345678910public class ClientChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(new ProtobufVarint32LengthFieldPrepender()); pipeline.addLast(new ProtobufEncoder()); pipeline.addLast(new ProtoBufClientHandler()); &#125;&#125; 客户端handler： 12345678910111213141516171819202122public class ProtoBufClientHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; MessageProto.ResponseMsg m = (MessageProto.ResponseMsg)msg; System.out.println("Server say: "+m.getReceiveOne()+","+m.getMsg()); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; MessageProto.RequestMsg.Builder builder = MessageProto.RequestMsg.newBuilder(); builder.setMsgType(ByteString.copyFromUtf8("CBSP")); builder.setReceiveOne("小明"); builder.setMsg("你好，我找你有事"); ctx.writeAndFlush(builder.build()); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("Client is close"); &#125;&#125; 启动服务端和客户端，输出如下： 最简单的protoBuf应用案例我们就写完了，真实的使用场景大同小异，随机应变即可。 3. thrift序列化的使用哈哈，我本来是打算讲thrift的安装和使用的，但是现在却讲不了，因为这玩意儿的安装是个问题。由于我没有linux环境，thrift如果在linux环境下安装使用是挺简单的，但是在windows环境下挺麻烦。thrift在windows下，还使用C++，搭环境是最难的。 libthrift依赖boost libthriftnb依赖boost，libevent 等于你得安装boost，libevent 除此之外，还需要openssl 装openssl，又需要perl，nasm 期间，还会涉及版本兼容问题，总而言之，比较折磨，而这还仅是安装编译。 所以暂时我就跳过这一部分，等我安装linux环境之后再来讲解吧。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习(六)-LengthFieldBasedFrameDecoder解码器]]></title>
    <url>%2Fposts%2F2b5f20ba.html</url>
    <content type="text"><![CDATA[在TCP协议中我们知道当我们在接收消息时候，我们如何判断我们一次读取到的包就是整包消息呢，特别是对于使用了长连接和使用了非阻塞I/O的程序。上节我们也说了上层应用协议为了对消息进行区分一般采用4种方式。前面三种我们都说了，第四种是：通过在消息头定义长度字段来标识消息总长度。这个我们还没讲。当然Netty也提供了相应的解码器：LengthFieldBasedFrameDecoder。 大多数的协议（私有或者公有），协议头中会携带长度字段，用于标识消息体或者整包消息的长度，例如SMPP、HTTP协议等。由于基于长度解码需求 的通用性，Netty提供了LengthFieldBasedFrameDecoder，自动屏蔽TCP底层的拆包和粘 包问题，只需要传入正确的参数，即可轻松解决“读半包“问题。 我们先来看一下他的构造函数： 123456789public LengthFieldBasedFrameDecoder(ByteOrder byteOrder, int maxFrameLength, int lengthFieldOffset, int lengthFieldLength, int lengthAdjustment, int initialBytesToStrip, boolean failFast) &#123;&#125; byteOrder：表示字节流表示的数据是大端还是小端，用于长度域的读取； maxFrameLength：表示的是包的最大长度，超出包的最大长度netty将会做一些特殊处理； lengthFieldOffset：指的是长度域的偏移量，表示跳过指定长度个字节之后的才是长度域； lengthFieldLength：记录该帧数据长度的字段本身的长度； lengthAdjustment：该字段加长度字段等于数据帧的长度，包体长度调整的大小，长度域的数值表示的长度加上这个修正值表示的就是带header的包； initialBytesToStrip：从数据帧中跳过的字节数，表示获取完一个完整的数据包之后，忽略前面的指定的位数个字节，应用解码器拿到的就是不带长度域的数据包； failFast：如果为true，则表示读取到长度域，TA的值的超过maxFrameLength，就抛出一个 TooLongFrameException，而为false表示只有当真正读取完长度域的值表示的字节之后，才会抛出 TooLongFrameException，默认情况下设置为true，建议不要修改，否则可能会造成内存溢出。 LengthFieldBasedFrameDecoder定义了一个长度的字段来表示消息的长度，因此能够处理可变长度的消息。将消息分为消息头和消息体，消息头固定位置增加一个表示长度的字段，通过长度字段来获取整包的信息。LengthFieldBasedFrameDecoder继承了ByteToMessageDecoder，即转换字节这样的工作是由ByteToMessageDecoder来完成，而LengthFieldBasedFrameDecoder只用安心完成他的解码工作就好。Netty在解耦和方面确实做的不错。 既然我们知道了LengthFieldBasedFrameDecoder处理的是带有消息头和消息体的消息类型，那么我们完全可以来定义一个我们自己的消息，我们来写一个消息类： 1234567891011121314151617181920212223242526272829303132333435363738394041public class Message &#123; //消息类型 private byte type; //消息长度 private int length; //消息体 private String msgBody; public Message(byte type, int length, String msgBody) &#123; this.type = type; this.length = length; this.msgBody = msgBody; &#125; public byte getType() &#123; return type; &#125; public void setType(byte type) &#123; this.type = type; &#125; public int getLength() &#123; return length; &#125; public void setLength(int length) &#123; this.length = length; &#125; public String getMsgBody() &#123; return msgBody; &#125; public void setMsgBody(String msgBody) &#123; this.msgBody = msgBody; &#125;&#125; 我们先来写服务端： 1234567891011121314151617181920212223242526272829303132333435363738394041public class NewServer &#123; private static final int MAX_FRAME_LENGTH = 1024 * 1024; private static final int LENGTH_FIELD_LENGTH = 4; private static final int LENGTH_FIELD_OFFSET = 1; private static final int LENGTH_ADJUSTMENT = 0; private static final int INITIAL_BYTES_TO_STRIP = 0; private int port; public NewServer(int port) &#123; this.port = port; &#125; public void start()&#123; EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap sbs = new ServerBootstrap() .group(bossGroup,workerGroup) .channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(port)) .childHandler(new NewServerChannelInitializer(MAX_FRAME_LENGTH,LENGTH_FIELD_LENGTH,LENGTH_FIELD_OFFSET,LENGTH_ADJUSTMENT,INITIAL_BYTES_TO_STRIP)) .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); ChannelFuture future = sbs.bind(port).sync(); System.out.println("Server start listen at " + port ); future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; NewServer server = new NewServer(7788); server.start(); &#125;&#125; 注意到服务端我们在上面定义了5个参数，这5个参数是为了传入LengthFieldBasedFrameDecoder里面用的，因为我们的LengthFieldBasedFrameDecoder写在了NewServerChannelInitializer类里面，所以这几个参数采用可配置的方式也更符合可扩展性，我们分别说一下这几个参数定值的含义： MAX_FRAME_LENGTH = 1024 * 1024 ：这个没什么说的，消息体的最大长度； LENGTH_FIELD_LENGTH = 4 ：指的就是我们的Message类中的length的长度，int占4位 LENGTH_FIELD_OFFSET = 1 ：偏移多少位之后才是我们的消息体，因为我们消息头只有type一个参数，byte类型占1位，所以是1； LENGTH_ADJUSTMENT = 0 ：该字段加长度字段等于数据帧的长度，一般数据帧长度都是这样定义(即我们在设置Message中的length属性)，加入你的消息体是20位，再加上 LENGTH_FIELD_LENGTH就是24位，所以在此处为了正确的解析出消息体，需要偏移4位才能解析出消息体的正确位置，我们在发送的消息里面设置的就是消息体本身的长度，所以无需偏移。 INITIAL_BYTES_TO_STRIP = 0 ：这里我们也不需要跳过数据帧中的字节数，因为我们的消息体和长度是分别发送的，详情见下面EnCoder代码。 然后我们写ChannelInitializer： 12345678910111213141516171819202122232425public class NewServerChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; private final int MAX_FRAME_LENGTH; private final int LENGTH_FIELD_LENGTH; private final int LENGTH_FIELD_OFFSET; private final int LENGTH_ADJUSTMENT; private final int INITIAL_BYTES_TO_STRIP; public NewServerChannelInitializer(int MAX_FRAME_LENGTH, int LENGTH_FIELD_LENGTH, int LENGTH_FIELD_OFFSET, int LENGTH_ADJUSTMENT, int INITIAL_BYTES_TO_STRIP) &#123; this.MAX_FRAME_LENGTH = MAX_FRAME_LENGTH; this.LENGTH_FIELD_LENGTH = LENGTH_FIELD_LENGTH; this.LENGTH_FIELD_OFFSET = LENGTH_FIELD_OFFSET; this.LENGTH_ADJUSTMENT = LENGTH_ADJUSTMENT; this.INITIAL_BYTES_TO_STRIP = INITIAL_BYTES_TO_STRIP; &#125; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(new NewDecoder(MAX_FRAME_LENGTH,LENGTH_FIELD_LENGTH,LENGTH_FIELD_OFFSET,LENGTH_ADJUSTMENT,INITIAL_BYTES_TO_STRIP,false)); // 自己的逻辑Handler pipeline.addLast("handler", new NewServerHandler()); &#125;&#125; 上面用到了我们自己写的Decoder，接下来定义一个Decoder，继承LengthFieldBasedFrameDecoder，以方便我们做一些改写： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class NewDecoder extends LengthFieldBasedFrameDecoder &#123; /** * 我们在Message类中定义了type和length，这都放在消息头部 * type占1个字节，length占4个字节所以头部总长度是5个字节 */ private static final int HEADER_SIZE = 5; private byte type; private int length; private String msgBody; /** * * @param maxFrameLength 网络字节序，默认为大端字节序 * @param lengthFieldOffset 消息中长度字段偏移的字节数 * @param lengthFieldLength 数据帧的最大长度 * @param lengthAdjustment 该字段加长度字段等于数据帧的长度 * @param initialBytesToStrip 从数据帧中跳过的字节数 * @param failFast 如果为true，则表示读取到长度域，TA的值的超过maxFrameLength，就抛出一个 TooLongFrameException */ public NewDecoder(int maxFrameLength, int lengthFieldOffset, int lengthFieldLength, int lengthAdjustment, int initialBytesToStrip, boolean failFast) &#123; super(maxFrameLength, lengthFieldOffset, lengthFieldLength, lengthAdjustment, initialBytesToStrip, failFast); &#125; @Override protected Object decode(ChannelHandlerContext ctx, ByteBuf in) throws Exception &#123; if(in == null)&#123; return null; &#125; if(in.readableBytes() &lt; HEADER_SIZE)&#123; throw new Exception("错误的消息"); &#125; /** * 通过源码我们能看到在读的过程中 * 每读一次读过的字节即被抛弃 * 即指针会往前跳 */ type = in.readByte(); length = in.readByte(); if(in.readableBytes() &lt; length)&#123; throw new Exception("消息不正确"); &#125; ByteBuf buf = in.readBytes(length); byte[] b = new byte[buf.readableBytes()]; buf.readBytes(b); msgBody = new String(b,"UTF-8"); Message msg = new Message(type,length,msgBody); return msg; &#125;&#125; 在上面的NewDecoder中有一个HEADER_SIZE-消息头。上面也解释过了，我们在Message中定义的type和length分别占一个字节和4个字节（别问我为啥是4个哈）。所以我们的消息头就是5个字节啦。 接下来就是服务端的handler了： 12345678910public class NewServerHandler extends SimpleChannelInboundHandler&lt;Object&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext channelHandlerContext, Object o) throws Exception &#123; if(o instanceof Message) &#123; Message msg = (Message)o; System.out.println("Client-&gt;Server:"+channelHandlerContext.channel().remoteAddress()+" send "+msg.getMsgBody()); &#125; &#125;&#125; 在handler中我们用来接收已经被NewDecoder解码过后的客户端发送过来的消息。 下面是客户端： 12345678910111213141516171819202122232425262728293031323334public class NewClient &#123; private int port; private String address; public NewClient(int port,String address) &#123; this.port = port; this.address = address; &#125; public void start()&#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new NewClientChannelInitializer()); try &#123; ChannelFuture future = bootstrap.connect(address,port).sync(); future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; NewClient client = new NewClient(7788,"127.0.0.1"); client.start(); &#125;&#125; 客户端Initializer： 123456789public class NewClientChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(new NewEncoder()); pipeline.addLast(new NewClientHandler()); &#125;&#125; 客户端中我们又定义了一个编码器NewEncoder，继承了MessageToByteEncoder，该类用于将文本信息转换为流： 123456789101112131415161718public class NewEncoder extends MessageToByteEncoder&lt;Message&gt; &#123; @Override protected void encode(ChannelHandlerContext channelHandlerContext, Message message, ByteBuf byteBuf) throws Exception &#123; if(message == null)&#123; throw new Exception("未获得消息内容"); &#125; String msgBody = message.getMsgBody(); byte[] b = msgBody.getBytes(Charset.forName("utf-8")); byteBuf.writeByte(message.getType()); byteBuf.writeByte(b.length); byteBuf.writeBytes(b); &#125;&#125; 接下来是我们的客户端handler： 123456789public class NewClientHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; String m = "你好啊,Netty。昂昂"; Message msg = new Message((byte)0xCA, m.length(), m); ctx.writeAndFlush(msg); &#125;&#125; 注意到在handler中我们发送了一个Message对象。然后会由NewEncoder编码发送出去，服务端对消息解码获得消息头和消息体。分别启动服务端和客户端，打印结果为： 我们的消息就发送出去了。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习(八)-Netty的心跳机制]]></title>
    <url>%2Fposts%2F9afa0af8.html</url>
    <content type="text"><![CDATA[我们知道在TCP长连接或者WebSocket长连接中一般我们都会使用心跳机制–即发送特殊的数据包来通告对方自己的业务还没有办完，不要关闭链接。那么心跳机制可以用来做什么呢？我们知道网络的传输是不可靠的，当我们发起一个链接请求的过程之中会发生什么事情谁都无法预料，或者断电，服务器重启，断网线之类。如果有这种情况的发生对方也无法判断你是否还在线。所以这时候我们引入心跳机制，在长链接中双方没有数据交互的时候互相发送数据(可能是空包，也可能是特殊数据)，对方收到该数据之后也回复相应的数据用以确保双方都在线，这样就可以确保当前链接是有效的。 1. 如何实现心跳机制一般实现心跳机制由两种方式： TCP协议自带的心跳机制来实现； 在应用层来实现。 但是TCP协议自带的心跳机制系统默认是设置的是2小时的心跳频率。它检查不到机器断电、网线拔出、防火墙这些断线。而且逻辑层处理断线可能也不是那么好处理。另外该心跳机制是与TCP协议绑定的，那如果我们要是使用UDP协议岂不是用不了？所以一般我们都不用。 而一般我们自己实现呢大致的策略是这样的： Client启动一个定时器，不断发送心跳； Server收到心跳后，做出回应； Server启动一个定时器，判断Client是否存在，这里做判断有两种方法：时间差和简单标识。 时间差： 收到一个心跳包之后记录当前时间； 判断定时器到达时间，计算多久没收到心跳时间=当前时间-上次收到心跳时间。如果改时间大于设定值则认为超时。 简单标识： 收到心跳后设置连接标识为true; 判断定时器到达时间，如果未收到心跳则设置连接标识为false; 今天我们来看一下Netty的心跳机制的实现，在Netty中提供了IdleStateHandler类来进行心跳的处理，它可以对一个 Channel 的 读/写设置定时器, 当 Channel 在一定事件间隔内没有数据交互时(即处于 idle 状态), 就会触发指定的事件。 该类可以对三种类型的超时做心跳机制检测： 123public IdleStateHandler(int readerIdleTimeSeconds, int writerIdleTimeSeconds, int allIdleTimeSeconds) &#123; this((long)readerIdleTimeSeconds, (long)writerIdleTimeSeconds, (long)allIdleTimeSeconds, TimeUnit.SECONDS);&#125; readerIdleTimeSeconds：设置读超时时间； writerIdleTimeSeconds：设置写超时时间； allIdleTimeSeconds：同时为读或写设置超时时间； 下面我们还是通过一个例子来讲解IdleStateHandler的使用。 服务端： 12345678910111213141516171819202122232425262728293031public class HeartBeatServer &#123; private int port; public HeartBeatServer(int port) &#123; this.port = port; &#125; public void start()&#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); ServerBootstrap server = new ServerBootstrap().group(bossGroup,workGroup) .channel(NioServerSocketChannel.class) .childHandler(new HeartBeatServerChannelInitializer()); try &#123; ChannelFuture future = server.bind(port).sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HeartBeatServer server = new HeartBeatServer(7788); server.start(); &#125;&#125; 服务端Initializer： 1234567891011public class HeartBeatServerChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast("handler",new IdleStateHandler(3, 0, 0, TimeUnit.SECONDS)); pipeline.addLast("decoder", new StringDecoder()); pipeline.addLast("encoder", new StringEncoder()); pipeline.addLast(new HeartBeatServerHandler()); &#125;&#125; 在这里IdleStateHandler也是handler的一种，所以加入addLast。我们分别设置4个参数：读超时时间为3s，写超时和读写超时为0，然后加入时间控制单元。 服务端handler： 12345678910111213141516171819202122232425262728293031public class HeartBeatServerHandler extends ChannelInboundHandlerAdapter&#123; private int loss_connect_time = 0; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(ctx.channel().remoteAddress() + "Server :" + msg.toString()); &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if(evt instanceof IdleStateEvent)&#123; //服务端对应着读事件，当为READER_IDLE时触发 IdleStateEvent event = (IdleStateEvent)evt; if(event.state() == IdleState.READER_IDLE)&#123; loss_connect_time++; System.out.println("接收消息超时"); if(loss_connect_time &gt; 2)&#123; System.out.println("关闭不活动的链接"); ctx.channel().close(); &#125; &#125;else&#123; super.userEventTriggered(ctx,evt); &#125; &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125;&#125; 我们看到在handler中调用了userEventTriggered方法，IdleStateEvent的state()方法一个有三个值：READER_IDLE，WRITER_IDLE，ALL_IDLE。正好对应读事件写事件和读写事件。 再来写一下客户端： 123456789101112131415161718192021222324252627282930313233public class HeartBeatsClient &#123; private int port; private String address; public HeartBeatsClient(int port, String address) &#123; this.port = port; this.address = address; &#125; public void start()&#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new HeartBeatsClientChannelInitializer()); try &#123; ChannelFuture future = bootstrap.connect(address,port).sync(); future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HeartBeatsClient client = new HeartBeatsClient(7788,"127.0.0.1"); client.start(); &#125;&#125; 客户端Initializer： 1234567891011public class HeartBeatsClientChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast("handler", new IdleStateHandler(0, 3, 0, TimeUnit.SECONDS)); pipeline.addLast("decoder", new StringDecoder()); pipeline.addLast("encoder", new StringEncoder()); pipeline.addLast(new HeartBeatClientHandler()); &#125;&#125; 这里我们设置了IdleStateHandler的写超时为3秒，客户端执行的动作为写消息到服务端，服务端执行读动作。 客户端handler: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class HeartBeatClientHandler extends ChannelInboundHandlerAdapter &#123; private static final ByteBuf HEARTBEAT_SEQUENCE = Unpooled.unreleasableBuffer(Unpooled.copiedBuffer("Heartbeat", CharsetUtil.UTF_8)); private static final int TRY_TIMES = 3; private int currentTime = 0; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("激活时间是："+new Date()); System.out.println("链接已经激活"); ctx.fireChannelActive(); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("停止时间是："+new Date()); System.out.println("关闭链接"); &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; System.out.println("当前轮询时间："+new Date()); if (evt instanceof IdleStateEvent) &#123; IdleStateEvent event = (IdleStateEvent) evt; if (event.state() == IdleState.WRITER_IDLE) &#123; if(currentTime &lt;= TRY_TIMES)&#123; System.out.println("currentTime:"+currentTime); currentTime++; ctx.channel().writeAndFlush(HEARTBEAT_SEQUENCE.duplicate()); &#125; &#125; &#125; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String message = (String) msg; System.out.println(message); if (message.equals("Heartbeat")) &#123; ctx.write("has read message from server"); ctx.flush(); &#125; ReferenceCountUtil.release(msg); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125;&#125; 启动服务端和客户端我们看到输出为： 我们再来屡一下思路： 首先客户端激活channel，因为客户端中并没有发送消息所以会触发客户端的IdleStateHandler，它设置的写超时时间为3s； 然后触发客户端的事件机制进入userEventTriggered方法，在触发器中计数并向客户端发送消息； 服务端接收消息； 客户端触发器继续轮询发送消息，直到计数器满不再向服务端发送消息； 服务端在IdleStateHandler设置的读消息超时时间5s内未收到消息，触发了服务端中handler的userEventTriggered方法，于是关闭客户端的链接。 大体我们的简单心跳机制就是这样的思路，通过事件触发机制以及计数器的方式来实现，上面我们的案例中最后客户端没有发送消息的时候我们是强制断开了客户端的链接，那么既然可以关闭，我们是不是也可是重新链接客户端呢？因为万一客户端本身并不想关闭而是由于别的原因导致他无法与服务端通信。下面我们来说一下重连机制。 当我们的服务端在未读到客户端消息超时而关闭客户端的时候我们一般在客户端的finally块中方的是关闭客户端的代码，这时我们可以做一下修改的，finally是一定会被执行新的，所以我们可以在finally块中重新调用一下启动客户端的代码，这样就又重新启动了客户端了，上客户端代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 本Client为测试netty重连机制 * Server端代码都一样，所以不做修改 * 只用在client端中做一下判断即可 */public class HeartBeatsClient2 &#123; private int port; private String address; ChannelFuture future; public HeartBeatsClient2(int port, String address) &#123; this.port = port; this.address = address; &#125; public void start()&#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new HeartBeatsClientChannelInitializer()); try &#123; future = bootstrap.connect(address,port).sync(); future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; //group.shutdownGracefully(); if (null != future) &#123; if (future.channel() != null &amp;&amp; future.channel().isOpen()) &#123; future.channel().close(); &#125; &#125; System.out.println("准备重连"); start(); System.out.println("重连成功"); &#125; &#125; public static void main(String[] args) &#123; HeartBeatsClient2 client = new HeartBeatsClient2(7788,"127.0.0.1"); client.start(); &#125;&#125; 其余部分的代码与上面的实例并无异同，只需改造客户端即可，我们再运行服务端和客户端会看到客户端虽然被关闭了，但是立马又被重启： 当然生产级别的代码应该不是这样实现的吧，哈哈，下一节我们再好好探讨。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件-activemq安全机制]]></title>
    <url>%2Fposts%2F413284da.html</url>
    <content type="text"><![CDATA[activemq作为消息中间件这样一个独立的个体存在，连通用户和服务器。如果没有一套完备的安全机制去设置用户权限设置消息分发机制可想后果是非常严重。ActiveMQ如果不加入安全机制的话，任何人只要知道消息服务的具体地址(包括ip，端口，消息地址[队列或者主题地址，)，都可以肆无忌惮的发送、接收消息。今天我们就探讨一下他的安全机制。 1.安全机制介绍我们讨论安全机制一般包括两个部分： 验证(Authentication)：就是要验证一个用户的有效性，即用户名、密码是否正确; 授权(Authorization)：就是授予用户某种角色，以使用户只能访问具有相应角色的资源。 activemq考虑到安全方案效率问题，他提供了可插拔的安全机制，你可以使用不同的安全插件灵活为你的系统配置安全访问方式。目前activemq提供两种安全控制插件： 简单认证插件(Simple authentication plugin-in) JAAS认证插件(Java Authentication and Authorization Service) 下面我们分别就这两种插件的使用做一个说明。 2.简单认证插件简单认证插件的目的就是让用户简单配置。我们打开activemq服务的目录apache-activemq，在 conf目录下找到activemq.xml。进去找到： 123&lt;shutdownHooks&gt; &lt;bean xmlns="http://www.springframework.org/schema/beans" class="org.apache.activemq.hooks.SpringContextHook" /&gt;&lt;/shutdownHooks&gt; 在他下面添加如下即可： 12345678&lt;plugins&gt; &lt;simpleAuthenticationPlugin&gt; &lt;users&gt; &lt;authenticationUser username="admin" password="admin" groups="users,admins"/&gt; &lt;authenticationUser username="user" password="password" groups="users"/&gt; &lt;/users&gt; &lt;/simpleAuthenticationPlugin&gt;&lt;/plugins&gt; ☆注意：此处添加的用户名和密码要和你在项目中配置的activemq用户名密码是一致的，如果在项目中不是此处已经配置过的用户发送消息的话，activemq客户端不会受理该消息。这样就达到了对非命中用户拦截的目的。 比如说你有客户端使用的用户是： 1234&lt;amq:connectionFactory id="amqConnectionFactory" brokerURL="tcp://127.0.0.1:61616" userName="admin" password="admin" /&gt; 那你就把该用户配置到activemq的配置文件中： 1&lt;authenticationUser username="admin" password="admin" groups="users,admins"/&gt; 上面是对用户进行限制，我们也可以对ip进行限制，还是在刚才的配置里面加上下面这一句： 12345678910111213&lt;plugins&gt; &lt;simpleAuthenticationPlugin&gt; &lt;users&gt; &lt;authenticationUser username="admin" password="admin" groups="users,admins"/&gt; &lt;!-- &lt;authenticationUser username="user" password="password" groups="users"/&gt; &lt;authenticationUser username="guest" password="password" groups="guests"/&gt;--&gt; &lt;/users&gt; &lt;transportConnectors&gt; &lt;transportConnector name="connection1" uri="tcp://0.0.0.0:61616" /&gt; &lt;/transportConnectors&gt; &lt;/simpleAuthenticationPlugin&gt;&lt;/plugins&gt; 0.0.0.0代表本网络中的所有主机，意味着该网段的所有主机都是可以通讯的。如果改成localhost或者127.0.0.1这种的那就只有本机了。这样我们就达到了通过IP限制的目的。 3.JAAS认证插件JAAS(Java Authentication and Authorization Service)也就是java的验证Authentication)、授权(Authorization)服务。简单来说，验证Authentication就是要验证一个用户的有效性，即用户名、密码是否正确。授权Authorization就是授予用户某种角色，可以访问哪些资源。JAASAuthentication Plugin依赖标准的JAAS机制来实现认证。通常情况下，你需要通过设置Java.security.auth.login.config系统属性来配置loginmodules的配置文件。如果没有指定这个系统属性，那么JAAS Authentication Plugin会缺省使用login.config作为文件名。 首先我们需要编写一个login.config文件： 123456activemq &#123; org.apache.activemq.jaas.PropertiesLoginModule required debug=true org.apache.activemq.jaas.properties.user="users.properties" org.apache.activemq.jaas.properties.group="groups.properties"; &#125;; users.properties文件： 123admin=admin user=ad1guest=ad1 group.properties文件： 123admins=admin users=user guests=guest ☆需要注意的是，PropertiesLoginModule使用本地文件的查找方式，而且查找时采用的base directory即login.config文件所在的目录，所以说这三个文件需要在同一个目录里才会找得到。另外，activemq 5.9 默认提供了以上的配置文件，我们来看一下文件目录： 然后我们还是在activemq.xml配置文件中添加插件。还是上面简单插件添加的位置，添加以下插件即可，只不过你的把之前添加的简单插件注释掉。 123456789101112131415161718192021&lt;plugins&gt; &lt;jaasAuthenticationPlugin configuration="activemq-domain" /&gt; &lt;authorizationPlugin&gt; &lt;map&gt; &lt;authorizationMap&gt; &lt;authorizationEntries&gt; &lt;!-- .表示通配符,例如USERS.&gt;表示以USERS.开头的主题,&gt;表示所有主题,read表示读的权限,write表示写的权限，admin表示角色组--&gt; &lt;authorizationEntry queue="&gt;" read="admins,guests" write="guests" admin="admins,guests" /&gt; &lt;authorizationEntry queue="USERS.&gt;" read="users" write="users" admin="users" /&gt; &lt;authorizationEntry queue="GUEST.&gt;" read="guests" write="guests,users" admin="guests,users" /&gt; &lt;authorizationEntry topic="&gt;" read="admins" write="admins" admin="admins" /&gt; &lt;authorizationEntry topic="USERS.&gt;" read="users" write="users" admin="users" /&gt; &lt;authorizationEntry topic="GUEST.&gt;" read="guests" write="guests,users" admin="guests,users" /&gt; &lt;authorizationEntry topic="ActiveMQ.Advisory.&gt;" read="guests,users" write="guests,users" admin="guests,users"/&gt; &lt;/authorizationEntries&gt; &lt;/authorizationMap&gt; &lt;/map&gt; &lt;/authorizationPlugin&gt;&lt;/plugins&gt; 添加完以上配置部分，重启avtivemq服务端，就会按照上面配置的用户进行读写的权限配置。 从上面看JAAS插件的权限分配要比简单插件的权限更加细致，不同的用户可以分别配置读写的权限，admin用户拥有创建topic或是queue的特权等等这样细致的划分，不同的用户各司其职，减少了误操作，或是刻意破换的可能性。]]></content>
      <categories>
        <category>activeMQ</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习-NIO(二)Buffer]]></title>
    <url>%2Fposts%2Fe8d11d6a.html</url>
    <content type="text"><![CDATA[当我们需要与 NIO Channel 进行交互时, 我们就需要使用到 NIO Buffer, 即数据从 Buffer读取到 Channel 中, 并且从 Channel 中写入到 Buffer 中。缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。 缓冲区基础Buffer 类型有: 缓冲区是包在一个对象内的基础数据的数组，Buffer类相比一般简单数组而言其优点是将数据的内容和相关信息放在一个对象里面，这个对象提供了处理缓冲区数据的丰富的API。 所有缓冲区都有4个属性：capacity、limit、position、mark，并遵循：capacity&gt;=limit&gt;=position&gt;=mark&gt;=0，下面是对这4个属性的解释： Capacity:&nbsp;&nbsp;&nbsp;&nbsp; 容量，即可以容纳的最大数据量；在缓冲区创建时被设定并且不能改变 Limit:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上界，缓冲区中当前数据量 Position: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;位置，下一个要被读或写的元素的索引 Mark:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;标记，调用mark()来设置mark=position，再调用reset()可以让position恢复到标记的位置即position=mark 我们通过一个简单的操作流程来说明buffer的使用，下图是新创建的容量为10的缓冲区逻辑视图： 然后进行5次调用put：buffer.put((byte)’A’).put((byte)’B’).put((byte)’C’).put((byte)’D’).put((byte)’E’) 5次调用put之后的缓冲区为： 现在缓冲区满了，我们必须将其清空。我们想把这个缓冲区传递给一个通道，以使内容能被全部写出，但现在执行get()无疑会取出未定义的数据。我们必须将 posistion设为0，然后通道就会从正确的位置开始读了，但读到哪算读完了呢？这正是limit引入的原因，它指明缓冲区有效内容的未端。这个操作 在缓冲区中叫做翻转：buffer.flip()。 Buffer的基本用法使用Buffer读写数据一般遵循以下四个步骤： 写入数据到Buffer 调用flip()方法 从Buffer中读取数据 调用clear()方法或者compact()方法 当向buffer写入数据时，buffer会记录下写了多少数据。 一旦要读取数据，需要通过flip()方法将Buffer从写模式切换到读模式。在读模式下，可以读取之前写入到buffer的所有数据。 一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear()或compact()方法。clear()方法会清空整个缓冲区。compact()方法只会清除已经读过的数据。任何未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。 下面我们看一段程序来看一下Buffer的基本用法： 12345678910111213141516171819202122232425262728public static void readFile(String fileName) &#123; RandomAccessFile aFile = null; try &#123; //文件流 aFile = new RandomAccessFile(fileName, "rw"); //将文件输入到管道 FileChannel inChannel = aFile.getChannel(); //为buffer分配1024个字节大小的空间 ByteBuffer buf = ByteBuffer.allocate(1024); //将buffer中的内容读取到管道中 int bytesRead = inChannel.read(buf); while (bytesRead != -1) &#123; //反转buffer，将写模式改为读模式 buf.flip(); while (buf.hasRemaining()) &#123; //获取buffer中的数据 System.out.print((char) buf.get()); &#125; //将上次分配的1024字节的内容清空，为下次接收做准备 buf.clear(); //管道重新读取buffer中的内容 bytesRead = inChannel.read(buf); &#125; aFile.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 字节缓冲区我们将进一步观察字节缓冲区。所有的基本数据类型都有相应的缓冲区类（布尔型除外），但字节缓冲区有自己的独特之处。字节是操作系统及其I/O设备使用的基本数据类型。当在JVM和操作系统间传递数据时，将其他的数据类型拆分成构成它们的字节是十分必要的。如我们在后面的章节中将要看到的那样，系统层次的I/O面向字节的性质可以在整个缓冲区的设计以及它们互相配合的服务中感受到。 直接缓冲区我们知道操作系统是在内存中进行I/O操作，这些内存区域，就操作系统方面而言，是相连的字节序列。于是，毫无疑问，只有字节缓冲区有资格参与I/O操作。即操作系统会直接存取进程，那么我们现在在JVM中进行操作，java中的内存空间是由JVM直接进行管理，但是在JVM中，字节数组可能不会在内存中连续存储，或者无用存储单元收集可能随时对其进行移动，这就不能保证I/O操作的目标是连续的。 出于这一原因，引入了直接缓冲区的概念。直接缓冲区被用于与通道和固有I/O例程交互。它们通过使用固有代码来告知操作系统直接释放或填充内存区域，对用于通道直接或原始存取的内存区域中的字节元素的存储尽了最大的努力。 直接字节缓冲区通常是I/O操作最好的选择。在设计方面，它们支持JVM可用的最高效I/O机制。非直接字节缓冲区可以被传递给通道，但是这样可能导致性能损耗。通常非直接缓冲不可能成为一个本地I/O操作的目标。如果您向一个通道中传递一个非直接ByteBuffer对象用于写入，通道可能会在每次调用中隐含地进行下面的操作： 创建一个临时的直接ByteBuffer对象。 将非直接缓冲区的内容复制到临时缓冲中。 使用临时缓冲区执行低层次I/O操作。 临时缓冲区对象离开作用域，并最终成为被回收的无用数据。 视图缓冲区就像我们已经讨论的那样，I/O基本上可以归结成组字节数据的四处传递。在进行大数据量的I/O操作时，很又可能你会使用各种ByteBuffer类去读取文件内容，接收来自网络连接的数据，等等。一旦数据到达了你的ByteBuffer，您就需要查看它以决定怎么做或者在将它发送出去之前对它进行一些操作。ByteBuffer类提供了丰富的API来创建视图缓冲区。 视图缓冲区通过已存在的缓冲区对象实例的工厂方法来创建。这种视图对象维护它自己的属性，容量，位置，上界和标记，但是和原来的缓冲区共享数据元素。但是ByteBuffer类允许创建视图来将byte型缓冲区字节数据映射为其它的原始数据类型。例如，asLongBuffer()函数创建一个将八个字节型数据当成一个long型数据来存取的视图缓冲区。 但是使用视图缓冲区的话，一旦ByteBuffer对于视图的维护对象产生非常规行的使用，那么对于工厂方法创建的缓冲区而言，asLongBuffer()函数就不在使用这个视窗，那么这个8字节的数据当成一个long类型的数据类型来存取的数据视图。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习(十)-Netty文件上传]]></title>
    <url>%2Fposts%2F208253d2.html</url>
    <content type="text"><![CDATA[今天我们来完成一个使用netty进行文件传输的任务。在实际项目中，文件传输通常采用FTP或者HTTP附件的方式。事实上通过TCP Socket+File的方式进行文件传输也有一定的应用场景，尽管不是主流，但是掌握这种文件传输方式还是比较重要的，特别是针对两个跨主机的JVM进程之间进行持久化数据的相互交换。 而使用netty来进行文件传输也是利用netty天然的优势：零拷贝功能。很多同学都听说过netty的”零拷贝”功能，但是具体体现在哪里又不知道，下面我们就简要介绍下： Netty的“零拷贝”主要体现在如下三个方面： 1) Netty的接收和发送ByteBuffer采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才写入Socket中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。 2) Netty提供了组合Buffer对象，可以聚合多个ByteBuffer对象，用户可以像操作一个Buffer那样方便的对组合Buffer进行操作，避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的Buffer。 3) Netty的文件传输采用了transferTo方法，它可以直接将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题。 具体的分析在此就不多做介绍，有兴趣的可以查阅相关文档。我们还是把重点放在文件传输上。Netty作为高性能的服务器端异步IO框架必然也离不开文件读写功能，我们可以使用netty模拟http的形式通过网页上传文件写入服务器，当然要使用http的形式那你也用不着netty！大材小用。netty4中如果想使用http形式上传文件你还得借助第三方jar包：okhttp。使用该jar完成http请求的发送。但是在netty5 中已经为我们写好了，我们可以直接调用netty5的API就可以实现。所以netty4和5的差别还是挺大的，至于使用哪个，那就看你们公司选择哪一个了！本文目前使用netty4来实现文件上传功能。下面我们上代码： pom文件： 12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.5.Final&lt;/version&gt;&lt;/dependency&gt; server端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.Channel;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.codec.serialization.ClassResolvers;import io.netty.handler.codec.serialization.ObjectDecoder;import io.netty.handler.codec.serialization.ObjectEncoder;public class FileUploadServer &#123; public void bind(int port) throws Exception &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class).option(ChannelOption.SO_BACKLOG, 1024).childHandler(new ChannelInitializer&lt;Channel&gt;() &#123; @Override protected void initChannel(Channel ch) throws Exception &#123; ch.pipeline().addLast(new ObjectEncoder()); ch.pipeline().addLast(new ObjectDecoder(Integer.MAX_VALUE, ClassResolvers.weakCachingConcurrentResolver(null))); // 最大长度 ch.pipeline().addLast(new FileUploadServerHandler()); &#125; &#125;); ChannelFuture f = b.bind(port).sync(); f.channel().closeFuture().sync(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; e.printStackTrace(); &#125; &#125; try &#123; new FileUploadServer().bind(port); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; server端handler： 12345678910111213141516171819202122232425262728293031323334353637383940import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import java.io.File;import java.io.RandomAccessFile;public class FileUploadServerHandler extends ChannelInboundHandlerAdapter &#123; private int byteRead; private volatile int start = 0; private String file_dir = "D:"; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof FileUploadFile) &#123; FileUploadFile ef = (FileUploadFile) msg; byte[] bytes = ef.getBytes(); byteRead = ef.getEndPos(); String md5 = ef.getFile_md5();//文件名 String path = file_dir + File.separator + md5; File file = new File(path); RandomAccessFile randomAccessFile = new RandomAccessFile(file, "rw"); randomAccessFile.seek(start); randomAccessFile.write(bytes); start = start + byteRead; if (byteRead &gt; 0) &#123; ctx.writeAndFlush(start); &#125; else &#123; randomAccessFile.close(); ctx.close(); &#125; &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; client端： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import io.netty.bootstrap.Bootstrap;import io.netty.channel.Channel;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioSocketChannel;import io.netty.handler.codec.serialization.ClassResolvers;import io.netty.handler.codec.serialization.ObjectDecoder;import io.netty.handler.codec.serialization.ObjectEncoder;import java.io.File;public class FileUploadClient &#123; public void connect(int port, String host, final FileUploadFile fileUploadFile) throws Exception &#123; EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class).option(ChannelOption.TCP_NODELAY, true).handler(new ChannelInitializer&lt;Channel&gt;() &#123; @Override protected void initChannel(Channel ch) throws Exception &#123; ch.pipeline().addLast(new ObjectEncoder()); ch.pipeline().addLast(new ObjectDecoder(ClassResolvers.weakCachingConcurrentResolver(null))); ch.pipeline().addLast(new FileUploadClientHandler(fileUploadFile)); &#125; &#125;); ChannelFuture f = b.connect(host, port).sync(); f.channel().closeFuture().sync(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; e.printStackTrace(); &#125; &#125; try &#123; FileUploadFile uploadFile = new FileUploadFile(); File file = new File("c:/1.txt"); String fileMd5 = file.getName();// 文件名 uploadFile.setFile(file); uploadFile.setFile_md5(fileMd5); uploadFile.setStarPos(0);// 文件开始位置 new FileUploadClient().connect(port, "127.0.0.1", uploadFile); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; client端handler： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import java.io.FileNotFoundException;import java.io.IOException;import java.io.RandomAccessFile;public class FileUploadClientHandler extends ChannelInboundHandlerAdapter &#123; private int byteRead; private volatile int start = 0; private volatile int lastLength = 0; public RandomAccessFile randomAccessFile; private FileUploadFile fileUploadFile; public FileUploadClientHandler(FileUploadFile ef) &#123; if (ef.getFile().exists()) &#123; if (!ef.getFile().isFile()) &#123; System.out.println("Not a file :" + ef.getFile()); return; &#125; &#125; this.fileUploadFile = ef; &#125; public void channelActive(ChannelHandlerContext ctx) &#123; try &#123; randomAccessFile = new RandomAccessFile(fileUploadFile.getFile(), "r"); randomAccessFile.seek(fileUploadFile.getStarPos()); lastLength = (int) randomAccessFile.length() / 10; byte[] bytes = new byte[lastLength]; if ((byteRead = randomAccessFile.read(bytes)) != -1) &#123; fileUploadFile.setEndPos(byteRead); fileUploadFile.setBytes(bytes); ctx.writeAndFlush(fileUploadFile); &#125; else &#123; System.out.println("文件已经读完"); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException i) &#123; i.printStackTrace(); &#125; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof Integer) &#123; start = (Integer) msg; if (start != -1) &#123; randomAccessFile = new RandomAccessFile(fileUploadFile.getFile(), "r"); randomAccessFile.seek(start); System.out.println("块儿长度：" + (randomAccessFile.length() / 10)); System.out.println("长度：" + (randomAccessFile.length() - start)); int a = (int) (randomAccessFile.length() - start); int b = (int) (randomAccessFile.length() / 10); if (a &lt; b) &#123; lastLength = a; &#125; byte[] bytes = new byte[lastLength]; System.out.println("-----------------------------" + bytes.length); if ((byteRead = randomAccessFile.read(bytes)) != -1 &amp;&amp; (randomAccessFile.length() - start) &gt; 0) &#123; System.out.println("byte 长度：" + bytes.length); fileUploadFile.setEndPos(byteRead); fileUploadFile.setBytes(bytes); try &#123; ctx.writeAndFlush(fileUploadFile); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; else &#123; randomAccessFile.close(); ctx.close(); System.out.println("文件已经读完--------" + byteRead); &#125; &#125; &#125; &#125; // @Override // public void channelRead(ChannelHandlerContext ctx, Object msg) throws // Exception &#123; // System.out.println("Server is speek ："+msg.toString()); // FileRegion filer = (FileRegion) msg; // String path = "E://Apk//APKMD5.txt"; // File fl = new File(path); // fl.createNewFile(); // RandomAccessFile rdafile = new RandomAccessFile(path, "rw"); // FileRegion f = new DefaultFileRegion(rdafile.getChannel(), 0, // rdafile.length()); // // System.out.println("This is" + ++counter + "times receive server:[" // + msg + "]"); // &#125; // @Override // public void channelReadComplete(ChannelHandlerContext ctx) throws // Exception &#123; // ctx.flush(); // &#125; public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close(); &#125; // @Override // protected void channelRead0(ChannelHandlerContext ctx, String msg) // throws Exception &#123; // String a = msg; // System.out.println("This is"+ // ++counter+"times receive server:["+msg+"]"); // &#125;&#125; 我们还自定义了一个对象，用于统计文件上传进度的： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.io.File;import java.io.Serializable;public class FileUploadFile implements Serializable &#123; private static final long serialVersionUID = 1L; private File file;// 文件 private String file_md5;// 文件名 private int starPos;// 开始位置 private byte[] bytes;// 文件字节数组 private int endPos;// 结尾位置 public int getStarPos() &#123; return starPos; &#125; public void setStarPos(int starPos) &#123; this.starPos = starPos; &#125; public int getEndPos() &#123; return endPos; &#125; public void setEndPos(int endPos) &#123; this.endPos = endPos; &#125; public byte[] getBytes() &#123; return bytes; &#125; public void setBytes(byte[] bytes) &#123; this.bytes = bytes; &#125; public File getFile() &#123; return file; &#125; public void setFile(File file) &#123; this.file = file; &#125; public String getFile_md5() &#123; return file_md5; &#125; public void setFile_md5(String file_md5) &#123; this.file_md5 = file_md5; &#125;&#125; 输出为： 块儿长度：894 长度：8052 -----------------------------894 byte 长度：894 块儿长度：894 长度：7158 -----------------------------894 byte 长度：894 块儿长度：894 长度：6264 -----------------------------894 byte 长度：894 块儿长度：894 长度：5370 -----------------------------894 byte 长度：894 块儿长度：894 长度：4476 -----------------------------894 byte 长度：894 块儿长度：894 长度：3582 -----------------------------894 byte 长度：894 块儿长度：894 长度：2688 -----------------------------894 byte 长度：894 块儿长度：894 长度：1794 -----------------------------894 byte 长度：894 块儿长度：894 长度：900 -----------------------------894 byte 长度：894 块儿长度：894 长度：6 -----------------------------6 byte 长度：6 块儿长度：894 长度：0 -----------------------------0 文件已经读完--------0 Process finished with exit code 0 这样就实现了服务器端文件的上传，当然我们也可以使用http的形式。 server端： 12345678910111213141516171819202122232425262728293031323334353637383940import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioServerSocketChannel;public class HttpFileServer implements Runnable &#123; private int port; public HttpFileServer(int port) &#123; super(); this.port = port; &#125; @Override public void run() &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workerGroup); serverBootstrap.channel(NioServerSocketChannel.class); //serverBootstrap.handler(new LoggingHandler(LogLevel.INFO)); serverBootstrap.childHandler(new HttpChannelInitlalizer()); try &#123; ChannelFuture f = serverBootstrap.bind(port).sync(); f.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HttpFileServer b = new HttpFileServer(9003); new Thread(b).start(); &#125;&#125; Server端initializer： 1234567891011121314151617181920import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelPipeline;import io.netty.channel.socket.SocketChannel;import io.netty.handler.codec.http.HttpObjectAggregator;import io.netty.handler.codec.http.HttpServerCodec;import io.netty.handler.stream.ChunkedWriteHandler;public class HttpChannelInitlalizer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new HttpServerCodec()); pipeline.addLast(new HttpObjectAggregator(65536)); pipeline.addLast(new ChunkedWriteHandler()); pipeline.addLast(new HttpChannelHandler()); &#125;&#125; server端hadler： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178import static io.netty.handler.codec.http.HttpHeaders.Names.CONTENT_TYPE;import static io.netty.handler.codec.http.HttpResponseStatus.BAD_REQUEST;import static io.netty.handler.codec.http.HttpResponseStatus.FORBIDDEN;import static io.netty.handler.codec.http.HttpResponseStatus.INTERNAL_SERVER_ERROR;import static io.netty.handler.codec.http.HttpResponseStatus.NOT_FOUND;import static io.netty.handler.codec.http.HttpVersion.HTTP_1_1;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelFutureListener;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelProgressiveFuture;import io.netty.channel.ChannelProgressiveFutureListener;import io.netty.channel.SimpleChannelInboundHandler;import io.netty.handler.codec.http.DefaultFullHttpResponse;import io.netty.handler.codec.http.DefaultHttpResponse;import io.netty.handler.codec.http.FullHttpRequest;import io.netty.handler.codec.http.FullHttpResponse;import io.netty.handler.codec.http.HttpChunkedInput;import io.netty.handler.codec.http.HttpHeaders;import io.netty.handler.codec.http.HttpResponse;import io.netty.handler.codec.http.HttpResponseStatus;import io.netty.handler.codec.http.HttpVersion;import io.netty.handler.codec.http.LastHttpContent;import io.netty.handler.stream.ChunkedFile;import io.netty.util.CharsetUtil;import io.netty.util.internal.SystemPropertyUtil;import java.io.File;import java.io.FileNotFoundException;import java.io.RandomAccessFile;import java.io.UnsupportedEncodingException;import java.net.URLDecoder;import java.util.regex.Pattern;import javax.activation.MimetypesFileTypeMap;public class HttpChannelHandler extends SimpleChannelInboundHandler&lt;FullHttpRequest&gt; &#123; public static final String HTTP_DATE_FORMAT = "EEE, dd MMM yyyy HH:mm:ss zzz"; public static final String HTTP_DATE_GMT_TIMEZONE = "GMT"; public static final int HTTP_CACHE_SECONDS = 60; @Override protected void channelRead0(ChannelHandlerContext ctx, FullHttpRequest request) throws Exception &#123; // 监测解码情况 if (!request.getDecoderResult().isSuccess()) &#123; sendError(ctx, BAD_REQUEST); return; &#125; final String uri = request.getUri(); final String path = sanitizeUri(uri); System.out.println("get file："+path); if (path == null) &#123; sendError(ctx, FORBIDDEN); return; &#125; //读取要下载的文件 File file = new File(path); if (file.isHidden() || !file.exists()) &#123; sendError(ctx, NOT_FOUND); return; &#125; if (!file.isFile()) &#123; sendError(ctx, FORBIDDEN); return; &#125; RandomAccessFile raf; try &#123; raf = new RandomAccessFile(file, "r"); &#125; catch (FileNotFoundException ignore) &#123; sendError(ctx, NOT_FOUND); return; &#125; long fileLength = raf.length(); HttpResponse response = new DefaultHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); HttpHeaders.setContentLength(response, fileLength); setContentTypeHeader(response, file); //setDateAndCacheHeaders(response, file); if (HttpHeaders.isKeepAlive(request)) &#123; response.headers().set("CONNECTION", HttpHeaders.Values.KEEP_ALIVE); &#125; // Write the initial line and the header. ctx.write(response); // Write the content. ChannelFuture sendFileFuture = ctx.write(new HttpChunkedInput(new ChunkedFile(raf, 0, fileLength, 8192)), ctx.newProgressivePromise()); //sendFuture用于监视发送数据的状态 sendFileFuture.addListener(new ChannelProgressiveFutureListener() &#123; @Override public void operationProgressed(ChannelProgressiveFuture future, long progress, long total) &#123; if (total &lt; 0) &#123; // total unknown System.err.println(future.channel() + " Transfer progress: " + progress); &#125; else &#123; System.err.println(future.channel() + " Transfer progress: " + progress + " / " + total); &#125; &#125; @Override public void operationComplete(ChannelProgressiveFuture future) &#123; System.err.println(future.channel() + " Transfer complete."); &#125; &#125;); // Write the end marker ChannelFuture lastContentFuture = ctx.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT); // Decide whether to close the connection or not. if (!HttpHeaders.isKeepAlive(request)) &#123; // Close the connection when the whole content is written out. lastContentFuture.addListener(ChannelFutureListener.CLOSE); &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); if (ctx.channel().isActive()) &#123; sendError(ctx, INTERNAL_SERVER_ERROR); &#125; ctx.close(); &#125; private static final Pattern INSECURE_URI = Pattern.compile(".*[&lt;&gt;&amp;\"].*"); private static String sanitizeUri(String uri) &#123; // Decode the path. try &#123; uri = URLDecoder.decode(uri, "UTF-8"); &#125; catch (UnsupportedEncodingException e) &#123; throw new Error(e); &#125; if (!uri.startsWith("/")) &#123; return null; &#125; // Convert file separators. uri = uri.replace('/', File.separatorChar); // Simplistic dumb security check. // You will have to do something serious in the production environment. if (uri.contains(File.separator + '.') || uri.contains('.' + File.separator) || uri.startsWith(".") || uri.endsWith(".") || INSECURE_URI.matcher(uri).matches()) &#123; return null; &#125; // Convert to absolute path. return SystemPropertyUtil.get("user.dir") + File.separator + uri; &#125; private static void sendError(ChannelHandlerContext ctx, HttpResponseStatus status) &#123; FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, status, Unpooled.copiedBuffer("Failure: " + status + "\r\n", CharsetUtil.UTF_8)); response.headers().set(CONTENT_TYPE, "text/plain; charset=UTF-8"); // Close the connection as soon as the error message is sent. ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE); &#125; /** * Sets the content type header for the HTTP Response * * @param response * HTTP response * @param file * file to extract content type */ private static void setContentTypeHeader(HttpResponse response, File file) &#123; MimetypesFileTypeMap m = new MimetypesFileTypeMap(); String contentType = m.getContentType(file.getPath()); if (!contentType.equals("application/octet-stream")) &#123; contentType += "; charset=utf-8"; &#125; response.headers().set(CONTENT_TYPE, contentType); &#125;&#125; client端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import io.netty.bootstrap.Bootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import io.netty.handler.codec.http.DefaultFullHttpRequest;import io.netty.handler.codec.http.HttpHeaders;import io.netty.handler.codec.http.HttpMethod;import io.netty.handler.codec.http.HttpRequestEncoder;import io.netty.handler.codec.http.HttpResponseDecoder;import io.netty.handler.codec.http.HttpVersion;import io.netty.handler.stream.ChunkedWriteHandler;import java.net.URI;public class HttpDownloadClient &#123; /** * 下载http资源 向服务器下载直接填写要下载的文件的相对路径 * （↑↑↑建议只使用字母和数字对特殊字符对字符进行部分过滤可能导致异常↑↑↑） * 向互联网下载输入完整路径 * @param host 目的主机ip或域名 * @param port 目标主机端口 * @param url 文件路径 * @param local 本地存储路径 * @throws Exception */ public void connect(String host, int port, String url, final String local) throws Exception &#123; EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; Bootstrap b = new Bootstrap(); b.group(workerGroup); b.channel(NioSocketChannel.class); b.option(ChannelOption.SO_KEEPALIVE, true); b.handler(new ChildChannelHandler(local)); // Start the client. ChannelFuture f = b.connect(host, port).sync(); URI uri = new URI(url); DefaultFullHttpRequest request = new DefaultFullHttpRequest( HttpVersion.HTTP_1_1, HttpMethod.GET, uri.toASCIIString()); // 构建http请求 request.headers().set(HttpHeaders.Names.HOST, host); request.headers().set(HttpHeaders.Names.CONNECTION, HttpHeaders.Values.KEEP_ALIVE); request.headers().set(HttpHeaders.Names.CONTENT_LENGTH, request.content().readableBytes()); // 发送http请求 f.channel().write(request); f.channel().flush(); f.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); &#125; &#125; private class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; &#123; String local; public ChildChannelHandler(String local) &#123; this.local = local; &#125; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; // 客户端接收到的是httpResponse响应，所以要使用HttpResponseDecoder进行解码 ch.pipeline().addLast(new HttpResponseDecoder()); // 客户端发送的是httprequest，所以要使用HttpRequestEncoder进行编码 ch.pipeline().addLast(new HttpRequestEncoder()); ch.pipeline().addLast(new ChunkedWriteHandler()); ch.pipeline().addLast(new HttpDownloadHandler(local)); &#125; &#125; public static void main(String[] args) throws Exception &#123; HttpDownloadClient client = new HttpDownloadClient(); //client.connect("127.0.0.1", 9003,"/file/pppp/1.doc","1.doc");// client.connect("zlysix.gree.com", 80, "http://zlysix.gree.com/HelloWeb/download/20m.apk", "20m.apk"); client.connect("www.ghost64.com", 80, "http://www.ghost64.com/qqtupian/zixunImg/local/2017/05/27/1495855297602.jpg", "1495855297602.jpg"); &#125;&#125; client端handler： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596import java.io.File;import java.io.FileOutputStream;import io.netty.buffer.ByteBuf;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import io.netty.handler.codec.http.HttpContent;//import io.netty.handler.codec.http.HttpHeaders;import io.netty.handler.codec.http.HttpResponse;import io.netty.handler.codec.http.LastHttpContent;import io.netty.util.internal.SystemPropertyUtil;/** * @Author:yangyue * @Description: * @Date: Created in 9:15 on 2017/5/28. */public class HttpDownloadHandler extends ChannelInboundHandlerAdapter &#123; private boolean readingChunks = false; // 分块读取开关 private FileOutputStream fOutputStream = null;// 文件输出流 private File localfile = null;// 下载文件的本地对象 private String local = null;// 待下载文件名 private int succCode;// 状态码 public HttpDownloadHandler(String local) &#123; this.local = local; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof HttpResponse) &#123;// response头信息 HttpResponse response = (HttpResponse) msg; succCode = response.getStatus().code(); if (succCode == 200) &#123; setDownLoadFile();// 设置下载文件 readingChunks = true; &#125; // System.out.println("CONTENT_TYPE:" // + response.headers().get(HttpHeaders.Names.CONTENT_TYPE)); &#125; if (msg instanceof HttpContent) &#123;// response体信息 HttpContent chunk = (HttpContent) msg; if (chunk instanceof LastHttpContent) &#123; readingChunks = false; &#125; ByteBuf buffer = chunk.content(); byte[] dst = new byte[buffer.readableBytes()]; if (succCode == 200) &#123; while (buffer.isReadable()) &#123; buffer.readBytes(dst); fOutputStream.write(dst); buffer.release(); &#125; if (null != fOutputStream) &#123; fOutputStream.flush(); &#125; &#125; &#125; if (!readingChunks) &#123; if (null != fOutputStream) &#123; System.out.println("Download done-&gt;"+ localfile.getAbsolutePath()); fOutputStream.flush(); fOutputStream.close(); localfile = null; fOutputStream = null; &#125; ctx.channel().close(); &#125; &#125; /** * 配置本地参数，准备下载 */ private void setDownLoadFile() throws Exception &#123; if (null == fOutputStream) &#123; local = SystemPropertyUtil.get("user.dir") + File.separator +local; //System.out.println(local); localfile = new File(local); if (!localfile.exists()) &#123; localfile.createNewFile(); &#125; fOutputStream = new FileOutputStream(localfile); &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; System.out.println("管道异常：" + cause.getMessage()); cause.printStackTrace(); ctx.channel().close(); &#125;&#125; 这里客户端我放的是网络连接，下载的是一副图片，启动服务端和客户端就可以看到这个图片被下载到了工程的根目录下。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习-NIO(四)Selector]]></title>
    <url>%2Fposts%2Fe87423e8.html</url>
    <content type="text"><![CDATA[这一节我们将探索选择器(selectors)。选择器提供选择执行已经就绪的任务的能力，这使得多元 I/O 成为可能。就像在第一章中描述的那样，就绪选择和多元执行使得单线程能够有效率地同时管理多个 I/O 通道(channels)。C/C++代码的工具箱中，许多年前就已经有 select()和 poll()这两个POSIX（可移植性操作系统接口）系统调用可供使用了。许过操作系统也提供相似的功能，但对Java 程序员来说，就绪选择功能直到 JDK 1.4 才成为可行的方案。 下面我们来使用选择器： 通过 Selector.open()方法, 我们可以创建一个选择器: 1Selector selector = Selector.open(); 将 Channel 注册到选择器中： 123channel.configureBlocking(false); SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 注意, 如果一个 Channel 要注册到 Selector 中, 那么这个 Channel 必须是非阻塞的, 即channel.configureBlocking(false);因为 Channel 必须要是非阻塞的, 因此 FileChannel 不能够使用选择器, 因为 FileChannel 都是阻塞的. 注意到, 在使用 Channel.register()方法时, 第二个参数指定了我们对 Channel 的什么类型的事件感兴趣, 这些事件有: Connect, 即连接事件(TCP 连接), 对应于SelectionKey.OP_CONNECT Accept, 即确认事件, 对应于SelectionKey.OP_ACCEPT Read, 即读事件, 对应于SelectionKey.OP_READ, 表示 buffer 可读. Write, 即写事件, 对应于SelectionKey.OP_WRITE, 表示 buffer 可写. 一个 Channel发出一个事件也可以称为 对于某个事件, Channel 准备好了. 因此一个 Channel 成功连接到了另一个服务器也可以被称为 connect ready.我们可以使用或运算|来组合多个事件, 例如: 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 注意, 一个 Channel 仅仅可以被注册到一个 Selector 一次, 如果将 Channel 注册到 Selector 多次, 那么其实就是相当于更新 SelectionKey 的 interest set. 例如: 12channel.register(selector, SelectionKey.OP_READ);channel.register(selector, SelectionKey.OP_READ | SelectionKey.OP_WRITE); 上面的 channel 注册到同一个 Selector 两次了, 那么第二次的注册其实就是相当于更新这个 Channel 的 interest set 为 SelectionKey.OP_READ | SelectionKey.OP_WRITE. 但是Java NIO的selector允许一个单一线程监听多个channel输入。我们可以注册多个channel到selector上，然后然后用一个线程来挑出一个处于可读或者可写状态的channel。selector机制使得单线程管理多个channel变得容易。 下面我们写一个完整的例子，看一下Selector的用法： 12345678910111213141516171819202122232425262728//创建选择器Selector selector = Selector.open();channel.configureBlocking(false);//注册通道SelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) &#123; //查看selector中的key是否准备好 int readyChannels = selector.select(); //小于0超时，等于0没准备好，大于0已经准备完毕 if(readyChannels == 0) continue; //获取选择器中的key Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); //遍历已选择键集中的每个键，并检测各个键所对应的通道的就绪事件 if(key.isAcceptable()) &#123; // 连接已经被ServerSocketChannel所接受 &#125; else if (key.isConnectable()) &#123; // 连接已经被远程终止. &#125; else if (key.isReadable()) &#123; // 通道已经准备好读数据 &#125; else if (key.isWritable()) &#123; // 通道已经准备好写数据 &#125; keyIterator.remove(); &#125;&#125; 选择器的使用还有很多的细节，我们应该多查看api文档了解各个方法的用法。下一节我们做一个综合练习，总结一下NIO的使用。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件-activemq入门(二)]]></title>
    <url>%2Fposts%2Fa042465a.html</url>
    <content type="text"><![CDATA[上一节我们了解了JMS规范并且知道了JMS规范的良好实现者-activemq。今天我们就去了解一下activemq的使用。另外我们应该抱着目的去学习，别忘了我们为什么要使用消息中间件：解耦系统之间的联系，同步或异步的消息传输，尤其是异步的消息传输，分布式环境下，可靠、高效的消息传输，可以保证消息的重发性和顺序性。即解决业务系统比较多或者是分布式环境下的系统之间安全有效通信的问题，带着这样的目的我们来学习消息中间件就有了方向。 1. 为什么用activemq在设计分布式应用程序时，应用程序间的耦合（或称集成）方式很重要。耦合意味着两个或者多个应用程序或系统的相互依赖关系。一种简单的方式是在所有的应用程序中从架构上设计他们与其他应用程序间的交叉实现。这样必然导致，一个应用程序的改变，直接导致另一个应用程序的改变。 ActiveMQ采用松耦合方式，应用程序将消息发送给ActiveMQ而并不关心什么时间以何种方式消息投递给接收者。同样的，消息接收者也不会关心消息来源于哪里和消息是怎样投递给ActiveMQ的。对于多语言编写的复杂应用环境中，允许客户端使用不同的编程语言甚至不同的消息包装协议。ActiveMQ作为消息的中间件，允许复杂的多语言应用程序以一种一步的方式集成和交互。所以说，ActiveMQ是一种好的，提供松散耦合的，能够为多语言交叉应用提供集成的中间件。 2. 什么时候用activemqActiveMQ的设计目标是提供标准的，面向消息的，能够跨越多语言和多系统的应用集成消息通信中间件。大多数情况下ActiveMQ被用于做系统之间的数据交换。 只要是两个应用程序间需要通信的情况，都可以考虑使用JMS，不论这种通信是在本地的（就是通信的两个应用程序在同一台主机上），还是分布在不同机器上。尽管是在同一个主机上的两个应用程序需要通信也可以使用ActiveMQ。ActiveMQ可以确保消息投递成功并采用异步方式通信。 3. activemq特性支持JMS规范：ActiveMQ完全实现了JMS1.1规范。 连接方式的多样化：ActiveMQ提供了广泛的连接模式，包括HTTP/S、JGroups、JXTA、muticast、SSL、TCP、UDP、XMPP等。提供了如此多的连接模式表明了ActiveMQ具有较高的灵活性。 与其他的Java容器紧密集成：ActiveMQ提供了和其它流行的Java容器的结合，包括Apache Geronimo、Apache Tomcat、JBoss、Jetty等。 客户端API：ActiveMQ提供了多种客户端可访问的API，包括Java、C/C++，.NET，Perl、PHP、Python、Ruby等。当然，ActiveMQ中介必须运行在Java虚拟机中，但是使用它的客户端可以使用其他的语言来实现。 中介集群：多个ActiveMQ中介可以一起协同工作，来完成某项复杂的工作，这被称为网络型中介（network of brokers），这种类型的中介将会支持多种拓扑类型。 4. 使用activemq首先我们去apache上下载activemq，点此下载。 接下来我是使用maven来管理jar的，如果你不用maven的话就去刚下载的activemq包中找到jar包导入即可。maven引入jar： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.14.5&lt;/version&gt;&lt;/dependency&gt; 然后我们进入刚下载的activemq，我进入的路径如下：apache-activemq-5.14.5-bin\apache-activemq-5.14.5\bin\win64\activemq.bat,我用的是64位的系统，如果你是32位的同理进入相应文件夹下点击activemq.bat启动activemq客户端，启动完成之后，直接访问ActiveMQ管理页面http://localhost:8161/admin/ 默认用户名密码admin/admin。 客户端界面如下： 接下来该我们写代码的时候了，首先我们还是先写一个P2P(点对点)模式的客户端。代码如下： Sender.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.DeliveryMode;import javax.jms.Destination;import javax.jms.MessageProducer;import javax.jms.Session;import javax.jms.TextMessage;import org.apache.activemq.ActiveMQConnection;import org.apache.activemq.ActiveMQConnectionFactory;import java.io.BufferedReader;import java.io.InputStreamReader;public class Sender &#123; public static void main(String[] args) &#123; //ConnectionFactory是连接工厂，JMS用它创建连接 ConnectionFactory connectionFactory; //Connection JMS客户端到JMS provider的连接 Connection connection = null; //Session 一个发送或者接收消息的线程 Session session; //Destination 消息发送目的地，消息发送给谁接收 Destination destination; //MessageProducer 消息发送者 MessageProducer messageProducer; //构造ConnectionFactory 实例对象，此处采用ActiveMQ的实现jar connectionFactory = new ActiveMQConnectionFactory( ActiveMQConnection.DEFAULT_USER, ActiveMQConnection.DEFAULT_PASSWORD, "tcp://localhost:61616"); try &#123; //构造工厂得到连接对象 connection = connectionFactory.createConnection(); //启动 connection.start(); //获取操作连接 session = connection.createSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); //创建一个Queue，名称为FirstQueue destination = session.createQueue("FirstQueue"); //得到消息生产者【发送者】 messageProducer = session.createProducer(destination); //设置不持久化，根据实际情况而定 messageProducer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); //创建一个消息对象 TextMessage message = session.createTextMessage(); //把我们的消息写入msg对象中 BufferedReader b=new BufferedReader(new InputStreamReader(System.in)); while(true) &#123; System.out.println("Enter Msg, end to terminate:"); String s=b.readLine(); if (s.equals("end")) break; message.setText(s); //发送消息 messageProducer.send(message); System.out.println("Message successfully sent."); &#125; session.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; if(null != connection)&#123; connection.close(); &#125; &#125; catch (Throwable ignore) &#123; &#125; &#125; &#125;&#125; Receiver.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.MessageConsumer;import javax.jms.Session;import javax.jms.TextMessage;import org.apache.activemq.ActiveMQConnection;import org.apache.activemq.ActiveMQConnectionFactory;public class Receiver &#123; public static void main(String[] args) &#123; //connectionFactory 连接工厂，JMS用它创建连接 ConnectionFactory connectionFactory; //connection JMS客户端到JMS provider 的连接 Connection connection = null; //session一个发送或者接收的线程 Session session; //destination 消息目的地，发送给谁接收 Destination destination; //消费者消息接收者 MessageConsumer consumer; connectionFactory = new ActiveMQConnectionFactory( ActiveMQConnection.DEFAULT_USER, ActiveMQConnection.DEFAULT_PASSWORD, "tcp://localhost:61616"); try &#123; //构造工厂得到连接对象 connection = connectionFactory.createConnection(); //启动 connection.start(); //获取操作连接 session = connection.createSession(Boolean.FALSE, Session.AUTO_ACKNOWLEDGE); destination = session.createQueue("FirstQueue"); consumer = session.createConsumer(destination); while(true)&#123; //设置接收者收消息的时间，为了方便测试，这里暂定设置为100s TextMessage message = (TextMessage)consumer.receive(100); if(null != message)&#123; System.out.println("收到消息==="+message.getText()); &#125;else&#123; break; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally&#123; try &#123; if(null != connection)&#123; connection.close(); &#125; &#125; catch (Throwable ignore) &#123; &#125; &#125; &#125;&#125; 代码已经注释过了，就不多做解释，接着我们先运行Sender,需要你在控制台输入你要发送的消息，当你输入”end”的时候才会结束输入，否则你每一次输入按回车都是发送一条消息。然后去看一下activemq的控制台，点击一下菜单栏上的Queues： 因为我刚发送了两条消息在这里会显示，消息会由activemq这个中间人统一管理，当接受者需要接受消息的时候，他会来请求activemq，从这里获取消息而不是发送端一直等着接收端。 下面你可以运行一下Receiver，这时候就把刚才这两条消息消费了。消息队列此刻就是空的。之所以强调这一点是为了和接下来的 发布/订阅 模式做一个比较，限于篇幅我就不截图了，大家可以尝试。 下面我们接着写一个Pub/Sub模式的例子，并没有多大的变化，在创建消息队列的时候改为topic模式： TopicSender.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879import javax.jms.*;import org.apache.activemq.ActiveMQConnection;import org.apache.activemq.ActiveMQConnectionFactory;import java.io.BufferedReader;import java.io.InputStreamReader;/** * Created by Administrator on 2017/4/25. */public class TopicSender &#123; public static void main(String[] args) &#123; //ConnectionFactory是连接工厂，JMS用它创建连接 ConnectionFactory connectionFactory; //Connection JMS客户端到JMS provider的连接 Connection connection = null; //Session 一个发送或者接收消息的线程 Session session; //Destination 消息发送目的地，消息发送给谁接收 Topic destination; //MessageProducer 消息发送者 MessageProducer messageProducer; //构造ConnectionFactory 实例对象，此处采用ActiveMQ的实现jar connectionFactory = new ActiveMQConnectionFactory( ActiveMQConnection.DEFAULT_USER, ActiveMQConnection.DEFAULT_PASSWORD, "tcp://localhost:61616"); try &#123; //构造工厂得到连接对象 connection = connectionFactory.createConnection(); //启动 connection.start(); //获取操作连接 session = connection.createSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); //创建一个Queue，SecondQueue 此处使用的是Topic模式 destination = session.createTopic("SecondQueue"); //得到消息生产者【发送者】 messageProducer = session.createProducer(destination); //设置不持久化，根据实际情况而定 messageProducer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); //创建一个消息对象 TextMessage message = session.createTextMessage(); //把我们的消息写入msg对象中 BufferedReader b=new BufferedReader(new InputStreamReader(System.in)); message.setText("你好"); //发送消息 messageProducer.send(message); System.out.println("Message successfully sent."); session.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; if(null != connection)&#123; connection.close(); &#125; &#125; catch (Throwable ignore) &#123; &#125; &#125; &#125;&#125; 同理接受方也是如此： TopicReciever.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class TopicReciever &#123; public static void main(String[] args) &#123; //connectionFactory 连接工厂，JMS用它创建连接 ConnectionFactory connectionFactory; //connection JMS客户端到JMS provider 的连接 Connection connection = null; //session一个发送或者接收的线程 final Session session; //destination 消息目的地，发送给谁接收 这里注意改成Topic类型的 Topic destination; //消费者消息接收者 final MessageConsumer consumer; connectionFactory = new ActiveMQConnectionFactory( ActiveMQConnection.DEFAULT_USER, ActiveMQConnection.DEFAULT_PASSWORD, "tcp://localhost:61616"); try &#123; //构造工厂得到连接对象 connection = connectionFactory.createConnection(); //启动 connection.start(); //获取操作连接 session = connection.createSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); //此处使用的是Topic模式 destination = session.createTopic("SecondQueue"); consumer = session.createConsumer(destination); while(true)&#123; //设置接收者收消息的时间 TextMessage message = (TextMessage)consumer.receive(10000); if(null != message)&#123; System.out.println("收到消息==="+message.getText()); &#125;else&#123; break; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 这里我们可以把Reciever同样的代码再复制一份Reciever1，然后我们先把两个接收端启动，再启动发送端，这时候我们发现消息被接受到了；但是如果我们先启动发送端再启动接收端，这时候虽然消息是被发送出去了，但是接收端并未收到，这是为什么呢？这就是我前面在讲P2P模式的时候留下的一个对比点： P2P模式是1V1的，我发送只对当前声明的这个标识，接受者也只接受该标识所对应的消息。一旦接受者获取该消息，该标识对应的消息即从消息队列中移除； Pub/Sub模式是1 V N 的，1个发送端发出的消息，可以有多个接收端去消费，但是有一个前提：想消费这条消息的接收端必须先注册，即先启动接收端去activemq的客户端注册，发送端就根据注册的情况主动把消息推送到订阅过该消息的消费者。 我们看到消息队列里面有一条消息，然后有两位消费者来订阅这一条消息，上面我们看到两个消费者分别取队列取一次消息，然后activemq会创建两个临时生产者去他们服务把消息给他们。 好拉，这一节的入门知识就讲到这里，既然是入门我们就不必太深刻，不然适得其反啊！哈哈。下面开始我们就详细的探讨activemq的一些特性以及消息中间件在集群环境中的应用。]]></content>
      <categories>
        <category>activeMQ</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（三）----线程的同步]]></title>
    <url>%2Fposts%2F71e4d230.html</url>
    <content type="text"><![CDATA[在现实开发中，我们或多或少的都经历过这样的情景：某一个变量被多个用户并发式的访问并修改，如何保证该变量在并发过程中对每一个用户的正确性呢？今天我们来聊聊线程同步的概念。 一般来说，程序并行化是为了获得更高的执行效率，但前提是，高效率不能以牺牲正确性为代价。如果程序并行化后， 连基本的执行结果的正确性都无法保证， 那么并行程序本身也就没有任何意义了。因此， 线程安全就是并行程序的根本和根基。解决这些问题从临界区的概念开始。临界区是访问一个共享资源在同一时间不能被超过一个线程执行的代码块。 java为我们提供了同步机制，帮助程序员实现临界区。当一个线程想要访问一个临界区,它使用其中的一个同步机制来找出是否有任何其他线程执行临界区。如果没有，这个线程就进入临界区。否则，这个线程通过同步机制暂停直到另一个线程执行完临界区。当多个线程正在等待一个线程完成执行的一个临界区，JVM选择其中一个线程执行，其余的线程会等待直到轮到它们。临界区有如下的规则： 如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入。 任何时候，处于临界区内的进程不可多于一个。如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待。 进入临界区的进程要在有限时间内退出，以便其它进程能及时进入自己的临界区。 如果进程不能进入自己的临界区，则应让出CPU，避免进程出现“忙等”现象。 java语言为解决同步问题帮我们提供了两种机制来实现： 1. synchronized关键字； 2. Lock锁及其实现； synchronized的作用关键字synchronized 的作用是实现线程间的同步。它的工作是对同步的代码加锁，使得每一次， 只能有一个线程进入同步块，从而保证线程间的安全性。 关键宇synchronized 可以有多种用法。这里做一个简单的整理。 · 指定加锁对象: 对给定对象加锁，进入同步代码前要获得给定对象的锁。 · 直接作用于实例方法: 相当于对当前实例加锁，进入同步代码前要获得当前实例的锁。 . 直接作用于静态方法: 相当于对当前类加锁， 进入同步代码前要获得当前类的锁。 1.给指定对象加锁： 123456789101112131415161718192021222324252627282930313233343536public class AccountingSync implements Runnable&#123; static AccountingSync instance=new AccountingSync() ; static int i =O; @Override public void run() ( for(int j=O; j&lt;lOOOOOOO; j++) &#123; synchronized (instance) &#123; //对象锁 i++ ; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException ( Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125; /* public static void main(String[] args) throws InterruptedException ( Thread t1=new Thread(new AccountingSync()); Thread t2=new Thread(new AccountingSync()); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125; */&#125; 知道我为什么要给出两个main方法让大家参考吗？上述锁对象是锁定AccountingSync实例对象。第一个main方法中t1 和 t2 两个线程同时指向了instance实例，所以第7行的锁对象synchronized (instance)在线程t1 和 线程 t2 获得锁的时候是获取同一个对象的，这个时候的锁是同一把锁。但是在第二个main方法中我们可以看到线程t1 和 线程 t2分别对应的是两个不同的AccountingSync对象，这时候锁对象获得的是不同的AccountingSync实例，安全性是没有保证的，大家可以动手尝试一下。 2.直接作用于实例方法： 12345678910111213141516171819202122232425262728293031323334public class TestSynchronized &#123; public static void main(String[] args) &#123; Tester2 a1 = new Tester2(); Th t1 = new Th(a1); t1.start(); Th t2 = new Th(a1); t2.start(); &#125;&#125;class Tester2 &#123; public synchronized void say(String name) throws InterruptedException&#123; for(int i = 0;i&lt;5;i++)&#123; Thread.sleep(1000); System.out.println(); System.out.println(name +","+i+new Date().toLocaleString() ); &#125; &#125;&#125;class Th extends Thread&#123; Tester2 test; public Th(Tester2 test1)&#123; test = test1; &#125; public void run()&#123; try &#123; test.say(Thread.currentThread().getName()); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125;&#125; 对Tester2类中的方法使用synchronized很好理解，同一时刻如果t1正在调用say()方法，在他没有执行完毕并退出方法之前其余的线程是无法获得该方法的。只能排队等待知道t1执行完毕。 3.作用于静态方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class Test1 &#123; public static void main(String[] args) &#123; for(int i=0;i&lt;50;i++)&#123; Thread t1 = new Thread(new Sale(5)); Thread t2 = new Thread(new Producted(5)); t1.start(); t2.start(); &#125; &#125; &#125; class Shop&#123; static int a = 40; synchronized static void shopping(int b)&#123; a -= b; System.out.println("售出 "+b+" 张大饼，"+"还剩 "+a+" 张大饼"); &#125; synchronized static void factory(int c)&#123; a += c; System.out.println("仓库还有 "+a+" 张大饼"); &#125; &#125; class Sale implements Runnable&#123; int b = 0; public Sale(int b)&#123; this.b = b; &#125; @Override public void run() &#123; if(b&lt;0)&#123; Thread.interrupted(); &#125; Shop.shopping(b); try &#123; Thread.sleep(1000); Shop.factory(b-5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; class Producted implements Runnable&#123; int b = 0; public Producted(int b)&#123; this.b = b; &#125; @Override public void run() &#123; Shop.factory(b); try &#123; Thread.sleep(1000); Shop.shopping(b-5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; ``` 静态方法前加synchronized这个锁等价于锁住了当前类的class对象，因为静态方法或者是静态关键字在本质上是一个类对象，而不是成员对象，在内存中位于方法区被所有的实例共享。即等同于synchronized(Shop.class)。我们需要注意的是锁住了类并不代表锁住了类所在的对象，类本身也是一种对象。它与类的实例是完全不同的两个对象，在加锁时不是相互依赖的，即对类加锁并不与上面例子中的加锁互斥，锁住了子类或子类的对象与锁住父类或父类的对象是不相关的。synchronized的使用其实主要是前面两种，对象锁和方法锁，静态方法锁我们并不常用到。其余的操作方式都是在这两种的基础上演变而来，比如大家经常说的“块级锁”：```javasynchronized(object)&#123; //代码内容&#125; 锁住的其实并不是代码块，而是object这个对象，所以如果在其他的代码中也发生synchronized(object)时就会发生互斥。我们为什么要研究这些呢，因为如果我们不知道我们锁住的是什么，就不清楚锁住了多大范围的内容，自然就不知道是否锁住了想要得到互斥的效果，同时也不知道如何去优化锁的使用。 因此java中的synchronized就真正能做到临界区的效果，在临界区内多个线程的操作绝对是串行的，这一点java绝对可以保证。同时synchronized造成的开销也是很大的，我们如果无法掌握好他的粒度控制，就会导致频繁的锁征用，进入悲观锁状态。 ####volatile—-轻量级的synchronized既然我们说到了synchronized那就不得不提到volatile，在java中synchronized是控制并发的，我们知道在我们对一个变量执行赋值操作的时候比如：i++，在执行完毕之后i的结果其实是写到缓存中的它并没有及时的写入到内存，后续在某些情况下（比如cpu缓存不够）再将cpu缓存写入内存，假设A线程正在执行i++操作，而此时B线程也来执行。B在执行i++之前是不会自己跑到缓存中去取变量的值的，它只会去内存中读取i，很显然i的值是没有被更新的，为了防止这种情况出现，volatile应运而生。 Java语言规范第三版中对volatile的定义如下： java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁更加方便。如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。 我们来看一个例子： 1234567891011121314151617181920212223242526public class TestWithoutVolatile &#123; private static boolean bChanged; public static void main(String[] args) throws InterruptedException &#123; new Thread() &#123; @Override public void run() &#123; for (;;) &#123; if (bChanged == !bChanged) &#123; System.out.println("!="); System.exit(0); &#125; &#125; &#125; &#125;.start(); Thread.sleep(1); new Thread() &#123; @Override public void run() &#123; for (;;) &#123; bChanged = !bChanged; &#125; &#125; &#125;.start(); &#125; &#125; 在上例中我们如果多次运行会出现两种结果，一种是正常打印：”!=”,还有一种就是程序会陷入死循环。但是我们如果给bChanged前面加上volatile的话则每次都会打印出”!=”,请读者朋友们下去可以尝试。在此处没有加volatile之前之所以会出现有时可以出现正确结果有时则卡死的原因就在于两个线程同时在运行的过程中双方都在操作bChanged变量，但是该变量的值对于同时在使用它的另一个线程来说并不总是可见的，运气好的时候线程修改完值之后就写入主存，运气不好的时候线程只在缓存中更新了值并未写入主存。但是在加了volatile修饰之后效果则不同，因为volatile可以保证变量的可见性。说到可见性，我们来看一幅图： 每一个线程都有相应的工作内存，工作内存中有一份主内存变量的副本，线程对变量的操作都在工作内存中进行（避免再次访问主内存，提高性能），不同线程不能访问彼此的工作内存，而通过将操作后的值刷新到主内存来进行彼此的交互，这就会带来一个变量值对其他线程的可见性问题。当一个任务在工作内存中变量值进行改变，其他任务对此是不可见的，导致每一个线程都有一份不同的变量副本。而volatile恰恰可以解决这个可见性的问题，当变量被volatile修饰，如private volatile int stateFlag = 0; 它将直接通过主内存中被读取或者写入，线程从主内存中加载的值将是最新的。 但是volatile的使用有着严格的限制，当对变量的操作依赖于以前值（如i++）,或者其值被其他字段的值约束，这个时候volatile是无法实现线程安全的。被volatile修饰的变量必须独立于程序的其他状态。因为volatile只是保证了变量的可见性，并不能保证操作的原子性，所谓原子性，即有“不可分”的意思，如对基本数据类型(java中排除long和double)的赋值操作a=6,如返回操作return a，这些操作都不会被线程调度器中断，同一时刻只有一个线程对它进行操作。看以下代码： 123456789101112131415161718192021222324252627public class Counter &#123; public volatile static int count = 0; public static void inc() &#123; //这里延迟1毫秒，使得结果明显 try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; &#125; count++; &#125; public static void main(String[] args) &#123; //同时启动1000个线程，去进行i++计算，看看实际结果 for (int i = 0; i &lt; 1000; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; Counter.inc(); &#125; &#125;).start(); &#125; //这里每次运行的值都有可能不同,可能为1000 System.out.println("运行结果:Counter.count=" + Counter.count); &#125;&#125; 运行上面的例子我们可以发现每次运行的结果都不一样，预期结果应该是1000，尽管counter被volatile修饰，保证了可见性，但是counter++并不是一个原子性操作，它被拆分为读取和写入两部分操作，我们需要用synchronized修饰： 123publicstaticsynchronizedvoid incNum() &#123; counter++;&#125; 此时每次运行结果都是1000，实现了线程安全。synchronized是一种独占锁，它对一段操作或内存进行加锁，当线程要操作被synchronized修饰的内存或操作时，必须首先获得锁才能进行后续操作；但是在同一时刻只能有一个线程获得相同的一把锁，所以它只允许一个线程进行操作。synchronized同样能够将变量最新值刷新到主内存，当一个变量只被synchronized方法操作时,是没有必要用volatile修饰的，所以我们接着把变量声明修改为： 1private static int counter; 多次运行结果依旧是1000。 说明：上例中如果你按照上面这样改完之后其实结果并是不1000，我多次运行的结果都是先打印出”运行结果:Counter.count=0”,然后线程卡死。究其原因，我猜可能是第一个线程等待一秒再执行count++，然后后面的线程在这个等待过程中等不及的原因。java线程的运行具有不确定性，不能保证线程会按部就班的顺序执行，所以会出现什么样的后果很难预测。正确结果代码如下： 1234567891011121314151617181920public class Counter &#123; public static int count = 0; public synchronized static void inc() &#123; count++; &#125; public static void main(String[] args) &#123; //同时启动1000个线程，去进行i++计算，看看实际结果 for (int i = 0; i &lt; 1000; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; Counter.inc(); &#125; &#125;).start(); &#125; //这里每次运行的值都有可能不同,可能为1000 System.out.println("运行结果:Counter.count=" + Counter.count); &#125;&#125; 综上所述，由于volatile只能保证变量对多个线程的可见性，但不能保证原子性，它的同步机制是比较脆弱的，它在使用过程中有着诸多限制，对使用者也有更高的要求，相对而言，synchronized锁机制是比较安全的同步机制，有时候出于提高性能的考虑，可以利用volatile对synchronized进行代替和优化，但前提是你必须充分理解其使用场景和涵义。 下一节我们接着分析Lock锁。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（三）----线程的同步]]></title>
    <url>%2Fposts%2F71e4d230.html</url>
    <content type="text"><![CDATA[在现实开发中，我们或多或少的都经历过这样的情景：某一个变量被多个用户并发式的访问并修改，如何保证该变量在并发过程中对每一个用户的正确性呢？今天我们来聊聊线程同步的概念。 一般来说，程序并行化是为了获得更高的执行效率，但前提是，高效率不能以牺牲正确性为代价。如果程序并行化后， 连基本的执行结果的正确性都无法保证， 那么并行程序本身也就没有任何意义了。因此， 线程安全就是并行程序的根本和根基。解决这些问题从临界区的概念开始。临界区是访问一个共享资源在同一时间不能被超过一个线程执行的代码块。 java为我们提供了同步机制，帮助程序员实现临界区。当一个线程想要访问一个临界区,它使用其中的一个同步机制来找出是否有任何其他线程执行临界区。如果没有，这个线程就进入临界区。否则，这个线程通过同步机制暂停直到另一个线程执行完临界区。当多个线程正在等待一个线程完成执行的一个临界 区，JVM选择其中一个线程执行，其余的线程会等待直到轮到它们。临界区有如下的规则： 如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入。 任何时候，处于临界区内的进程不可多于一个。如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待。 进入临界区的进程要在有限时间内退出，以便其它进程能及时进入自己的临界区。 如果进程不能进入自己的临界区，则应让出CPU，避免进程出现“忙等”现象。 java语言为解决同步问题帮我们提供了两种机制来实现： 1. synchronized关键字； 2. Lock锁及其实现； 1 synchronized的作用关键字synchronized 的作用是实现线程间的同步。它的工作是对同步的代码加锁，使得每一次， 只能有一个线程进入同步块，从而保证线程间的安全性。 关键宇synchronized 可以有多种用法。这里做一个简单的整理。 · 指定加锁对象: 对给定对象加锁，进入同步代码前要获得给定对象的锁。 · 直接作用于实例方法: 相当于对当前实例加锁，进入同步代码前要获得当前实例的锁。 . 直接作用于静态方法: 相当于对当前类加锁， 进入同步代码前要获得当前类的锁。 1.给指定对象加锁： 1234567891011121314151617181920212223242526272829303132333435public class AccountingSync implements Runnable&#123; static AccountingSync instance=new AccountingSync() ; static int i =O; @Override public void run() ( for(int j=O; j&lt;lOOOOOOO; j++) &#123; synchronized (instance) &#123; //对象锁 i++ ; &#125; &#125;&#125;public static void main(String[] args) throws InterruptedException ( Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i);&#125;/*public static void main(String[] args) throws InterruptedException ( Thread t1=new Thread(new AccountingSync()); Thread t2=new Thread(new AccountingSync()); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i);&#125;*/ 知道我为什么要给出两个main方法让大家参考吗？上述锁对象是锁定AccountingSync实例对象。第一个main方法中t1 和 t2 两个线程同时指向了instance实例，所以第7行的锁对象synchronized (instance)在线程t1 和 线程 t2 获得锁的时候是获取同一个对象的，这个时候的锁是同一把锁。但是在第二个main方法中我们可以看到线程t1 和 线程 t2分别对应的是两个不同的AccountingSync对象，这时候锁对象获得的是不同的AccountingSync实例，安全性是没有保证的，大家可以动手尝试一下。 2.直接作用于实例方法： 123456789101112131415161718192021222324252627282930313233public class TestSynchronized &#123; public static void main(String[] args) &#123; Tester2 a1 = new Tester2(); Th t1 = new Th(a1); t1.start(); Th t2 = new Th(a1); t2.start(); &#125;&#125;class Tester2 &#123; public synchronized void say(String name) throws InterruptedException&#123; for(int i = 0;i&lt;5;i++)&#123; Thread.sleep(1000); System.out.println(); System.out.println(name +","+i+new Date().toLocaleString() ); &#125; &#125;&#125;class Th extends Thread&#123; Tester2 test; public Th(Tester2 test1)&#123; test = test1; &#125; public void run()&#123; try &#123; test.say(Thread.currentThread().getName()); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 对Tester2类中的方法使用synchronized很好理解，同一时刻如果t1正在调用say()方法，在他没有执行完毕并退出方法之前其余的线程是无法获得该方法的。只能排队等待知道t1执行完毕。 3.作用于静态方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class Test1 &#123; public static void main(String[] args) &#123; for(int i=0;i&lt;50;i++)&#123; Thread t1 = new Thread(new Sale(5)); Thread t2 = new Thread(new Producted(5)); t1.start(); t2.start(); &#125; &#125;&#125;class Shop&#123; static int a = 40; synchronized static void shopping(int b)&#123; a -= b; System.out.println("售出 "+b+" 张大饼，"+"还剩 "+a+" 张大饼"); &#125; synchronized static void factory(int c)&#123; a += c; System.out.println("仓库还有 "+a+" 张大饼"); &#125;&#125;class Sale implements Runnable&#123; int b = 0; public Sale(int b)&#123; this.b = b; &#125; @Override public void run() &#123; if(b&lt;0)&#123; Thread.interrupted(); &#125; Shop.shopping(b); try &#123; Thread.sleep(1000); Shop.factory(b-5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class Producted implements Runnable&#123; int b = 0; public Producted(int b)&#123; this.b = b; &#125; @Override public void run() &#123; Shop.factory(b); try &#123; Thread.sleep(1000); Shop.shopping(b-5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 静态方法前加synchronized这个锁等价于锁住了当前类的class对象，因为静态方法或者是静态关键字在本质上是一个类对象，而不是成员对象，在内存中位于方法区被所有的实例共享。即等同于synchronized(Shop.class)。我们需要注意的是锁住了类并不代表锁住了类所在的对象，类本身也是一种对象。它与类的实例是完全不同的两个对象，在加锁时不是相互依赖的，即对类加锁并不与上面例子中的加锁互斥，锁住了子类或子类的对象与锁住父类或父类的对象是不相关的。 synchronized的使用其实主要是前面两种，对象锁和方法锁，静态方法锁我们并不常用到。其余的操作方式都是在这两种的基础上演变而来，比如大家经常说的“块级锁”： 123synchronized(object)&#123; //代码内容&#125; 锁住的其实并不是代码块，而是object这个对象，所以如果在其他的代码中也发生synchronized(object)时就会发生互斥。我们为什么要研究这些呢，因为如果我们不知道我们锁住的是什么，就不清楚锁住了多大范围的内容，自然就不知道是否锁住了想要得到互斥的效果，同时也不知道如何去优化锁的使用。 因此java中的synchronized就真正能做到临界区的效果，在临界区内多个线程的操作绝对是串行的，这一点java绝对可以保证。同时synchronized造成的开销也是很大的，我们如果无法掌握好他的粒度控制，就会导致频繁的锁征用，进入悲观锁状态。 2 volatile—-轻量级的synchronized既然我们说到了synchronized那就不得不提到volatile，在java中synchronized是控制并发的，我们知道在我们对一个变量执行赋值操作的时候比如：i++，在执行完毕之后i的结果其实是写到缓存中的它并没有及时的写入到内存，后续在某些情况下（比如cpu缓存不够）再将cpu缓存写入内存，假设A线程正在执行i++操作，而此时B线程也来执行。B在执行i++之前是不会自己跑到缓存中去取变量的值的，它只会去内存中读取i，很显然i的值是没有被更新的，为了防止这种情况出现，volatile应运而生。 Java语言规范第三版中对volatile的定义如下： java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁更加方便。如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。 我们来看一个例子： 1234567891011121314151617181920212223242526public class TestWithoutVolatile &#123; private static boolean bChanged; public static void main(String[] args) throws InterruptedException &#123; new Thread() &#123; @Override public void run() &#123; for (;;) &#123; if (bChanged == !bChanged) &#123; System.out.println("!="); System.exit(0); &#125; &#125; &#125; &#125;.start(); Thread.sleep(1); new Thread() &#123; @Override public void run() &#123; for (;;) &#123; bChanged = !bChanged; &#125; &#125; &#125;.start(); &#125; &#125; 在上例中我们如果多次运行会出现两种结果，一种是正常打印：”!=”,还有一种就是程序会陷入死循环。但是我们如果给bChanged前面加上volatile的话则每次都会打印出”!=”,请读者朋友们下去可以尝试。在此处没有加volatile之前之所以会出现有时可以出现正确结果有时则卡死的原因就在于两个线程同时在运行的过程中双方都在操作bChanged变量，但是该变量的值对于同时在使用它的另一个线程来说并不总是可见的，运气好的时候线程修改完值之后就写入主存，运气不好的时候线程只在缓存中更新了值并未写入主存。但是在加了volatile修饰之后效果则不同，因为volatile可以保证变量的可见性。说到可见性，我们来看一幅图： 每一个线程都有相应的工作内存，工作内存中有一份主内存变量的副本，线程对变量的操作都在工作内存中进行（避免再次访问主内存，提高性能），不同线程不能访问彼此的工作内存，而通过将操作后的值刷新到主内存来进行彼此的交互，这就会带来一个变量值对其他线程的可见性问题。当一个任务在工作内存中变量值进行改变，其他任务对此是不可见的，导致每一个线程都有一份不同的变量副本。而volatile恰恰可以解决这个可见性的问题，当变量被volatile修饰，如private volatile int stateFlag = 0; 它将直接通过主内存中被读取或者写入，线程从主内存中加载的值将是最新的。 但是volatile的使用有着严格的限制，当对变量的操作依赖于以前值（如i++）,或者其值被其他字段的值约束，这个时候volatile是无法实现线程安全的。被volatile修饰的变量必须独立于程序的其他状态。因为volatile只是保证了变量的可见性，并不能保证操作的原子性，所谓原子性，即有“不可分”的意思，如对基本数据类型(java中排除long和double)的赋值操作a=6,如返回操作return a，这些操作都不会被线程调度器中断，同一时刻只有一个线程对它进行操作。看以下代码： 123456789101112131415161718192021222324252627public class Counter &#123; public volatile static int count = 0; public static void inc() &#123; //这里延迟1毫秒，使得结果明显 try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; &#125; count++; &#125; public static void main(String[] args) &#123; //同时启动1000个线程，去进行i++计算，看看实际结果 for (int i = 0; i &lt; 1000; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; Counter.inc(); &#125; &#125;).start(); &#125; //这里每次运行的值都有可能不同,可能为1000 System.out.println("运行结果:Counter.count=" + Counter.count); &#125;&#125; 运行上面的例子我们可以发现每次运行的结果都不一样，预期结果应该是1000，尽管counter被volatile修饰，保证了可见性，但是counter++并不是一个原子性操作，它被拆分为读取和写入两部分操作，我们需要用synchronized修饰： 123publicstaticsynchronizedvoid incNum() &#123; counter++;&#125; 此时每次运行结果都是1000，实现了线程安全。synchronized是一种独占锁，它对一段操作或内存进行加锁，当线程要操作被synchronized修饰的内存或操作时，必须首先获得锁才能进行后续操作；但是在同一时刻只能有一个线程获得相同的一把锁，所以它只允许一个线程进行操作。synchronized同样能够将变量最新值刷新到主内存，当一个变量只被synchronized方法操作时,是没有必要用volatile修饰的，所以我们接着把变量声明修改为： 1private static int counter; 多次运行结果依旧是1000。 说明：上例中如果你按照上面这样改完之后其实结果并是不1000，我多次运行的结果都是先打印出”运行结果:Counter.count=0”,然后线程卡死。究其原因，我猜可能是第一个线程等待一秒再执行count++，然后后面的线程在这个等待过程中等不及的原因。java线程的运行具有不确定性，不能保证线程会按部就班的顺序执行，所以会出现什么样的后果很难预测。正确结果代码如下： 1234567891011121314151617181920public class Counter &#123; public static int count = 0; public synchronized static void inc() &#123; count++; &#125; public static void main(String[] args) &#123; //同时启动1000个线程，去进行i++计算，看看实际结果 for (int i = 0; i &lt; 1000; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; Counter.inc(); &#125; &#125;).start(); &#125; //这里每次运行的值都有可能不同,可能为1000 System.out.println("运行结果:Counter.count=" + Counter.count); &#125;&#125; 综上所述，由于volatile只能保证变量对多个线程的可见性，但不能保证原子性，它的同步机制是比较脆弱的，它在使用过程中有着诸多限制，对使用者也有更高的要求，相对而言，synchronized锁机制是比较安全的同步机制，有时候出于提高性能的考虑，可以利用volatile对synchronized进行代替和优化，但前提是你必须充分理解其使用场景和涵义。 下一节我们接着分析Lock锁。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件-activemq消息机制和持久化介绍(三)]]></title>
    <url>%2Fposts%2F28fe9931.html</url>
    <content type="text"><![CDATA[前面一节简单学习了activemq的使用，我们知道activemq的使用方式非常简单有如下几个步骤： 创建连接工厂 创建连接 创建会话 创建目的地 创建生产者或消费者 生产或消费消息 关闭生产或消费者、关闭会话、关闭连接 前面我们的实例代码中已经按照这个步骤完成了P2P和Pub/Sub模式的消息发送和接收。那么这一节我们就针对他的消息传播机制和持久化方式做一个简单的学习。在会用的同时我们也需要理解一些基本的概念，这样才不至于在出错后无从下手。 1.activemq服务器工作模型我们先看一下消息发送的时序图： ConnectionFactory 对象创建一个连接工厂，消息的发送和接受服务均由此进行； ConnectionFactory 创建一个活动Connection作为当前使用的连接； Session 是一个用于生成和使用消息的单线程上下文，它用于创建发送的生产者和接收消息的消费者，并为所发送的消息定义发送顺序。会话通过大量确认选项或通过事务来支持可靠传送。 户端使用 MessageProducer 向指定的物理目标发送消息，生产者可指定一个默认传送模式（持久性消息与非持久性消息）、优先级和有效期值，以控制生产者向物理目标发送的所有消息； 消费者可以支持同步或异步消息接收。异步使用可通过向消费者注册 MessageListener 来实现。当会话线程调用 MessageListener 对象的 onMessage 方法时，客户端将使用消息。 2.ActiveMQ消息传送模型 ActiveMQ 支持两种消息传送模型：PTP（即点对点模型）和Pub/Sub（即发布 /订阅模型）,前面我们已经讲过，在此就不赘述。 3.消息选择器ActiveMQ提供了一种机制，使用它，消息服务可根据消息选择器中的标准来执行消息过滤。生产者可在消息中放入应用程序特有的属性，而消费者可使用基于这些属性的选择标准来表明对消息是否感兴趣。 消息选择器是根据 header 和 properties 允许客户端选择性的制定需要接收的消息，消息选择器是无法利用 消息主体(Body)进行过滤的。无论你的消息主题是什么类型， 文本、或者对象、或者键值对。下面我们讲一下消息选择器的语法以及使用规范： 可接收的类型包括：byte,int,double,boolean,String; 属性标识符定义：变量名与java定义一样； 要么在heads中定义 要么在 properties中定义，如果在sender中是在heads中定义而receiver中却从properties中寻找的话，找不到的情况下他是不会自动去heads中寻找的，而是会返回null； 根据不同类型的变量选择不同的方法： message.setIntProperty(&quot;test&quot;,14); 那么在接收端可以对该变量进行拦截： session.createConsumer(destination,&quot;test &gt; 14&quot;)； 属性标志符是区分大小写的； 拦截器中的部分表示方式：可以是条件表达式 可以是算术表达式 可以是比较运算和逻辑运算组成的表达式 支持 () 左右括号； 支持逻辑运算的优先顺序表达式 例如: NOT , AND , OR； 比较运算符有: = , &gt; , &gt;= , &lt; , &lt;= , &lt;&gt; (not equal)； eg： 标识符是null &quot;prop_name IS NULL&quot; 标识符非空 not null &quot;prop_name IS NOT NULL&quot; &quot;age BETWEEN 15 AND 19&quot; is equivalent to &quot;age &gt;= 15 AND age &lt;= 19&quot; &quot;Country NOT IN (&apos; UK&apos;, &apos;US&apos;, &apos;France&apos;) &quot; 代码很简单，只需要在Sender端做如下改写： 123TextMessage message = session.createTextMessage();message.setIntProperty("test",14);message.setText("test"); Receiver端： 1consumer = session.createConsumer(destination,"test &gt; 14"); 对发送端的特定字符做一个判断符合条件即被拦截 4.消息确认机制jms消息只有在被确认之后才认为成功消费了这条消息。消息的成功消费通常包括三个步骤： （1）client接收消息 （2）client处理消息 （3）消息被确认（也就是client给一个确认消息） 在事务性会话中当一个事务被提交的时候，确认自动发生，和应答模式没关系，这个值可以随便写。（这里多提一句异步消息接收中不能使用事务性会话）。 在非事务性会话中消息何时被确认取决于创建的session中设置的消息应答模式（acknowledge model）该参数有三个值： Session.AUTO_ACKNOWLEDGE：当client端成功的从receive方法或从onMessage(Message message) 方法返回的时候，会话自动确认client收到消息。 Session.CLIENT_ACKNOWLEDGE: 客户单通过调用acknowledge方法来确认客户端收到消息。但需要注意在这种应答模式下，确认是在会话层上进行的，确认一个被消费的消息将自动确认所有已消费的其他消息。比如一个消费者已经消费了10条消息，然后确认了第5条消息被消费，则这10条都被确认消费了。、 acknowledge（）通知方法是在Message对象上，同步接收，调用acknowledge（）方法进行确认如下所示： consumer = session.createConsumer(queue);Message message = consumer.receive();message.acknowledge(); 异步接受，调用acknowledge（）方法进行确认： 12345678910111213consumer.setMessageListener(new MessageListener() &#123; @Override public void onMessage(Message message) &#123; TextMessage textMessage = (TextMessage) message; try &#123; String value = textMessage.getText(); System.out.println("value: " + value); message.acknowledge(); //消息消费确认通知 &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125;); 3.Session.DUPS_ACKNOWLEDGE：不是必须签收，消息可能会重复发送。在第二次重新传送消息的时候，消息头的JmsDelivered会被置为true标示当前消息已经传送过一次，客户端需要进行消息的重复处理控制。 5. 持久化消息JMS 支持以下两种消息提交模式： 5.1 ERSISTENT 持久消息是activemq默认的传送方式，此方式下的消息在配合activemq.xml中配置的消息存储方式，会被存储在特定的地方，直到有消费者将消息消费或者消息过期进入DLQ队列，消息生命周期才会结束。此模式下可以保证消息只会被成功传送一次和成功使用一次，消息具有可靠性。在消息传递到目标消费者，在消费者没有成功应答前，消息不会丢失。所以很自然的，需要一个地方来持久性存储。如果消息消费者在进行消费过程发生失败，则消息会被再次投递。 DeliveryMode.PERSISTENT 指示JMS provider持久保存消息，以保证消息不会因为JMS provider的失败而丢失。 消息持久化在硬盘中，ActiveMQ持久化有三种方式：AMQ、KahaDB、JDBC。 AMQ AMQ是一种文件存储形式，它具有写入速度快和容易恢复的特点。消息存储在一个个文件中，文件的默认大小为32M，如果一条消息的大小超过了32M，那么这个值必须设置大一点。当一个存储文件中的消息已经全部被消费，那么这个文件将被标识为可删除，在下一个清除阶段，这个文件被删除。AMQ适用于ActiveMQ5.3之前的版本。 KahaDB KahaDB是基于文件的本地数据库储存形式，虽然没有AMQ的速度快，但是它具有强扩展性，恢复的时间比AMQ短，从5.4版本之后KahaDB做为默认的持久化方式。 JDBC 可以将消息存储到数据库中，例如：Mysql、SQL Server、Oracle、DB2。 具体使用方式大家下去查一下，限于篇幅在此就不做太详细的介绍。 5.2 NON_PERSISTENT 非持久消息非持久的消息适用于不重要的，可以接受消息丢失的哪一类消息，这种消息只会被投递一次，消息不会在持久性存储中存储，也不会保证消息丢失后的重新投递。 DeliveryMode.NON_PERSISTENT 不要求JMS provider持久保存消息，消息存放在内存中，读写速度快，在JMS服务停止后消息会消失，没有持久化到硬盘。 6. ActiveMQ消息过期设置允许消息过期 。默认情况下，消息永不会过期。如果消息在特定周期内失去意义，那么可以设置过期时间。有两种方法设置消息的过期时间，时间单位为毫秒： 使用 setTimeToLive 方法为所有的消息设置过期时间； 使用 send 方法为每一条消息设置过期时间。 消息过期时间，send 方法中的 timeToLive 值加上发送时刻的 GMT 时间值。如果 timeToLive 值等于零，则 JMSExpiration 被设为零，表示该消息永不过期。如果发送后，在消息过期时间之后消息还没有被发送到目的地，则该消息被清除。 这一节对activemq的消息机制和持久化我们就简单介绍到这里，后面我们结合具体的工程来把它应用到生产中，再来讲解如何持久化如何高效的应用于生产环境。]]></content>
      <categories>
        <category>activeMQ</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件-activemq实战整合Spring之Topic模式(五)]]></title>
    <url>%2Fposts%2F1d6950fa.html</url>
    <content type="text"><![CDATA[这一节我们看一下Topic模式下的消息发布是如何处理的。 applicationContext-ActiveMQ.xml配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:amq="http://activemq.apache.org/schema/core" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans-4.1.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context-4.1.xsdhttp://www.springframework.org/schema/mvchttp://www.springframework.org/schema/mvc/spring-mvc-4.1.xsdhttp://activemq.apache.org/schema/corehttp://activemq.apache.org/schema/core/activemq-core-5.12.1.xsd"&gt; &lt;context:component-scan base-package="cn.edu.hust.activemq" /&gt; &lt;mvc:annotation-driven /&gt; &lt;amq:connectionFactory id="amqConnectionFactory" brokerURL="tcp://127.0.0.1:61616" userName="admin" password="admin" /&gt; &lt;!-- 配置JMS连接工厂 --&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.CachingConnectionFactory"&gt; &lt;constructor-arg ref="amqConnectionFactory" /&gt; &lt;property name="sessionCacheSize" value="100" /&gt; &lt;/bean&gt; &lt;!-- 定义消息队列（topic） --&gt; &lt;bean id="demoTopicDestination" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;!-- 设置消息队列的名字 --&gt; &lt;constructor-arg&gt; &lt;value&gt;first-queue&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 配置JMS模板（topic），Spring提供的JMS工具类，它发送、接收消息。 --&gt; &lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="defaultDestination" ref="demoTopicDestination" /&gt; &lt;property name="receiveTimeout" value="10000" /&gt; &lt;property name="pubSubDomain" value="true" /&gt; &lt;/bean&gt; &lt;!-- 配置消息队列监听者（topic） --&gt; &lt;bean id="topicMessageListener" class="cn.edu.hust.activemq.filter.QueueMessageListener" /&gt; &lt;bean id="topicMessageListener1" class="cn.edu.hust.activemq.filter.QueueMessageListener1" /&gt; &lt;!-- 显示注入消息监听容器（topic），配置连接工厂，监听的目标是demoQueueDestination，监听器是上面定义的监听器 --&gt; &lt;bean id="queueListenerContainer" class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="demoTopicDestination" /&gt; &lt;property name="messageListener" ref="topicMessageListener" /&gt; &lt;!--消息接收超时 --&gt; &lt;property name="receiveTimeout" value="10000" /&gt; &lt;/bean&gt; &lt;bean id="queueListenerContainerB" class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="demoTopicDestination" /&gt; &lt;property name="messageListener" ref="topicMessageListener1" /&gt; &lt;!--消息接收超时 --&gt; &lt;property name="receiveTimeout" value="10000" /&gt; &lt;/bean&gt; &lt;/beans&gt; 这里与queue模式不一样的地方在于订阅者有一个或是多个，有几个订阅者就需要配置监听器。 applicationContext.xml 12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- 查找最新的schemaLocation 访问 http://www.springframework.org/schema/ --&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/aophttp://www.springframework.org/schema/aop/spring-aop-4.0.xsdhttp://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans-4.0.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context-4.0.xsdhttp://www.springframework.org/schema/mvchttp://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd"&gt; &lt;!-- 指定Sping组件扫描的基本包路径 --&gt; &lt;context:component-scan base-package="cn.edu.hust.activemq" &gt; &lt;!-- 这里只扫描Controller，不可重复加载Service --&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;/context:component-scan&gt; &lt;!-- 启用MVC注解 --&gt; &lt;mvc:annotation-driven /&gt; &lt;!-- JSP视图解析器--&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/" /&gt; &lt;property name="suffix" value=".jsp" /&gt; &lt;!-- 定义其解析视图的order顺序为1 --&gt; &lt;property name="order" value="1" /&gt; &lt;/bean&gt;&lt;/beans&gt; web.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd" version="3.0"&gt;&lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext-ActiveMQ.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;servlet&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 处理编码格式 --&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 其余部分与queue模式代码一样，只是需要多配置一个监听器，目录结构如下： ProducerService.java 123456789101112import javax.jms.Destination;/** * Created by Administrator on 2017/5/3. */public interface ProducerService &#123; void sendMessage(Destination destination,final String msg); void sendMessage(final String msg);&#125; ProducerServiceImpl.java 1234567891011121314151617181920212223242526272829303132333435363738394041import cn.edu.hust.activemq.service.ProducerService;import org.springframework.jms.core.JmsTemplate;import org.springframework.jms.core.MessageCreator;import org.springframework.stereotype.Service;import javax.annotation.Resource;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.Session;/** * Created by Administrator on 2017/5/3. */@Servicepublic class ProducerServiceImpl implements ProducerService &#123; @Resource(name="jmsTemplate") private JmsTemplate jmsTemplate; @Override public void sendMessage(Destination destination, final String msg) &#123; System.out.println(Thread.currentThread().getName()+" 向队列"+destination.toString()+"发送消息---------&gt;"+msg); jmsTemplate.send(destination, new MessageCreator() &#123; public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage(msg); &#125; &#125;); &#125; @Override public void sendMessage(final String msg) &#123; String destination = jmsTemplate.getDefaultDestinationName(); System.out.println(Thread.currentThread().getName()+" 向队列"+destination+"发送消息--------&gt;"+msg); jmsTemplate.send(new MessageCreator() &#123; public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage(msg); &#125; &#125;); &#125;&#125; ConsumerService.java 123456789import javax.jms.Destination;import javax.jms.TextMessage;/** * Created by Administrator on 2017/5/3. */public interface ConsumerService &#123; TextMessage receive(Destination destination);&#125; ConsumerServiceImpl.java 123456789101112131415161718192021222324252627282930import cn.edu.hust.activemq.service.ConsumerService;import javax.jms.Destination;import javax.jms.TextMessage;import org.springframework.jms.core.JmsTemplate;import org.springframework.stereotype.Service;import javax.annotation.Resource;import javax.jms.JMSException;/** * Created by Administrator on 2017/5/3. */@Servicepublic class ConsumerServiceImpl implements ConsumerService &#123; @Resource(name="jmsTemplate") private JmsTemplate jmsTemplate; @Override public TextMessage receive(Destination destination)&#123; TextMessage textMessage = (TextMessage) jmsTemplate.receive(destination); try&#123; System.out.println("从队列" + destination.toString() + "收到了消息：\t" + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; return textMessage; &#125;&#125; QueueMessageListener.java 1234567891011121314151617181920import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage;/** * Created by Administrator on 2017/5/3. */public class QueueMessageListener implements MessageListener &#123; public void onMessage(Message message) &#123; TextMessage tm = (TextMessage) message; try &#123; System.out.println("topicMessageListener监听到了文本消息：\t" + tm.getText()); //do something ... &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; QueueMessageListener1.java 1234567891011121314151617181920import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage;/** * Created by Administrator on 2017/5/3. */public class QueueMessageListener1 implements MessageListener &#123; public void onMessage(Message message) &#123; TextMessage tm = (TextMessage) message; try &#123; System.out.println("topicMessageListener1监听到了文本消息：\t" + tm.getText()); //do something ... &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 接下来是controller: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import cn.edu.hust.activemq.service.ConsumerService;import cn.edu.hust.activemq.service.ProducerService;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.ResponseBody;import javax.annotation.Resource;import javax.jms.Destination;import javax.jms.TextMessage;/** * Created by Administrator on 2017/5/3. */@Controllerpublic class MessageController &#123; private Logger logger = LoggerFactory.getLogger(MessageController.class); @Resource(name = "demoQueueDestination") private Destination destination; //队列消息生产者 @Resource private ProducerService producer; //队列消息消费者 @Resource private ConsumerService consumer; @RequestMapping(value = "/SendMessage", method = RequestMethod.GET) @ResponseBody public void send(String msg) &#123; logger.info(Thread.currentThread().getName()+"------------开始发送消息"); producer.sendMessage(msg); logger.info(Thread.currentThread().getName()+"------------发送完毕"); &#125; @RequestMapping(value= "/ReceiveMessage",method = RequestMethod.GET) @ResponseBody public Object receive()&#123; logger.info(Thread.currentThread().getName()+"------------开始接受消息"); TextMessage tm = consumer.receive(destination); logger.info(Thread.currentThread().getName()+"------------接受完毕"); return tm; &#125;&#125; 我们启动工程，在地址栏中输入：http://localhost:8080/SendMessage?msg=nihao，代码很简单我就没有写前台页面啦，msg部分你可以随便写。回车之后我们去看一下控制台两个订阅者都接收到消息。]]></content>
      <categories>
        <category>activeMQ</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件-activemq实战之消息持久化(六)]]></title>
    <url>%2Fposts%2Faf8467f6.html</url>
    <content type="text"><![CDATA[对于activemq消息的持久化我们在第二节的时候就简单介绍过，今天我们详细的来分析一下activemq的持久化过程以及持久化插件。在生产环境中为确保消息的可靠性，我们肯定的面临持久化消息的问题，今天就一起来攻克他吧。 1. 持久化方式介绍前面我们也简单提到了activemq提供的插件式的消息存储，在这里再提一下，主要有以下几种方式： AMQ消息存储-基于文件的存储方式，是activemq开始的版本默认的消息存储方式； KahaDB消息存储-提供了容量的提升和恢复能力，是现在的默认存储方式； JDBC消息存储-消息基于JDBC存储的； Memory消息存储-基于内存的消息存储，由于内存不属于持久化范畴，而且如果使用内存队列，可以考虑使用更合适的产品，如ZeroMQ。所以内存存储不在讨论范围内。 上面几种消息存储方式对于消息存储的逻辑来说并没有什么区别，只是在性能以及存储方式上来说有所不同。但是对于消息发送的方式来说，p2p和Pub/Sub两种类型的消息他们的持久化方式却是不同的： 对于点对点的消息一旦消费者完成消费这条消息将从broker上删除；对于发布订阅类型的消息，即使所有的订阅者都完成了消费，Broker也不一定会马上删除无用消息，而是保留推送历史，之后会异步清除无用消息。而每个订阅者消费到了哪条消息的offset会记录在Broker，以免下次重复消费。因为消息是顺序消费，先进先出，所以只需要记录上次消息消费到哪里就可以了。 因为AMQ现在已经被不再使用被KahaDB所替代，所以我们就讲KahaDB，JDBC消息存储在许多对可靠性要求高而对性能要求低一些的大公司还是经常使用的，下面我们就这两种持久化方式的使用做一节专题。 2. Kahadb说到Kahadb之前我们还是得提到他的前身AMQ，AMQ是一种文件存储形式，他具有写入速度快和容易恢复的特点，消息存储在一个个的文件里，文件默认大小为32M，超过这个大小的消息将会存入下一个文件。当一个文件中的消息已经全部消费，那么这个文件将被标志我可删除，在下一个清除阶段这个文件将被删除。 如果需要使用持久化，则需要在前文中的配置文件applicationContext-ActiveMQ.xml中增加如下配置： 123&lt;persistenceAdapter&gt;&lt;amqPersistenceAdapterdirectory="activemq-data"maxFileLength="32mb"/&gt;&lt;/persistenceAdapter&gt; directory : 指定持久化消息的存储目录journalMaxFileLength : 指定保存消息的日志文件大小，具体根据你的实际应用配置 我们的Kahadb也是基于文件的本地数据库存储形式，他虽然没有AMQ快，但是扩展性很强，从activemq5.4版本之后就把Kahadb作为默认的持久化方式。 Kahadb的配置方式如下： 123&lt;persistenceAdapter&gt; &lt;kahaDB directory="activemq-data"journalMaxFileLength="32mb"/&gt; &lt;/persistenceAdapter&gt; KahaDB的属性件下表格： 属性名称 属性值 描述 directory activemq-data 消息文件和日志的存储目录 indexWriteBatchSize 1000 一批索引的大小，当要更新的索引量到达这个值时，更新到消息文件中 indexCacheSize 1000 内存中，索引的页大小 enableIndexWriteAsync false 索引是否异步写到消息文件中 journalMaxFileLength 32mb 一个消息文件的大小 enableJournalDiskSyncs true 是否讲非事务的消息同步写入到磁盘 cleanupInterval 30000 清除操作周期，单位ms checkpointInterval 5000 索引写入到消息文件的周期，单位ms ignoreMissingJournalfiles false 忽略丢失的消息文件，false，当丢失了消息文件，启动异常 checkForCorruptJournalFiles false 检查消息文件是否损坏，true，检查发现损坏会尝试修复 checksumJournalFiles false 产生一个checksum，以便能够检测journal文件是否损坏。 5.4版本之后有效的属性: archiveDataLogs false 当为true时，归档的消息文件被移到directoryArchive,而不是直接删除 directoryArchive null 存储被归档的消息文件目录 databaseLockedWaitDelay 10000 在使用负载时，等待获得文件锁的延迟时间，单位ms maxAsyncJobs 10000 同个生产者产生等待写入的异步消息最大量 concurrentStoreAndDispatchTopics false 当写入消息的时候，是否转发主题消息 concurrentStoreAndDispatchQueues true 当写入消息的时候，是否转发队列消息 5.6版本之后有效的属性: archiveCorruptedIndex false 是否归档错误的索引 由于在ActiveMQ V5.4+的版本中，KahaDB是默认的持久化存储方案。所以即使你不配置任何的KahaDB参数信息，ActiveMQ也会启动KahaDB。这种情况下，KahaDB文件所在位置是你的ActiveMQ安装路径下的/data/${broker.Name}/KahaDB子目录。其中${broker.Name}代表这个ActiveMQ服务节点的名称。下面我把刚启动服务并发送了消息之后的activemq安装目录打开给大家看看： 正式的生产环境还是建议在主配置文件中明确设置KahaDB的工作参数： 12345678910&lt;broker xmlns="http://activemq.apache.org/schema/core" brokerName="broker" persistent="true" useShutdownHook="false"&gt; ... &lt;persistenceAdapter&gt; &lt;kahaDB directory="activemq-data" journalMaxFileLength="32mb" concurrentStoreAndDispatchQueues="false" concurrentStoreAndDispatchTopics="false" /&gt; &lt;/persistenceAdapter&gt;&lt;/broker&gt; 3. 关系型数据库存储方案从ActiveMQ 4+版本开始，ActiveMQ就支持使用关系型数据库进行持久化存储——通过JDBC实现的数据库连接。可以使用的关系型数据库囊括了目前市面的主流数据库。 使用JDBC的方式持久化我们就得修改之前的配置文件： 将其中的这段配置： 123&lt;persistenceAdapter&gt; &lt;kahaDB directory="$&#123;activemq.base&#125;/data/kahadb"/&gt;&lt;/persistenceAdapter&gt; 修改为下面这段内容： 123&lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource="# mysql-ds "/&gt;&lt;/persistenceAdapter&gt; 在结点之后，增加数据源的配置,如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110&lt;!-- MySql DataSource Sample Setup --&gt; &lt;bean id="mysql-ds" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/activemqdb?relaxAutoCommit=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf-8"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="root"/&gt; &lt;property name="poolPreparedStatements" value="true"/&gt; &lt;/bean&gt; &lt;!-- Oracle DataSource Sample Setup --&gt; &lt;bean id="oracle-ds" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close"&gt; &lt;property name="driverClassName" value="oracle.jdbc.driver.OracleDriver"/&gt; &lt;property name="url" value="jdbc:oracle:thin:@localhost:1521:activemqdb"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="root"/&gt; &lt;property name="poolPreparedStatements" value="true"/&gt; &lt;/bean&gt; &lt;!-- Oracle DataSource Sample Setup --&gt; &lt;bean id="db2-ds" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close"&gt; &lt;property name="driverClassName" value="com.ibm.db2.jcc.DB2Driver"/&gt; &lt;property name="url" value="jdbc:db2://hndb02.bf.ctc.com:50002/activemq"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="root"/&gt; &lt;property name="maxActive" value="200"/&gt; &lt;property name="poolPreparedStatements" value="true"/&gt; &lt;/bean&gt; ``` 还是在上一篇的实例工程中，我们改变一下applicationContext-ActiveMQ.xml的配置如下：```java&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:amq="http://activemq.apache.org/schema/core" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans-4.1.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context-4.1.xsdhttp://www.springframework.org/schema/mvchttp://www.springframework.org/schema/mvc/spring-mvc-4.1.xsdhttp://activemq.apache.org/schema/corehttp://activemq.apache.org/schema/core/activemq-core-5.12.1.xsd"&gt; &lt;context:component-scan base-package="cn.edu.hust.activemq" /&gt; &lt;mvc:annotation-driven /&gt; &lt;amq:connectionFactory id="amqConnectionFactory" brokerURL="tcp://127.0.0.1:61616" userName="admin" password="admin" /&gt; &lt;!-- 配置JMS连接工厂 --&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.CachingConnectionFactory"&gt; &lt;constructor-arg ref="amqConnectionFactory" /&gt; &lt;property name="sessionCacheSize" value="100" /&gt; &lt;/bean&gt; &lt;!-- 定义消息队列（Queue） --&gt; &lt;bean id="demoQueueDestination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;!-- 设置消息队列的名字 --&gt; &lt;constructor-arg&gt; &lt;value&gt;first-queue&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 配置JMS模板（Queue），Spring提供的JMS工具类，它发送、接收消息。 --&gt; &lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="defaultDestination" ref="demoQueueDestination" /&gt; &lt;property name="receiveTimeout" value="10000" /&gt; &lt;!-- true是topic，false是queue，默认是false，此处显示写出false --&gt; &lt;property name="pubSubDomain" value="false" /&gt; &lt;/bean&gt; &lt;!-- 配置消息队列监听者（Queue） --&gt; &lt;bean id="queueMessageListener" class="cn.edu.hust.activemq.filter.QueueMessageListener" /&gt; &lt;!-- 显示注入消息监听容器（Queue），配置连接工厂，监听的目标是demoQueueDestination，监听器是上面定义的监听器 --&gt; &lt;bean id="queueListenerContainer" class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="demoQueueDestination" /&gt; &lt;property name="messageListener" ref="queueMessageListener" /&gt; &lt;/bean&gt; &lt;broker xmlns="http://activemq.apache.org/schema/core" brokerName="localhost" dataDirectory="$&#123;activemq.data&#125;" persistent="true"&gt; &lt;!--&lt;persistenceAdapter&gt; &lt;kahaDB directory="$&#123;activemq.data&#125;/kahadb"/&gt; &lt;/persistenceAdapter&gt; --&gt; &lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataDirectory="$&#123;activemq.data&#125;" dataSource="#mysql-ds"&gt; &lt;/jdbcPersistenceAdapter&gt; &lt;/persistenceAdapter&gt; &lt;/broker&gt; &lt;bean id="mysql-ds" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://127.0.0.1/activemq?relaxAutoCommit=true"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt; &lt;property name="maxActive" value="200"/&gt; &lt;property name="poolPreparedStatements" value="true"/&gt; &lt;/bean&gt;&lt;/beans&gt; 此时，重新启动MQ，就会发现db数据库中多了三张表：activemq_acks，activemq_lock，activemq_msgs，OK，说明activemq已经持久化成功啦！ activemq_acks：用于存储订阅关系。如果是持久化Topic，订阅者和服务器的订阅关系在这个表保存，主要数据库字段如下： container：消息的destination sub_dest：如果是使用static集群，这个字段会有集群其他系统的信息 client_id：每个订阅者都必须有一个唯一的客户端id用以区分 sub_name：订阅者名称 selector：选择器，可以选择只消费满足条件的消息。条件可以用自定义属性实现，可支持多属性and和or操作 last_acked_id：记录消费过的消息的id activemq_lock：在集群环境中才有用，只有一个Broker可以获得消息，称为Master Broker，其他的只能作为备份等待Master Broker不可用，才可能成为下一个Master Broker。这个表用于记录哪个Broker是当前的Master Broker。 activemq_msgs：用于存储消息，Queue和Topic都存储在这个表中。主要的数据库字段如下： id：自增的数据库主键 container：消息的destination msgid_prod：消息发送者客户端的主键 msg_seq：是发送消息的顺序，msgid_prod+msg_seq可以组成jms的messageid expiration：消息的过期时间，存储的是从1970-01-01到现在的毫秒数 msg：消息本体的java序列化对象的二进制数据 priority：优先级，从0-9，数值越大优先级越高 activemq_acks用于存储订阅关系。如果是持久化topic，订阅者和服务器的订阅关系在这个表保存。]]></content>
      <categories>
        <category>activeMQ</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习-NIO(三)Channel]]></title>
    <url>%2Fposts%2F12968bae.html</url>
    <content type="text"><![CDATA[通道（Channel）是java.nio的第二个主要创新。它们既不是一个扩展也不是一项增强，而是全新、极好的Java I/O示例，提供与I/O服务的直接连接。Channel用于在字节缓冲区和位于通道另一侧的实体（通常是一个文件或套接字）之间有效地传输数据。 channel介绍通道是访问I/O服务的导管。I/O可以分为广义的两大类别：File I/O和Stream I/O。那么相应地有两种类型的通道也就不足为怪了，它们是文件（file）通道和套接字（socket）通道。我们看到在api里有一个FileChannel类和三个socket通道类：SocketChannel、ServerSocketChannel和DatagramChannel。 通道可以以多种方式创建。Socket通道有可以直接创建新socket通道的工厂方法。但是一个FileChannel对象却只能通过在一个打开的RandomAccessFile、FileInputStream或FileOutputStream对象上调用getChannel( )方法来获取。你不能直接创建一个FileChannel对象。 我们先来看一下FileChannel的用法： 1234567891011121314151617181920212223242526272829303132333435// 创建文件输出字节流FileOutputStream fos = new FileOutputStream("data.txt");//得到文件通道FileChannel fc = fos.getChannel();//往通道写入ByteBufferfc.write(ByteBuffer.wrap("Some text ".getBytes()));//关闭流fos.close();//随机访问文件RandomAccessFile raf = new RandomAccessFile("data.txt", "rw");//得到文件通道fc = raf.getChannel();//设置通道的文件位置 为末尾fc.position(fc.size()); //往通道写入ByteBufferfc.write(ByteBuffer.wrap("Some more".getBytes()));//关闭raf.close();//创建文件输入流FileInputStream fs = new FileInputStream("data.txt");//得到文件通道fc = fs.getChannel();//分配ByteBuffer空间大小ByteBuffer buff = ByteBuffer.allocate(BSIZE);//从通道中读取ByteBufferfc.read(buff);//调用此方法为一系列通道写入或相对获取 操作做好准备buff.flip();//从ByteBuffer从依次读取字节并打印while (buff.hasRemaining())&#123; System.out.print((char) buff.get());&#125;fs.close(); 再来看一下SocketChannel： 12345SocketChannel sc = SocketChannel.open( );sc.connect (new InetSocketAddress ("somehost", someport)); ServerSocketChannel ssc = ServerSocketChannel.open( ); ssc.socket( ).bind (new InetSocketAddress (somelocalport)); DatagramChannel dc = DatagramChannel.open( ); 可以设置 SocketChannel 为非阻塞模式（non-blocking mode）.设置之后，就可以在异步模式下调用connect(), read() 和write()了。如果SocketChannel在非阻塞模式下，此时调用connect()，该方法可能在连接建立之前就返回了。为了确定连接是否建立，可以调用finishConnect()的方法。像这样： 123456socketChannel.configureBlocking(false);socketChannel.connect(new InetSocketAddress("http://jenkov.com", 80)); while(! socketChannel.finishConnect() )&#123; //wait, or do something else...&#125; 服务器端的使用经常会考虑到非阻塞socket通道，因为它们使同时管理很多socket通道变得更容易。但是，在客户端使用一个或几个非阻塞模式的socket通道也是有益处的，例如，借助非阻塞socket通道，GUI程序可以专注于用户请求并且同时维护与一个或多个服务器的会话。在很多程序上，非阻塞模式都是有用的。 调用finishConnect( )方法来完成连接过程，该方法任何时候都可以安全地进行调用。假如在一个非阻塞模式的SocketChannel对象上调用finishConnect( )方法，将可能出现下列情形之一： connect( )方法尚未被调用。那么将产生NoConnectionPendingException异常。 连接建立过程正在进行，尚未完成。那么什么都不会发生，finishConnect( )方法会立即返回false值。 在非阻塞模式下调用connect( )方法之后，SocketChannel又被切换回了阻塞模式。那么如果有必要的话，调用线程会阻塞直到连接建立完成，finishConnect( )方法接着就会返回true值。在初次调用connect( )或最后一次调用finishConnect( )之后，连接建立过程已经完成。那么SocketChannel对象的内部状态将被更新到已连接状态，finishConnect( )方法会返回true值，然后SocketChannel对象就可以被用来传输数据了。 连接已经建立。那么什么都不会发生，finishConnect( )方法会返回true值。 Socket通道是线程安全的。并发访问时无需特别措施来保护发起访问的多个线程，不过任何时候都只有一个读操作和一个写操作在进行中。请记住，sockets是面向流的而非包导向的。它们可以保证发送的字节会按照顺序到达但无法承诺维持字节分组。某个发送器可能给一个socket写入了20个字节而接收器调用read( )方法时却只收到了其中的3个字节。剩下的17个字节还是传输中。由于这个原因，让多个不配合的线程共享某个流socket的同一侧绝非一个好的设计选择。 最后再看一下DatagramChannel： 最后一个socket通道是DatagramChannel。正如SocketChannel对应Socket，ServerSocketChannel对应ServerSocket，每一个DatagramChannel对象也有一个关联的DatagramSocket对象。不过原命名模式在此并未适用：“DatagramSocketChannel”显得有点笨拙，因此采用了简洁的“DatagramChannel”名称。 正如SocketChannel模拟连接导向的流协议（如TCP/IP），DatagramChannel则模拟包导向的无连接协议（如UDP/IP）： 创建DatagramChannel的模式和创建其他socket通道是一样的：调用静态的open( )方法来创建一个新实例。新DatagramChannel会有一个可以通过调用socket( )方法获取的对等DatagramSocket对象。DatagramChannel对象既可以充当服务器（监听者）也可以充当客户端（发送者）。如果你希望新创建的通道负责监听，那么通道必须首先被绑定到一个端口或地址/端口组合上。绑定DatagramChannel同绑定一个常规的DatagramSocket没什么区别，都是委托对等socket对象上的API实现的： 123DatagramChannel channel = DatagramChannel.open( );DatagramSocket socket = channel.socket( ); socket.bind (new InetSocketAddress (portNumber)); DatagramChannel是无连接的。每个数据报（datagram）都是一个自包含的实体，拥有它自己的目的地址及不依赖其他数据报的数据净荷。与面向流的的socket不同，DatagramChannel可以发送单独的数据报给不同的目的地址。同样，DatagramChannel对象也可以接收来自任意地址的数据包。每个到达的数据报都含有关于它来自何处的信息（源地址）。 一个未绑定的DatagramChannel仍能接收数据包。当一个底层socket被创建时，一个动态生成的端口号就会分配给它。绑定行为要求通道关联的端口被设置为一个特定的值（此过程可能涉及安全检查或其他验证）。不论通道是否绑定，所有发送的包都含有DatagramChannel的源地址（带端口号）。未绑定的DatagramChannel可以接收发送给它的端口的包，通常是来回应该通道之前发出的一个包。已绑定的通道接收发送给它们所绑定的熟知端口（wellknown port）的包。数据的实际发送或接收是通过send( )和receive( )方法来实现的。 注意：*假如您提供的ByteBuffer没有足够的剩余空间来存放您正在接收的数据包，没有被填充的字节都会被悄悄地丢弃。* Scatter/Gather通道提供了一种被称为Scatter/Gather的重要新功能（有时也被称为矢量I/O）。它是指在多个缓冲区上实现一个简单的I/O操作。对于一个write操作而言，数据是从几个缓冲区按顺序抽取（称为gather）并沿着通道发送的。缓冲区本身并不需要具备这种gather的能力（通常它们也没有此能力）。该gather过程的效果就好比全部缓冲区的内容被连结起来，并在发送数据前存放到一个大的缓冲区中。对于read操作而言，从通道读取的数据会按顺序被散布（称为scatter）到多个缓冲区，将每个缓冲区填满直至通道中的数据或者缓冲区的最大空间被消耗完。 scatter / gather经常用于需要将传输的数据分开处理的场合，例如传输一个由消息头和消息体组成的消息，你可能会将消息体和消息头分散到不同的buffer中，这样你可以方便的处理消息头和消息体。 Scattering Reads是指数据从一个channel读取到多个buffer中。如下图描述： 代码示例如下： 1234ByteBuffer header = ByteBuffer.allocateDirect (10); ByteBuffer body = ByteBuffer.allocateDirect (80); ByteBuffer [] buffers = &#123; header, body &#125;; int bytesRead = channel.read (buffers); Gathering Writes是指数据从多个buffer写入到同一个channel。如下图描述： 代码示例如下： 1234ByteBuffer header = ByteBuffer.allocateDirect (10); ByteBuffer body = ByteBuffer.allocateDirect (80); ByteBuffer [] buffers = &#123; header, body &#125;; channel.write(bufferArray); 使用得当的话，Scatter/Gather会是一个极其强大的工具。它允许你委托操作系统来完成辛苦活：将读取到的数据分开存放到多个存储桶（bucket）或者将不同的数据区块合并成一个整体。这是一个巨大的成就，因为操作系统已经被高度优化来完成此类工作了。它节省了您来回移动数据的工作，也就避免了缓冲区拷贝和减少了您需要编写、调试的代码数量。既然您基本上通过提供数据容器引用来组合数据，那么按照不同的组合构建多个缓冲区阵列引用，各种数据区块就可以以不同的方式来组合了。下面的例子好地诠释了这一点： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class GatheringTest &#123; private static final String DEMOGRAPHIC = "output.txt"; public static void main (String [] argv) throws Exception &#123; int reps = 10; if (argv.length &gt; 0) &#123; reps = Integer.parseInt(argv[0]); &#125; FileOutputStream fos = new FileOutputStream(DEMOGRAPHIC); GatheringByteChannel gatherChannel = fos.getChannel(); ByteBuffer[] bs = utterBS(reps); while (gatherChannel.write(bs) &gt; 0) &#123; // 不做操作，让通道把数据输出到文件写完 &#125; System.out.println("Mindshare paradigms synergized to " + DEMOGRAPHIC); fos.close(); &#125; private static String [] col1 = &#123; "Aggregate", "Enable", "Leverage", "Facilitate", "Synergize", "Repurpose", "Strategize", "Reinvent", "Harness" &#125;; private static String [] col2 = &#123; "cross-platform", "best-of-breed", "frictionless", "ubiquitous", "extensible", "compelling", "mission-critical", "collaborative", "integrated" &#125;; private static String [] col3 = &#123; "methodologies", "infomediaries", "platforms", "schemas", "mindshare", "paradigms", "functionalities", "web services", "infrastructures" &#125;; private static String newline = System.getProperty ("line.separator"); private static ByteBuffer [] utterBS (int howMany) throws Exception &#123; List list = new LinkedList(); for (int i = 0; i &lt; howMany; i++) &#123; list.add(pickRandom(col1, " ")); list.add(pickRandom(col2, " ")); list.add(pickRandom(col3, newline)); &#125; ByteBuffer[] bufs = new ByteBuffer[list.size()]; list.toArray(bufs); return (bufs); &#125; private static Random rand = new Random( ); /** * 随机生成字符 * @param strings * @param suffix * @return * @throws Exception */ private static ByteBuffer pickRandom (String [] strings, String suffix) throws Exception &#123; String string = strings [rand.nextInt (strings.length)]; int total = string.length() + suffix.length( ); ByteBuffer buf = ByteBuffer.allocate (total); buf.put (string.getBytes ("US-ASCII")); buf.put (suffix.getBytes ("US-ASCII")); buf.flip( ); return (buf); &#125;&#125; 输出为： Reinvent integrated web services Aggregate best-of-breed platforms Harness frictionless platforms Repurpose extensible paradigms Facilitate ubiquitous methodologies Repurpose integrated methodologies Facilitate mission-critical paradigms Synergize compelling methodologies Reinvent compelling functionalities Facilitate extensible platforms 虽然这种输出没有什么意义，但是gather确是很容易的让我们把它输出出来。 Pipejava.nio.channels包中含有一个名为Pipe（管道）的类。广义上讲，管道就是一个用来在两个实体之间单向传输数据的导管。Java NIO 管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道，从source通道读取。Pipe类创建一对提供环回机制的Channel对象。这两个通道的远端是连接起来的，以便任何写在SinkChannel对象上的数据都能出现在SourceChannel对象上。 下面我们来创建一条Pipe，并向Pipe中写数据： 123456789101112131415//通过Pipe.open()方法打开管道Pipe pipe = Pipe.open();//要向管道写数据，需要访问sink通道Pipe.SinkChannel sinkChannel = pipe.sink();//通过调用SinkChannel的write()方法，将数据写入SinkChannelString newData = "New String to write to file..." + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; sinkChannel.write(buf);&#125; 再看如何从管道中读取数据： 读取管道的数据，需要访问source通道： 1Pipe.SourceChannel sourceChannel = pipe.source(); 调用source通道的read()方法来读取数据： 12ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = sourceChannel.read(buf); read()方法返回的int值会告诉我们多少字节被读进了缓冲区。 到此我们就把通道的简单用法讲完了，要想会用还是得多去练习，多模拟使用，这样才知道什么时候用以及怎么用，下节我们来讲选择器-Selectors。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件-activemq实战之整合Spring(四)]]></title>
    <url>%2Fposts%2F64e3c39e.html</url>
    <content type="text"><![CDATA[前面的理论准备已经很充分，这一节我们来实战：将activemq整合到Spring框架才行中，因为Spring已经集成了JMS，这也为我们配置activermq带来了方便。 1. Spring对jms的支持因为Spring已经将JMS集成到框架里面了，对jms做了自己的封装，我们使用起来更加方便，在Spring中使用jms比较麻烦的就是配置，在Spring中配置JMS大体需要8个部分： ConnectionFactory： 和jms服务器的连接, 可以是外部的jms server, 也可以使用embedded ActiveMQ Broker； Destination： 有topic和queue两种方式； JmsTemplate： spring提供的jms模板； MessageConverter： 消息转换器； MessageProducer： 消息生产者； MessageConsumer： 消息消费者； MessageListener： 消息监听器； MessageListenerContainer： 消息监听容器。 下面我把完整的配置文件按照上面的步骤拆开分别讲解： 1.1首先我们配置ConnectionFactory： 1234&lt;amq:connectionFactory id="amqConnectionFactory" brokerURL="tcp://127.0.0.1:61616" userName="admin" password="admin" /&gt; brokerURL是指要连接的activeMQ server的地址，该配置即使用activemq独立的消息存储环境，即使服务器重启消息也不会丢失。 123456&lt;!-- 配置JMS连接工厂 --&gt;&lt;bean id="connectionFactory" class="org.springframework.jms.connection.CachingConnectionFactory"&gt; &lt;constructor-arg ref="amqConnectionFactory" /&gt; &lt;property name="sessionCacheSize" value="100" /&gt;&lt;/bean&gt; 我们从Spring给我们提供的connectionFactory中获取Connection，并且把该connectionFactory注册到上面定义的activemq server中。 1.2 Destination： 由前面我们知道Destination有两种形式：P2P和Pub/Sub。那么在配置中表示就是： 1234567&lt;!-- 定义消息队列（Queue） --&gt;&lt;bean id="demoQueueDestination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;!-- 设置消息队列的名字 --&gt; &lt;constructor-arg&gt; &lt;value&gt;first-queue&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 或： 1234567&lt;!-- 定义消息队列（topic） --&gt;&lt;bean id="demoQueueDestination" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;!-- 设置消息队列的名字 --&gt; &lt;constructor-arg&gt; &lt;value&gt;first-queue&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 1.3 JmsTemplate： 将connectionFactory和defaultDestination注入JmsTemplate中： 12345678&lt;!-- 配置JMS模板（Queue），Spring提供的JMS工具类，它发送、接收消息。 --&gt;&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="defaultDestination" ref="demoQueueDestination" /&gt; &lt;property name="receiveTimeout" value="10000" /&gt; &lt;!-- true是topic，false是queue，默认是false，此处显示写出false --&gt; &lt;property name="pubSubDomain" value="false" /&gt;&lt;/bean&gt; 在Java相关处理文件中添加(这里用的是@Inject注解，当然也可以用@Autowired)： 1234@Resource(name="jmsTemplate")private JmsTemplate jmsTemplate;TextMessage textMessage = (TextMessage) jmsTemplate.receive(destination); 1.4 MessageConverter MessageConverter实现的是org.springframework.jms.support.converter.MessageConverter接口, 提供消息的转换功能。 1&lt;bean id="defaultMessageConverter" class="cn.edu.hust.activemq.filter.DefaultMessageConverter" /&gt; 1.5 MessageProducer和MessageConsumer 此处灵活使用，可以以服务的形式提供也可以以工具类的形式提供，详情见下面的示例代码。 1.6 MessageListener 消息的消费者应有的有对应的Listener。 12&lt;!-- 配置消息队列监听者（Queue） --&gt;&lt;bean id="queueMessageListener" class="cn.edu.hust.activemq.filter.QueueMessageListener" /&gt; = 1.7 MessageListenerContainer MessageListenerContainer即Listener的容器，用来对Listener坐一些配置，每一个listener都对应着一个Container： 1234567&lt;!-- 显示注入消息监听容器（Queue），配置连接工厂，监听的目标是demoQueueDestination，监听器是上面定义的监听器 --&gt;&lt;bean id="queueListenerContainer" class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="demoQueueDestination" /&gt; &lt;property name="messageListener" ref="queueMessageListener" /&gt;&lt;/bean&gt; Spring为我们听过了两种类型的MessageListenerContainer：SimpleMessageListenerContainer和DefaultMessageListenerContainer。 SimpleMessageListenerContainer会在一开始的时候就创建一个会话Session和消费者Consumer，并且会适用标准的JMS的MessageConsumer.setMessageListener()方法注册监听器让JMS提供调用监听器的回调函数。它不会动态的适应运行时需要和参与外部的事务管理。兼容性方面，它非常接近于独立的JMS规范，但一般不兼容J2EE的JMS限制。大多数情况下，我们还是使用DefaultMessageListenerContainer。 DefaultMessageListenerContainer，与SimpleMessageListenerContainer相比，它会动态的适应运行时的需求，并且能够参与外部的事务管理。 上面就是mq的配置文件部分，如果从上到下的配置部分都清楚地话使用起来肯定没有问题，我们再做一个简要的总结： 可以有一个或者多个消息生产者向同一个destination发送消息； queue类型的只能有一个消息消费者； topic类型的可以有多个消息消费者； 每个消费者对应一个MessageListener和一个MessageListenerContainer。 下面我们看一下整合的全部代码： 首先上pom.xml看一下依赖的jar包： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;q&lt;/groupId&gt; &lt;artifactId&gt;q&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;q Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;springframework&gt;4.3.0.RELEASE&lt;/springframework&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;springframework&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;springframework&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;springframework&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;springframework&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;$&#123;springframework&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- xbean 如&lt;amq:connectionFactory /&gt; --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.xbean&lt;/groupId&gt; &lt;artifactId&gt;xbean-spring&lt;/artifactId&gt; &lt;version&gt;3.16&lt;/version&gt; &lt;/dependency&gt; &lt;!-- activemq --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-core&lt;/artifactId&gt; &lt;version&gt;5.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt; &lt;version&gt;5.12.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;q&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.6&lt;/source&gt; &lt;target&gt;1.6&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 然后是我们的Spring配置文件applicationContext.xml: 12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- 查找最新的schemaLocation 访问 http://www.springframework.org/schema/ --&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/aophttp://www.springframework.org/schema/aop/spring-aop-4.0.xsdhttp://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans-4.0.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context-4.0.xsdhttp://www.springframework.org/schema/mvchttp://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd"&gt; &lt;!-- 指定Sping组件扫描的基本包路径 --&gt; &lt;context:component-scan base-package="cn.edu.hust.activemq" &gt; &lt;!-- 这里只扫描Controller，不可重复加载Service --&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;/context:component-scan&gt; &lt;!-- 启用MVC注解 --&gt; &lt;mvc:annotation-driven /&gt; &lt;!-- JSP视图解析器--&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/" /&gt; &lt;property name="suffix" value=".jsp" /&gt; &lt;!-- 定义其解析视图的order顺序为1 --&gt; &lt;property name="order" value="1" /&gt; &lt;/bean&gt;&lt;/beans&gt; activemq的配置文件applicationContext-ActiveMQ.xml： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:amq="http://activemq.apache.org/schema/core" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans-4.1.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context-4.1.xsdhttp://www.springframework.org/schema/mvchttp://www.springframework.org/schema/mvc/spring-mvc-4.1.xsdhttp://activemq.apache.org/schema/corehttp://activemq.apache.org/schema/core/activemq-core-5.12.1.xsd"&gt; &lt;context:component-scan base-package="cn.edu.hust.activemq" /&gt; &lt;mvc:annotation-driven /&gt; &lt;amq:connectionFactory id="amqConnectionFactory" brokerURL="tcp://127.0.0.1:61616" userName="admin" password="admin" /&gt; &lt;!-- 配置JMS连接工厂 --&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.CachingConnectionFactory"&gt; &lt;constructor-arg ref="amqConnectionFactory" /&gt; &lt;property name="sessionCacheSize" value="100" /&gt; &lt;/bean&gt; &lt;!-- 定义消息队列（Queue） --&gt; &lt;bean id="demoQueueDestination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;!-- 设置消息队列的名字 --&gt; &lt;constructor-arg&gt; &lt;value&gt;first-queue&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 配置JMS模板（Queue），Spring提供的JMS工具类，它发送、接收消息。 --&gt; &lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="defaultDestination" ref="demoQueueDestination" /&gt; &lt;property name="receiveTimeout" value="10000" /&gt; &lt;!-- true是topic，false是queue，默认是false，此处显示写出false --&gt; &lt;property name="pubSubDomain" value="false" /&gt; &lt;/bean&gt; &lt;!-- 配置消息队列监听者（Queue） --&gt; &lt;bean id="queueMessageListener" class="cn.edu.hust.activemq.filter.QueueMessageListener" /&gt; &lt;!-- 显示注入消息监听容器（Queue），配置连接工厂，监听的目标是demoQueueDestination，监听器是上面定义的监听器 --&gt; &lt;bean id="queueListenerContainer" class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="demoQueueDestination" /&gt; &lt;property name="messageListener" ref="queueMessageListener" /&gt; &lt;/bean&gt;&lt;/beans&gt; 配置的介绍在上面我已经讲过了，不明白的地方翻到上面去看看。 web.xml文件的配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd" version="3.0"&gt;&lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext-ActiveMQ.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;servlet&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 处理编码格式 --&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 我们的工程目录结构如下： 上service的代码： ProducerService.java 123456789101112import javax.jms.Destination;/** * Created by Administrator on 2017/5/3. */public interface ProducerService &#123; void sendMessage(Destination destination,final String msg); void sendMessage(final String msg);&#125; ProducerServiceImpl.java 1234567891011121314151617181920212223242526272829303132333435363738394041import cn.edu.hust.activemq.service.ProducerService;import org.springframework.jms.core.JmsTemplate;import org.springframework.jms.core.MessageCreator;import org.springframework.stereotype.Service;import javax.annotation.Resource;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.Session;/** * Created by Administrator on 2017/5/3. */@Servicepublic class ProducerServiceImpl implements ProducerService &#123; @Resource(name="jmsTemplate") private JmsTemplate jmsTemplate; @Override public void sendMessage(Destination destination, final String msg) &#123; System.out.println(Thread.currentThread().getName()+" 向队列"+destination.toString()+"发送消息---------&gt;"+msg); jmsTemplate.send(destination, new MessageCreator() &#123; public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage(msg); &#125; &#125;); &#125; @Override public void sendMessage(final String msg) &#123; String destination = jmsTemplate.getDefaultDestinationName(); System.out.println(Thread.currentThread().getName()+" 向队列"+destination+"发送消息--------&gt;"+msg); jmsTemplate.send(new MessageCreator() &#123; public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage(msg); &#125; &#125;); &#125;&#125; ConsumerService.java 123456789import javax.jms.Destination;import javax.jms.TextMessage;/** * Created by Administrator on 2017/5/3. */public interface ConsumerService &#123; TextMessage receive(Destination destination);&#125; ConsumerServiceImpl.java 123456789101112131415161718192021222324252627282930import cn.edu.hust.activemq.service.ConsumerService;import javax.jms.Destination;import javax.jms.TextMessage;import org.springframework.jms.core.JmsTemplate;import org.springframework.stereotype.Service;import javax.annotation.Resource;import javax.jms.JMSException;/** * Created by Administrator on 2017/5/3. */@Servicepublic class ConsumerServiceImpl implements ConsumerService &#123; @Resource(name="jmsTemplate") private JmsTemplate jmsTemplate; @Override public TextMessage receive(Destination destination)&#123; TextMessage textMessage = (TextMessage) jmsTemplate.receive(destination); try&#123; System.out.println("从队列" + destination.toString() + "收到了消息：\t" + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; return textMessage; &#125;&#125; QueueMessageListener.java 1234567891011121314151617181920import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage;/** * Created by Administrator on 2017/5/3. */public class QueueMessageListener implements MessageListener &#123; public void onMessage(Message message) &#123; TextMessage tm = (TextMessage) message; try &#123; System.out.println("QueueMessageListener监听到了文本消息：\t" + tm.getText()); //do something ... &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 接下来是controller: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import cn.edu.hust.activemq.service.ConsumerService;import cn.edu.hust.activemq.service.ProducerService;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.ResponseBody;import javax.annotation.Resource;import javax.jms.Destination;import javax.jms.TextMessage;/** * Created by Administrator on 2017/5/3. */@Controllerpublic class MessageController &#123; private Logger logger = LoggerFactory.getLogger(MessageController.class); @Resource(name = "demoQueueDestination") private Destination destination; //队列消息生产者 @Resource private ProducerService producer; //队列消息消费者 @Resource private ConsumerService consumer; @RequestMapping(value = "/SendMessage", method = RequestMethod.GET) @ResponseBody public void send(String msg) &#123; logger.info(Thread.currentThread().getName()+"------------开始发送消息"); producer.sendMessage(msg); logger.info(Thread.currentThread().getName()+"------------发送完毕"); &#125; @RequestMapping(value= "/ReceiveMessage",method = RequestMethod.GET) @ResponseBody public Object receive()&#123; logger.info(Thread.currentThread().getName()+"------------开始接受消息"); TextMessage tm = consumer.receive(destination); logger.info(Thread.currentThread().getName()+"------------接受完毕"); return tm; &#125;&#125; 代码就是上面这些，我们先启动acticemq server，然后下启动工程，在地址栏中输入：http://localhost:8080/SendMessage?msg=nihao，代码很简单我就没有写前台页面啦，msg部分你可以随便写。回车之后我们去看一下控制台消息就发送出去了。]]></content>
      <categories>
        <category>activeMQ</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis Generator最完整配置详解]]></title>
    <url>%2Fposts%2Fa9e1e2fd.html</url>
    <content type="text"><![CDATA[转自：【http://www.jianshu.com/p/e09d2370b796】 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt; &lt;!-- 配置生成器 --&gt; &lt;generatorConfiguration&gt; &lt;!-- 可以用于加载配置项或者配置文件，在整个配置文件中就可以使用$&#123;propertyKey&#125;的方式来引用配置项 resource：配置资源加载地址，使用resource，MBG从classpath开始找，比如com/myproject/generatorConfig.properties url：配置资源加载地质，使用URL的方式，比如file:///C:/myfolder/generatorConfig.properties. 注意，两个属性只能选址一个; 另外，如果使用了mybatis-generator-maven-plugin，那么在pom.xml中定义的properties都可以直接在generatorConfig.xml中使用 &lt;properties resource="" url="" /&gt; --&gt; &lt;!-- 在MBG工作的时候，需要额外加载的依赖包 location属性指明加载jar/zip包的全路径 &lt;classPathEntry location="/Program Files/IBM/SQLLIB/java/db2java.zip" /&gt; --&gt; &lt;!-- context:生成一组对象的环境 id:必选，上下文id，用于在生成错误时提示 defaultModelType:指定生成对象的样式 1，conditional：类似hierarchical； 2，flat：所有内容（主键，blob）等全部生成在一个对象中； 3，hierarchical：主键生成一个XXKey对象(key class)，Blob等单独生成一个对象，其他简单属性在一个对象中(record class) targetRuntime: 1，MyBatis3：默认的值，生成基于MyBatis3.x以上版本的内容，包括XXXBySample； 2，MyBatis3Simple：类似MyBatis3，只是不生成XXXBySample； introspectedColumnImpl：类全限定名，用于扩展MBG --&gt; &lt;context id="mysql" defaultModelType="hierarchical" targetRuntime="MyBatis3Simple" &gt; &lt;!-- 自动识别数据库关键字，默认false，如果设置为true，根据SqlReservedWords中定义的关键字列表； 一般保留默认值，遇到数据库关键字（Java关键字），使用columnOverride覆盖 --&gt; &lt;property name="autoDelimitKeywords" value="false"/&gt; &lt;!-- 生成的Java文件的编码 --&gt; &lt;property name="javaFileEncoding" value="UTF-8"/&gt; &lt;!-- 格式化java代码 --&gt; &lt;property name="javaFormatter" value="org.mybatis.generator.api.dom.DefaultJavaFormatter"/&gt; &lt;!-- 格式化XML代码 --&gt; &lt;property name="xmlFormatter" value="org.mybatis.generator.api.dom.DefaultXmlFormatter"/&gt; &lt;!-- beginningDelimiter和endingDelimiter：指明数据库的用于标记数据库对象名的符号，比如ORACLE就是双引号，MYSQL默认是`反引号； --&gt; &lt;property name="beginningDelimiter" value="`"/&gt; &lt;property name="endingDelimiter" value="`"/&gt; &lt;!-- 必须要有的，使用这个配置链接数据库 @TODO:是否可以扩展 --&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql:///pss" userId="root" password="admin"&gt; &lt;!-- 这里面可以设置property属性，每一个property属性都设置到配置的Driver上 --&gt; &lt;/jdbcConnection&gt; &lt;!-- java类型处理器 用于处理DB中的类型到Java中的类型，默认使用JavaTypeResolverDefaultImpl； 注意一点，默认会先尝试使用Integer，Long，Short等来对应DECIMAL和 NUMERIC数据类型； --&gt; &lt;javaTypeResolver type="org.mybatis.generator.internal.types.JavaTypeResolverDefaultImpl"&gt; &lt;!-- true：使用BigDecimal对应DECIMAL和 NUMERIC数据类型 false：默认, scale&gt;0;length&gt;18：使用BigDecimal; scale=0;length[10,18]：使用Long； scale=0;length[5,9]：使用Integer； scale=0;length&lt;5：使用Short； --&gt; &lt;property name="forceBigDecimals" value="false"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- java模型创建器，是必须要的元素 负责：1，key类（见context的defaultModelType）；2，java类；3，查询类 targetPackage：生成的类要放的包，真实的包受enableSubPackages属性控制； targetProject：目标项目，指定一个存在的目录下，生成的内容会放到指定目录中，如果目录不存在，MBG不会自动建目录 --&gt; &lt;javaModelGenerator targetPackage="com._520it.mybatis.domain" targetProject="src/main/java"&gt; &lt;!-- for MyBatis3/MyBatis3Simple 自动为每一个生成的类创建一个构造方法，构造方法包含了所有的field；而不是使用setter； --&gt; &lt;property name="constructorBased" value="false"/&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;!-- for MyBatis3 / MyBatis3Simple 是否创建一个不可变的类，如果为true， 那么MBG会创建一个没有setter方法的类，取而代之的是类似constructorBased的类 --&gt; &lt;property name="immutable" value="false"/&gt; &lt;!-- 设置一个根对象， 如果设置了这个根对象，那么生成的keyClass或者recordClass会继承这个类；在Table的rootClass属性中可以覆盖该选项 注意：如果在key class或者record class中有root class相同的属性，MBG就不会重新生成这些属性了，包括： 1，属性名相同，类型相同，有相同的getter/setter方法； --&gt; &lt;property name="rootClass" value="com._520it.mybatis.domain.BaseDomain"/&gt; &lt;!-- 设置是否在getter方法中，对String类型字段调用trim()方法 --&gt; &lt;property name="trimStrings" value="true"/&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成SQL map的XML文件生成器， 注意，在Mybatis3之后，我们可以使用mapper.xml文件+Mapper接口（或者不用mapper接口）， 或者只使用Mapper接口+Annotation，所以，如果 javaClientGenerator配置中配置了需要生成XML的话，这个元素就必须配置 targetPackage/targetProject:同javaModelGenerator --&gt; &lt;sqlMapGenerator targetPackage="com._520it.mybatis.mapper" targetProject="src/main/resources"&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 对于mybatis来说，即生成Mapper接口，注意，如果没有配置该元素，那么默认不会生成Mapper接口 targetPackage/targetProject:同javaModelGenerator type：选择怎么生成mapper接口（在MyBatis3/MyBatis3Simple下）： 1，ANNOTATEDMAPPER：会生成使用Mapper接口+Annotation的方式创建（SQL生成在annotation中），不会生成对应的XML； 2，MIXEDMAPPER：使用混合配置，会生成Mapper接口，并适当添加合适的Annotation，但是XML会生成在XML中； 3，XMLMAPPER：会生成Mapper接口，接口完全依赖XML； 注意，如果context是MyBatis3Simple：只支持ANNOTATEDMAPPER和XMLMAPPER --&gt; &lt;javaClientGenerator targetPackage="com._520it.mybatis.mapper" type="ANNOTATEDMAPPER" targetProject="src/main/java"&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;!-- 可以为所有生成的接口添加一个父接口，但是MBG只负责生成，不负责检查 &lt;property name="rootInterface" value=""/&gt; --&gt; &lt;/javaClientGenerator&gt; &lt;!-- 选择一个table来生成相关文件，可以有一个或多个table，必须要有table元素 选择的table会生成一下文件： 1，SQL map文件 2，生成一个主键类； 3，除了BLOB和主键的其他字段的类； 4，包含BLOB的类； 5，一个用户生成动态查询的条件类（selectByExample, deleteByExample），可选； 6，Mapper接口（可选） tableName（必要）：要生成对象的表名； 注意：大小写敏感问题。正常情况下，MBG会自动的去识别数据库标识符的大小写敏感度，在一般情况下，MBG会 根据设置的schema，catalog或tablename去查询数据表，按照下面的流程： 1，如果schema，catalog或tablename中有空格，那么设置的是什么格式，就精确的使用指定的大小写格式去查询； 2，否则，如果数据库的标识符使用大写的，那么MBG自动把表名变成大写再查找； 3，否则，如果数据库的标识符使用小写的，那么MBG自动把表名变成小写再查找； 4，否则，使用指定的大小写格式查询； 另外的，如果在创建表的时候，使用的""把数据库对象规定大小写，就算数据库标识符是使用的大写，在这种情况下也会使用给定的大小写来创建表名； 这个时候，请设置delimitIdentifiers="true"即可保留大小写格式； 可选： 1，schema：数据库的schema； 2，catalog：数据库的catalog； 3，alias：为数据表设置的别名，如果设置了alias，那么生成的所有的SELECT SQL语句中，列名会变成：alias_actualColumnName 4，domainObjectName：生成的domain类的名字，如果不设置，直接使用表名作为domain类的名字；可以设置为somepck.domainName，那么会自动把domainName类再放到somepck包里面； 5，enableInsert（默认true）：指定是否生成insert语句； 6，enableSelectByPrimaryKey（默认true）：指定是否生成按照主键查询对象的语句（就是getById或get）； 7，enableSelectByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询语句； 8，enableUpdateByPrimaryKey（默认true）：指定是否生成按照主键修改对象的语句（即update)； 9，enableDeleteByPrimaryKey（默认true）：指定是否生成按照主键删除对象的语句（即delete）； 10，enableDeleteByExample（默认true）：MyBatis3Simple为false，指定是否生成动态删除语句； 11，enableCountByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询总条数语句（用于分页的总条数查询）； 12，enableUpdateByExample（默认true）：MyBatis3Simple为false，指定是否生成动态修改语句（只修改对象中不为空的属性）； 13，modelType：参考context元素的defaultModelType，相当于覆盖； 14，delimitIdentifiers：参考tableName的解释，注意，默认的delimitIdentifiers是双引号，如果类似MYSQL这样的数据库，使用的是`（反引号，那么还需要设置context的beginningDelimiter和endingDelimiter属性） 15，delimitAllColumns：设置是否所有生成的SQL中的列名都使用标识符引起来。默认为false，delimitIdentifiers参考context的属性 注意，table里面很多参数都是对javaModelGenerator，context等元素的默认属性的一个复写； --&gt; &lt;table tableName="userinfo" &gt; &lt;!-- 参考 javaModelGenerator 的 constructorBased属性--&gt; &lt;property name="constructorBased" value="false"/&gt; &lt;!-- 默认为false，如果设置为true，在生成的SQL中，table名字不会加上catalog或schema； --&gt; &lt;property name="ignoreQualifiersAtRuntime" value="false"/&gt; &lt;!-- 参考 javaModelGenerator 的 immutable 属性 --&gt; &lt;property name="immutable" value="false"/&gt; &lt;!-- 指定是否只生成domain类，如果设置为true，只生成domain类，如果还配置了sqlMapGenerator，那么在mapper XML文件中，只生成resultMap元素 --&gt; &lt;property name="modelOnly" value="false"/&gt; &lt;!-- 参考 javaModelGenerator 的 rootClass 属性 &lt;property name="rootClass" value=""/&gt; --&gt; &lt;!-- 参考javaClientGenerator 的 rootInterface 属性 &lt;property name="rootInterface" value=""/&gt; --&gt; &lt;!-- 如果设置了runtimeCatalog，那么在生成的SQL中，使用该指定的catalog，而不是table元素上的catalog &lt;property name="runtimeCatalog" value=""/&gt; --&gt; &lt;!-- 如果设置了runtimeSchema，那么在生成的SQL中，使用该指定的schema，而不是table元素上的schema &lt;property name="runtimeSchema" value=""/&gt; --&gt; &lt;!-- 如果设置了runtimeTableName，那么在生成的SQL中，使用该指定的tablename，而不是table元素上的tablename &lt;property name="runtimeTableName" value=""/&gt; --&gt; &lt;!-- 注意，该属性只针对MyBatis3Simple有用； 如果选择的runtime是MyBatis3Simple，那么会生成一个SelectAll方法，如果指定了selectAllOrderByClause，那么会在该SQL中添加指定的这个order条件； --&gt; &lt;property name="selectAllOrderByClause" value="age desc,username asc"/&gt; &lt;!-- 如果设置为true，生成的model类会直接使用column本身的名字，而不会再使用驼峰命名方法，比如BORN_DATE，生成的属性名字就是BORN_DATE,而不会是bornDate --&gt; &lt;property name="useActualColumnNames" value="false"/&gt; &lt;!-- generatedKey用于生成生成主键的方法， 如果设置了该元素，MBG会在生成的&lt;insert&gt;元素中生成一条正确的&lt;selectKey&gt;元素，该元素可选 column:主键的列名； sqlStatement：要生成的selectKey语句，有以下可选项： Cloudscape:相当于selectKey的SQL为： VALUES IDENTITY_VAL_LOCAL() DB2 :相当于selectKey的SQL为： VALUES IDENTITY_VAL_LOCAL() DB2_MF :相当于selectKey的SQL为：SELECT IDENTITY_VAL_LOCAL() FROM SYSIBM.SYSDUMMY1 Derby :相当于selectKey的SQL为：VALUES IDENTITY_VAL_LOCAL() HSQLDB :相当于selectKey的SQL为：CALL IDENTITY() Informix :相当于selectKey的SQL为：select dbinfo('sqlca.sqlerrd1') from systables where tabid=1 MySql :相当于selectKey的SQL为：SELECT LAST_INSERT_ID() SqlServer :相当于selectKey的SQL为：SELECT SCOPE_IDENTITY() SYBASE :相当于selectKey的SQL为：SELECT @@IDENTITY JDBC :相当于在生成的insert元素上添加useGeneratedKeys="true"和keyProperty属性 &lt;generatedKey column="" sqlStatement=""/&gt; --&gt; &lt;!-- 该元素会在根据表中列名计算对象属性名之前先重命名列名，非常适合用于表中的列都有公用的前缀字符串的时候， 比如列名为：CUST_ID,CUST_NAME,CUST_EMAIL,CUST_ADDRESS等； 那么就可以设置searchString为"^CUST_"，并使用空白替换，那么生成的Customer对象中的属性名称就不是 custId,custName等，而是先被替换为ID,NAME,EMAIL,然后变成属性：id，name，email； 注意，MBG是使用java.util.regex.Matcher.replaceAll来替换searchString和replaceString的， 如果使用了columnOverride元素，该属性无效； &lt;columnRenamingRule searchString="" replaceString=""/&gt; --&gt; &lt;!-- 用来修改表中某个列的属性，MBG会使用修改后的列来生成domain的属性； column:要重新设置的列名； 注意，一个table元素中可以有多个columnOverride元素哈~ --&gt; &lt;!--生成的实体类字段与表中字段名不同，property属性制定实体类字段名称--&gt; &lt;columnOverride column="para_index" property="index"&gt; &lt;/columnOverride&gt; &lt;columnOverride column="username"&gt; &lt;!-- 使用property属性来指定列要生成的属性名称 --&gt; &lt;property name="property" value="userName"/&gt; &lt;!-- javaType用于指定生成的domain的属性类型，使用类型的全限定名 &lt;property name="javaType" value=""/&gt; --&gt; &lt;!-- jdbcType用于指定该列的JDBC类型 &lt;property name="jdbcType" value=""/&gt; --&gt; &lt;!-- typeHandler 用于指定该列使用到的TypeHandler，如果要指定，配置类型处理器的全限定名 注意，mybatis中，不会生成到mybatis-config.xml中的typeHandler 只会生成类似：where id = #&#123;id,jdbcType=BIGINT,typeHandler=com._520it.mybatis.MyTypeHandler&#125;的参数描述 &lt;property name="jdbcType" value=""/&gt; --&gt; &lt;!-- 参考table元素的delimitAllColumns配置，默认为false &lt;property name="delimitedColumnName" value=""/&gt; --&gt; &lt;/columnOverride&gt; &lt;!-- ignoreColumn设置一个MGB忽略的列，如果设置了改列，那么在生成的domain中，生成的SQL中，都不会有该列出现 column:指定要忽略的列的名字； delimitedColumnName：参考table元素的delimitAllColumns配置，默认为false 注意，一个table元素中可以有多个ignoreColumn元素 &lt;ignoreColumn column="deptId" delimitedColumnName=""/&gt; --&gt; &lt;/table&gt; &lt;/context&gt; &lt;/generatorConfiguration&gt;]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习(九)-Netty编解码技术之Marshalling]]></title>
    <url>%2Fposts%2Fccb5d663.html</url>
    <content type="text"><![CDATA[前面我们讲过protobuf的使用，主流的编解码框架其实还有很多种： ①JBoss的Marshalling包 ②google的Protobuf ③基于Protobuf的Kyro ④Apache的Thrift JBoss Marshalling是一个Java对象的序列化API包，修正了JDK自带的序列化包的很多问题，但又保持跟java.io.Serializable接口的兼容；同时增加了一些可调的参数和附加的特性，并且这些参数和特性可通过工厂类进行配置。 相比于传统的Java序列化机制，它的优点如下： 1) 可插拔的类解析器，提供更加便捷的类加载定制策略，通过一个接口即可实现定制； 2) 可插拔的对象替换技术，不需要通过继承的方式； 3) 可插拔的预定义类缓存表，可以减小序列化的字节数组长度，提升常用类型的对象序列化性能； 4) 无须实现java.io.Serializable接口，即可实现Java序列化； 5) 通过缓存技术提升对象的序列化性能。 相比于protobuf和thrift的两种编解码框架，JBoss Marshalling更多是在JBoss内部使用，应用范围有限。 Protobuf全称Google Protocol Buffers，它由谷歌开源而来，在谷歌内部久经考验。它将数据结构以.proto文件进行描述，通过代码生成工具可以生成对应数据结构的POJO对象和Protobuf相关的方法和属性。 它的特点如下： 1) 结构化数据存储格式（XML，JSON等）； 2) 高效的编解码性能； 3) 语言无关、平台无关、扩展性好； 4) 官方支持Java、C++和Python三种语言。 首先我们来看下为什么不使用XML，尽管XML的可读性和可扩展性非常好，也非常适合描述数据结构，但是XML解析的时间开销和XML为了可读性而牺牲的空间开销都非常大，因此不适合做高性能的通信协议。Protobuf使用二进制编码，在空间和性能上具有更大的优势。 Protobuf另一个比较吸引人的地方就是它的数据描述文件和代码生成机制，利用数据描述文件对数据结构进行说明的优点如下： 1) 文本化的数据结构描述语言，可以实现语言和平台无关，特别适合异构系统间的集成； 2) 通过标识字段的顺序，可以实现协议的前向兼容； 3) 自动代码生成，不需要手工编写同样数据结构的C++和Java版本； 4) 方便后续的管理和维护。相比于代码，结构化的文档更容易管理和维护。 Thrift源于Facebook，在2007年Facebook将Thrift作为一个开源项目提交给Apache基金会。对于当时的Facebook来说，创造Thrift是为了解决Facebook各系统间大数据量的传输通信以及系统之间语言环境不同需要跨平台的特性，因此Thrift可以支持多种程序语言，如C++、C#、Cocoa、Erlang、Haskell、Java、Ocami、Perl、PHP、Python、Ruby和Smalltalk。 在多种不同的语言之间通信，Thrift可以作为高性能的通信中间件使用，它支持数据（对象）序列化和多种类型的RPC服务。Thrift适用于静态的数据交换，需要先确定好它的数据结构，当数据结构发生变化时，必须重新编辑IDL文件，生成代码和编译，这一点跟其他IDL工具相比可以视为是Thrift的弱项。Thrift适用于搭建大型数据交换及存储的通用工具，对于大型系统中的内部数据传输，相对于JSON和XML在性能和传输大小上都有明显的优势。 Thrift主要由5部分组成： 1) 语言系统以及IDL编译器：负责由用户给定的IDL文件生成相应语言的接口代码； 2) TProtocol：RPC的协议层，可以选择多种不同的对象序列化方式，如JSON和Binary； 3) TTransport：RPC的传输层，同样可以选择不同的传输层实现，如socket、NIO、MemoryBuffer等； 4) TProcessor：作为协议层和用户提供的服务实现之间的纽带，负责调用服务实现的接口； 5) TServer：聚合TProtocol、TTransport和TProcessor等对象。 我们重点关注的是编解码框架，与之对应的就是TProtocol。由于Thrift的RPC服务调用和编解码框架绑定在一起，所以，通常我们使用Thrift的时候会采取RPC框架的方式。但是，它的TProtocol编解码框架还是可以以类库的方式独立使用的。 与Protobuf比较类似的是，Thrift通过IDL描述接口和数据结构定义，它支持8种Java基本类型、Map、Set和List，支持可选和必选定义，功能非常强大。因为可以定义数据结构中字段的顺序，所以它也可以支持协议的前向兼容。 Thrift支持三种比较典型的编解码方式： 1) 通用的二进制编解码； 2) 压缩二进制编解码； 3) 优化的可选字段压缩编解码。 由于支持二进制压缩编解码，Thrift的编解码性能表现也相当优异，远远超过Java序列化和RMI等。 这一节我们来讲解JBoss的Marshalling的使用。 和protobuf的使用不同，netty默认支持protobuf，所以为他预设了一个编解码器：ProtobufVarint32LengthFieldPrepender，ProtobufVarint32FrameDecoder。那如果采用jboss-marshalling进行编解码，则没有这么好的运气我们需要自己优先创建一个编解码的工厂类，供信息通讯时候对信息的编解码。 pom文件如下，需要新增两个jar包：jboss-marshalling，jboss-marshalling-serial。 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.edu.hust.netty&lt;/groupId&gt; &lt;artifactId&gt;netty&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;netty Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.5.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jboss.marshalling&lt;/groupId&gt; &lt;artifactId&gt;jboss-marshalling-river&lt;/artifactId&gt; &lt;version&gt;1.4.10.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jboss.marshalling&lt;/groupId&gt; &lt;artifactId&gt;jboss-marshalling-serial&lt;/artifactId&gt; &lt;version&gt;1.4.11.Final&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;netty&lt;/finalName&gt; &lt;/build&gt;&lt;/project&gt; 我们先来写一个工厂类，手动创建编解码器： 1234567891011121314151617181920212223242526272829303132333435363738394041import io.netty.handler.codec.marshalling.*;import org.jboss.marshalling.MarshallerFactory;import org.jboss.marshalling.Marshalling;import org.jboss.marshalling.MarshallingConfiguration;/** * Marshalling工厂 */public final class MarshallingCodeCFactory &#123; /** * 创建Jboss Marshalling解码器MarshallingDecoder * @return MarshallingDecoder */ public static MarshallingDecoder buildMarshallingDecoder() &#123; //首先通过Marshalling工具类的精通方法获取Marshalling实例对象 参数serial标识创建的是java序列化工厂对象。 final MarshallerFactory marshallerFactory = Marshalling.getProvidedMarshallerFactory("serial"); //创建了MarshallingConfiguration对象，配置了版本号为5 final MarshallingConfiguration configuration = new MarshallingConfiguration(); configuration.setVersion(5); //根据marshallerFactory和configuration创建provider UnmarshallerProvider provider = new DefaultUnmarshallerProvider(marshallerFactory, configuration); //构建Netty的MarshallingDecoder对象，俩个参数分别为provider和单个消息序列化后的最大长度 MarshallingDecoder decoder = new MarshallingDecoder(provider, 1024 * 1024 * 1); return decoder; &#125; /** * 创建Jboss Marshalling编码器MarshallingEncoder * @return MarshallingEncoder */ public static MarshallingEncoder buildMarshallingEncoder() &#123; final MarshallerFactory marshallerFactory = Marshalling.getProvidedMarshallerFactory("serial"); final MarshallingConfiguration configuration = new MarshallingConfiguration(); configuration.setVersion(5); MarshallerProvider provider = new DefaultMarshallerProvider(marshallerFactory, configuration); //构建Netty的MarshallingEncoder对象，MarshallingEncoder用于实现序列化接口的POJO对象序列化为二进制数组 MarshallingEncoder encoder = new MarshallingEncoder(provider); return encoder; &#125;&#125; 下面是服务端： 12345678910111213141516171819202122232425262728293031323334353637383940import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioServerSocketChannel;/** * Created by Administrator on 2017/3/11. */public class HelloWordServer &#123; private int port; public HelloWordServer(int port) &#123; this.port = port; &#125; public void start()&#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); ServerBootstrap server = new ServerBootstrap().group(bossGroup,workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ServerChannelInitializer()); try &#123; ChannelFuture future = server.bind(port).sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HelloWordServer server = new HelloWordServer(7788); server.start(); &#125;&#125; 服务端Initializer： 1234567891011121314151617181920212223import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelPipeline;import io.netty.channel.socket.SocketChannel;import io.netty.handler.codec.DelimiterBasedFrameDecoder;import io.netty.handler.codec.Delimiters;import io.netty.handler.codec.string.StringDecoder;import io.netty.handler.codec.string.StringEncoder;/** * Created by Administrator on 2017/3/11. */public class ServerChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(MarshallingCodeCFactory.buildMarshallingDecoder()); pipeline.addLast(MarshallingCodeCFactory.buildMarshallingEncoder()); // 自己的逻辑Handler pipeline.addLast("handler", new HelloWordServerHandler()); &#125;&#125; 注意我们在这里加入了刚才我们写的编解码器哈，顺序没有关系。 服务端handler： 123456789101112131415161718192021222324252627import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;/** * Created by Administrator on 2017/3/11. */public class HelloWordServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if(msg instanceof String)&#123; System.out.println(msg.toString()); &#125;else&#123; ctx.writeAndFlush("received your msg"); Msg m = (Msg)msg; System.out.println("client: "+m.getBody()); m.setBody("人生苦短，快用python"); ctx.writeAndFlush(m); &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; super.exceptionCaught(ctx, cause); ctx.close(); &#125;&#125; 接下来是客户端： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import io.netty.bootstrap.Bootstrap;import io.netty.channel.Channel;import io.netty.channel.ChannelFuture;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioSocketChannel;import java.io.BufferedReader;import java.io.InputStreamReader;/** * Created by Administrator on 2017/3/11. */public class HelloWorldClient &#123; private int port; private String address; public HelloWorldClient(int port,String address) &#123; this.port = port; this.address = address; &#125; public void start()&#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new ClientChannelInitializer()); try &#123; ChannelFuture future = bootstrap.connect(address,port).sync(); future.channel().writeAndFlush("Hello Netty Server ,I am a common client"); future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HelloWorldClient client = new HelloWorldClient(7788,"127.0.0.1"); client.start(); &#125;&#125; 客户端Initializer： 123456789101112131415161718192021222324import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelPipeline;import io.netty.channel.socket.SocketChannel;import io.netty.handler.codec.DelimiterBasedFrameDecoder;import io.netty.handler.codec.Delimiters;import io.netty.handler.codec.string.StringDecoder;import io.netty.handler.codec.string.StringEncoder;/** * Created by Administrator on 2017/3/11. */public class ClientChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(MarshallingCodeCFactory.buildMarshallingDecoder()); pipeline.addLast(MarshallingCodeCFactory.buildMarshallingEncoder()); // 客户端的逻辑 pipeline.addLast("handler", new HelloWorldClientHandler()); &#125;&#125; 同样这里也加入编解码器。 客户端handler： 1234567891011121314151617181920212223242526272829303132import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;/** * Created by Administrator on 2017/3/11. */public class HelloWorldClientHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if(msg instanceof String)&#123; System.out.println(msg); &#125;else&#123; Msg m = (Msg)msg; System.out.println("client: "+m.getBody()); &#125; &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; Msg msg = new Msg(); msg.setHeader((byte)0xa); msg.setLength(34); msg.setBody("放纵自己，你好兄弟"); ctx.writeAndFlush(msg); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("Client is close"); &#125;&#125; 我们注意上面有一个Msg对象，这个就是我们自己定义的一个对象，用于网络传输用的： 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.io.Serializable;/** * 自定义一个对象 */public class Msg implements Serializable &#123; private byte header; private String body; private long length; private byte type; public byte getHeader() &#123; return header; &#125; public void setHeader(byte header) &#123; this.header = header; &#125; public String getBody() &#123; return body; &#125; public void setBody(String body) &#123; this.body = body; &#125; public long getLength() &#123; return length; &#125; public void setLength(long length) &#123; this.length = length; &#125; public byte getType() &#123; return type; &#125; public void setType(byte type) &#123; this.type = type; &#125;&#125; 下面我们运行客户端和服务端，可以看到消息已经发出去了：]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习-NIO(一)简介]]></title>
    <url>%2Fposts%2Fec039d95.html</url>
    <content type="text"><![CDATA[I/O简介在 Java 编程中，直到最近一直使用 流 的方式完成 I/O。所有 I/O 都被视为单个的字节的移动，通过一个称为 Stream 的对象一次移动一个字节。流 I/O 用于与外部世界接触。它也在内部使用，用于将对象转换为字节，然后再转换回对象。 Java NIO即Java Non-blocking IO(Java非阻塞I/O)，因为是在Jdk1.4之后增加的一套新的操作I/O工具包，所以一般会被叫做Java New IO。NIO是为提供I/O吞吐量而专门设计，其卓越的性能甚至可以与C媲美。NIO是通过Reactor模式的事件驱动机制来达到Non blocking的，那么什么是Reactor模式呢？Reactor翻译成中文是“反应器”，就是我们将事件注册到Reactor中，当有相应的事件发生时，Reactor便会告知我们有哪些事件发生了，我们再根据具体的事件去做相应的处理。 NIO 与原来的 I/O 有同样的作用和目的，但是它使用不同的方式–块I/O。块 I/O 的效率可以比流 I/O 高许多。NIO 的创建目的是为了让 Java 程序员可以实现高速 I/O 而无需编写自定义的本机代码。NIO 将最耗时的 I/O 操作(即填充和提取缓冲区)转移回操作系统，因而可以极大地提高速度。 面向流 的 I/O 系统一次一个字节地处理数据。一个输入流产生一个字节的数据，一个输出流消费一个字节的数据。为流式数据创建过滤器非常容易。链接几个过滤器，以便每个过滤器只负责单个复杂处理机制的一部分，这样也是相对简单的。不利的一面是，面向流的 I/O 通常相当慢。 一个 面向块 的 I/O 系统以块的形式处理数据。每一个操作都在一步中产生或者消费一个数据块。按块处理数据比按(流式的)字节处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性。 NIO介绍NIO有三个核心模块：Selector(选择器)、Channel(通道)、Buffer(缓冲区)，另外java.nio.charsets包下新增的字符集类也是nio一个重要的模块，但个人觉得不算是NIO的核心，只是一个供NIO核心类使用的工具类。 通道和缓冲区什么是通道通道是对原 I/O 包中的流的模拟。到任何目的地(或来自任何地方)的所有数据都必须通过一个 Channel 对象。一个 Buffer 实质上是一个容器对象。发送给一个通道的所有对象都必须首先放到缓冲区中；同样地，从通道中读取的任何数据都要读到缓冲区中。 Channel是一个对象，可以通过它读取和写入数据。拿 NIO 与原来的 I/O 做个比较，通道就像是流。正如前面提到的，所有数据都通过 Buffer 对象来处理。你永远不会将字节直接写入通道中，相反，你是将数据写入包含一个或者多个字节的缓冲区。同样，你不会直接从通道中读取字节，而是将数据从通道读入缓冲区，再从缓冲区获取这个字节。 下面是JAVA NIO中的一些主要Channel的实现： FileChannel DatagramChannel SocketChannel ServerSocketChannel 正如你所看到的，这些通道涵盖了UDP 和 TCP 网络IO，以及文件IO。 什么是缓冲区Buffer 是一个对象， 它包含一些要写入或者刚读出的数据。 在 NIO 中加入 Buffer 对象，体现了新库与原 I/O 的一个重要区别。在面向流的 I/O 中，将数据直接写入或者将数据直接读到 Stream 对象中。在 NIO 库中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的。在写入数据时，它是写入到缓冲区中的。任何时候访问 NIO 中的数据，您都是将它放到缓冲区中。缓冲区实质上是一个数组。通常它是一个字节数组，但是也可以使用其他种类的数组。但是一个缓冲区不 仅仅 是一个数组。缓冲区提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程。 Buffer与chennel的关系如下： 最常用的缓冲区类型是 ByteBuffer。一个 ByteBuffer 可以在其底层字节数组上进行 get/set 操作(即字节的获取和设置)。ByteBuffer 不是 NIO 中唯一的缓冲区类型。事实上，对于每一种基本 Java 类型都有一种缓冲区类型： ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 每一个 Buffer 类都是 Buffer 接口的一个实例。 除了 ByteBuffer，每一个 Buffer 类都有完全一样的操作，只是它们所处理的数据类型不一样。因为大多数标准 I/O 操作都使用 ByteBuffer，所以它具有所有共享的缓冲区操作以及一些特有的操作。 什么是Selector在并发型服务器程序中使用NIO，实际上是通过网络事件驱动模型实现的。我们应用Select 机制，不用为每一个客户端连接新启线程处理，而是将其注册到特定的Selector 对象上，这就可以在单线程中利用Selector 对象管理大量并发的网络连接，更好的利用了系统资源；采用非阻塞I/O的通信方式，不要求阻塞等待I/O 操作完成即可返回，从而减少了管理I/O 连接导致的系统开销，大幅度提高了系统性能。 当有读或写等任何注册的事件发生时，可以从Selector 中获得相应的SelectionKey ， 从SelectionKey 中可以找到发生的事件和该事件所发生的具体的SelectableChannel，以获得客户端发送过来的数据。由于在非阻塞网络I/O 中采用了事件触发机制，处理程序可以得到系统的主动通知，从而可以实现底层网络I/O无阻塞、流畅地读写，而不像在原来的阻塞模式下处理程序需要不断循环等待。使用NIO，可以编写出性能更好、更易扩展的并发型服务器程序。 这是在一个单线程中使用一个Selector处理4个Channel的图示： 要使用Selector，得先向Selector注册Channel，然后调用它的select()方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件，事件的例子比如有新连接进来或是数据接收等。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习(一)-为什么选择Netty]]></title>
    <url>%2Fposts%2F704e9e4d.html</url>
    <content type="text"><![CDATA[前面我们简单学习了NIO。我们知道java的I/O模型一共有四种，分别是：传统的BIO，伪异步I/O，NIO和AIO。为了澄清概念和分清区别，我们还是先简单的介绍一下他们的概念，然后再去比较优劣。以及探讨我们为什么使用netty。 1.概念澄清1.1 BIOBIO，即Blocking I/O。网络编程的基本模型是Client/Server 模型，也就是两个进程之间进行相互通信，其中服务端提供位置信息(绑定的Ip 地址和监听端口) ，客户端通过连接操作向服务端监听的地址发起连接请求，通过三次握手建立连接，如果连接建在成功，双方就可以通过网络套接字( Socket ) 进行通信。在基于传统同步阻塞模型开发中， ServerSocket 负责绑定IP 地址，启动监听端口:Socket 负责发起连接操作。连接成功之后，双方通过输入和输出流进行同步阻塞式通信。 BIO通信模型图： 解释一下上图： 采用BIO通信模型的服务端，通常由一个独立的Acceptor线程负责监听客户端的连接，它接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端， 统程销毁。这就是典型的一请求一回答通信模型。 对于这种IO模型我们知道：用户线程发出IO请求之后，内核会去查看数据是否就绪，如果没有就绪就会等待数据就绪，而用户线程就会处于阻塞状态，用户线程交出CPU。当数据就绪之后，内核会将数据拷贝到用户线程，并返回结果给用户线程，用户线程才解除block状态。即在读写数据过程中会发生阻塞现象。 1.2 伪异步IO为了解决同步阻塞 I/O 面临的一个链路需要一个线程处理的问题，后来有人对它的线程模型进行了优化一一后端通过一个线程池来处理多个客户端的请求接入，形成客户端个数M: 线程池最大线程数N 的比例关系，其中M 可以远远大于N。通过线程地可以灵活地调配线程资源，设置线程的最大值，防止由于海量并发接入导致线程耗尽。 伪异步IO通信模型图： 采用线程池和任务队列可以实现伪异步I/O通信框架。当有新的客户端接入时，将客户端的Socket 封装成一个Task (该任务实现java.lang.Runnable 接口）投递到后端的线程池中进行处理， JDK 的线程将维护一个消息队列和N个活跃线程， 对消息队列中的任务进行处理。由于统程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的， 无论多少个客户端并发访问， 都不会导致资源的耗尽和省机。 伪异步I/O 通信框架采用了线程池实现，因此避免了为每个请求都创建一个独立线程造成的线程资源耗尽问题。但是由于它底层的通信依然采用同步阻塞模型，因此无法从根本上解决问题。伪异步I/O 实际上仅仅是对之前I/O 线程模型的一个简单优化，它无法从根本上解决同步I/O 导致的通信线程阻塞问题。下面我们就简单分析下通信对方返回应答时间过长会引起的级联故障。 服务端处理缓慢，返回应答消息耗费60s，平时只需要10ms; 采用伪异步I/O 的线程在读取故障服务节点的响应，由于读/取输入流是阻塞的，它将会被同步阻塞60s; 假如所有的可用线程都被故障服务器阻塞，那后续的所有的I/O消息都将在队列中排队; 由于线程地采用阻塞队列实现，当队列积满之后，后续入队列的操作将被阻塞; 由于前端只有一个Accptor 线程接收客户端接入，它被阻塞在线程池的同步阻塞队列之后，新的客户端请求消息将被拒绝，客户端会发生大量的连接超时; 由于几于所有的连接都超时，调用者会认为系统已经崩溃，无法接收新的请求消息。 如何破解这个难题?下面我们再看一下NIO。 1.3 NIONIO,很多人叫他New I/O，由于之前老的I/O 类库是阻塞I/O ，New I/O 类库的目标就是要让Java 支持非阻塞I/O，所以，更多的人喜欢称之为非阻塞I/O(Non-block I/O)。 与Socket类和ServerSocket 类相对应， NIO也提供了SocketChannel 和ServerSocketChannel两种不同的套接字通道实现。这两种新增的通道都支持阻塞和非阻塞两种模式。阻塞模式使用非常简单，但是性能和可靠性都不好，非阻塞模式则正好相反。开发人员可以根据自己的需要来选择合适的模式。一般来说，低负载、低并发的应用程序可以选择同步阻塞I/O以降低编程复杂度:对于高负载、高并发的网络应用，需要使用NIO 的非阻塞模式进行开发。 前面我们已经对NIO进行了介绍，我们知道NIO中引入了缓冲区Buffer，通道Channel和多路复用器Selector的概念。一个多路复用器Selector 可以同时轮询多个Channel，而Channel又是全双工的，同时支持读写操作，使用NIO 编程的优点总结如下： 客户端发起的连接操作是异步的，可以通过在多路复用器注册OP_CONNECT 等待后续结果，不需要像之前的客户端那样被同步阻塞。 SocketChannel 的读写操作都是异步的，如果没有可读写的数据它不会同步等待，直接返回，这样I/O 通信线程就可以处理其他的链路，不需要同步等待这个链路可用。 线程模型的优化:由于JDK 的Selector 在Linux 等主流操作系统上通过epoll 实现，它没有连接句柄数的限制(只受限于操作系统的最大句柄数或者对单个进程的句柄限制)，这意味着一个Selector 线程可以同时处理成千上万个客户端连接，而且性能不会随着客户端的增加而线性下降。因此，它非常适合做高性能、高负载的网络服务器。 1.4 AIONIO 2.0 引入了新的异步通道的概念，并提供了异步文件通道和异步套接字通道的实现。异步通道提供以下两种方式获取获取操作结果： ▷通过java.util.concurrent.Future 类来表示异步操作的结果; ▷在执行异步操作的时候传入一个java.nio.channels; NIO 2.0 的异步套接字通道是真正的异步非阻塞I/O ，对应于UNIX 网络编程中的事件驱动I/O (AIO) 。它不需要通过多路复用器( Selector) 对注册的通道进行轮询操作即可实现异步读写，从而简化了NIO 的编程模型。 前面对不同的I/O模型进行了简单介绍，不同的I/O 模型由于线程模型、API 等差别很大，所以用法的差异也非常大。我们用一个表格来做一个统一说明： 2. 为什么用Netty开发出高质量的NIO 程序并不是一件简单的事情，除去NIO 固有的复杂性和Bug不谈，作为一个NIO 服务端,需要能够处理网络的闪断、客户端的重复接入、客户端的安全认证、消息的编解码、半包读写等情况， 如果你没有足够的NIO 编程经验积累， 一个NIO 框架的稳定往往需要半年甚至更长的时间。更为糟糕的是， 一旦在生产环境中发生问题， 往往会导致跨节点的服务调用中断， 严重的可能会导致整个集群环境都不可用， 需要重启服务器，这种非正常停机会带来巨大的损失。 从可维护性角度看，由于NIO 采用了异步非阻塞编程模型，而且是一个I/O 线程处理多条链路，它的调试和跟踪非常麻烦， 特别是生产环境中的问题，我们无法进行有效的调试和跟踪， 往往只能靠一些日志来帮助分析，定位难度很大。 对于java原生的IO我们之所以不选择使用是因为： NIO的类库和API繁杂使用麻烦，你需要熟练掌握Selectol,ServerSocketChannel,SocketChannel,ByteBuffer 等。 需妥具备其他的额外技能做制垫，例如熟悉Java 多线程编程。这是因为NIO编程涉及到Reactor 模式，你必须对多钱程和网络编程非常如悉，才能编写出高质量的NIO程序。 可靠性能力补齐， 工作量和难度都非常大。例如客户端面临断连重连、网络间断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题， NI0 编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大。 JDK NIO的BUG，比如epoll bug，这个BUG会在linux上导致cpu 100%，使得nio server/client不可用，这个BUG直到jdk 6u4才解决，但是直到JDK1.7中仍然有这个问题，该问题并未被完全解决，只是发生的频率降低了而已。 基于上述原因大多数场景下都不建议直接使原生NIO，除非你精通NIO编程或者是有特殊的需要，否则作为服务器编程的NIO可能会带来巨大的生产隐患。 关于Netty： Netty是一个高性能、异步事件驱动的NIO框架，它提供了对TCP、UDP和文件传输的支持，作为一个异步NIO框架，Netty的所有IO操作都是异步非阻塞的，通过Future-Listener机制，用户可以方便的主动获取或者通过通知机制获得IO操作结果。作为当前最流行的NIO框架，Netty在互联网领域、大数据分布式计算领域、游戏行业、通信行业等获得了广泛的应用，一些业界著名的开源组件也基于Netty的NIO框架构建。 与Netty同样功能的NIO框架还有Mina，Netty的主导作者与Mina的主导作者是同一人，在设计理念上与Mina基本上是一致的。Mina出身于开源界的大牛Apache组织，Netty出身于商业开源大亨Jboss。这几年Netty社区相对比较活跃，所以我们就先选择Netty作为入手网络编程的首选，有时间再学习一下Mina。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习(二）-Helloworld Netty]]></title>
    <url>%2Fposts%2F7ab746e7.html</url>
    <content type="text"><![CDATA[这一节我们来讲解Netty，使用Netty之前我们先了解一下Netty能做什么，无为而学，岂不是白费力气！ 1.使用Netty能够做什么 开发异步、非阻塞的TCP网络应用程序； 开发异步、非阻塞的UDP网络应用程序； 开发异步文件传输应用程序； 开发异步HTTP服务端和客户端应用程序； 提供对多种编解码框架的集成，包括谷歌的Protobuf、Jboss marshalling、Java序列化、压缩编解码、XML解码、字符串编解码等，这些编解码框架可以被用户直接使用； 提供形式多样的编解码基础类库，可以非常方便的实现私有协议栈编解码框架的二次定制和开发； 基于职责链模式的Pipeline-Handler机制，用户可以非常方便的对网络事件进行拦截和定制； 所有的IO操作都是异步的，用户可以通过Future-Listener机制主动Get结果或者由IO线程操作完成之后主动Notify结果，用户的业务线程不需要同步等待； IP黑白名单控制； 打印消息码流； 流量控制和整形； 性能统计； 基于链路空闲事件检测的心跳检测 2. Netty常用类讲解在这里我们就一些我们常用到的类做大致的讲解，然后再写入门程序的时候大致知道每一行都讲了什么。 EventLoop,EventLoopGroup EventLoop目的是为Channel处理IO操作，一个EventLoop可以为多个Channel服务,EventLoopGroup会包含多个EventLoop。 BootStrap,ServerBootstrap 一个Netty应用通常由一个Bootstrap开始，它主要作用是配置整个Netty程序，串联起各个组件。 ChannelInitializer 当一个链接建立时，我们需要知道怎么来接收或者发送数据，当然，我们有各种各样的Handler实现来处理它，那么ChannelInitializer便是用来配置这些Handler，它会提供一个ChannelPipeline，并把Handler加入到ChannelPipeline。 Handler 为了支持各种协议和处理数据的方式，便诞生了Handler组件。Handler主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。 ChannelInboundHandler 一个最常用的Handler。这个Handler的作用就是处理接收到数据时的事件，也就是说，我们的业务逻辑一般就是写在这个Handler里面的，ChannelInboundHandler就是用来处理我们的核心业务逻辑。 Future 在Netty中所有的IO操作都是异步的，因此，你不能立刻得知消息是否被正确处理，但是我们可以过一会等它执行完成或者直接注册一个监听，具体的实现就是通过Future和ChannelFutures,他们可以注册一个监听，当操作执行成功或失败时监听会自动触发。总之，所有的操作都会返回一个ChannelFuture。 3. 第一个Helloworld上面我们已经对常用类进行说明，下面我们就使用这些类来构建我们的第一个入门程序，本示例我使用的是maven来构建工程，如果你使用的是普通的项目则跳过第一步。 首先引入maven jar包： 12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.5.Final&lt;/version&gt;&lt;/dependency&gt; 下面我们来写客户端： 12345678910111213141516171819202122232425262728293031323334353637383940public class HelloWorldClient &#123; private int port; private String address; public HelloWorldClient(int port,String address) &#123; this.port = port; this.address = address; &#125; public void start()&#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new ClientChannelInitializer()); try &#123; Channel channel = bootstrap.connect(address,port).sync().channel(); BufferedReader reader = new BufferedReader(new InputStreamReader(System.in)); for(;;)&#123; String msg = reader.readLine(); if(msg == null)&#123; continue; &#125; channel.writeAndFlush(msg + "\r\n"); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HelloWorldClient client = new HelloWorldClient(7788,"127.0.0.1"); client.start(); &#125;&#125; ChannelInitializer用来配置处理数据的handler： 123456789101112131415161718public class ClientChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); /* * 这个地方的 必须和服务端对应上。否则无法正常解码和编码 * * 解码和编码 我将会在下一节为大家详细的讲解。暂时不做详细的描述 * * / pipeline.addLast("decoder", new StringDecoder()); pipeline.addLast("encoder", new StringEncoder()); // 我们自己的handler pipeline.addLast("handler", new HelloWorldClientHandler()); &#125;&#125; 写一个我们自己的handler，用自己的方式来处理数据： 12345678910111213141516public class HelloWorldClientHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println("server say : "+msg.toString()); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("Client is active"); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("Client is close"); &#125;&#125; 客户端我们写完了，下面开始写服务器端： 12345678910111213141516171819202122232425262728293031public class HelloWordServer &#123; private int port; public HelloWordServer(int port) &#123; this.port = port; &#125; public void start()&#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); ServerBootstrap server = new ServerBootstrap().group(bossGroup,workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ServerChannelInitializer()); try &#123; ChannelFuture future = server.bind(port).sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; HelloWordServer server = new HelloWordServer(7788); server.start(); &#125;&#125; 服务端的ChannelInitializer： 12345678910111213public class ServerChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); // 字符串解码 和 编码 pipeline.addLast("decoder", new StringDecoder()); pipeline.addLast("encoder", new StringEncoder()); // 自己的逻辑Handler pipeline.addLast("handler", new HelloWordServerHandler()); &#125;&#125; 服务器端的handler: 123456789101112131415public class HelloWordServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(ctx.channel().remoteAddress()+"===&gt;server: "+msg.toString()); ctx.write("received your msg"); ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; super.exceptionCaught(ctx, cause); ctx.close(); &#125;&#125; 上面服务器端和客户端的代码都已经写完，下面我们先启动服务端，然后启动客户端，程序中我是在客户端让手动输入，输入结束之后回车，服务器端即可接受数据。 客户端： 服务端：]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java学习-NIO(五)NIO学习总结以及NIO新特性介绍]]></title>
    <url>%2Fposts%2Fda918f82.html</url>
    <content type="text"><![CDATA[我们知道是NIO是在2002年引入到J2SE 1.4里的，很多Java开发者比如我还是不知道怎么充分利用NIO，更少的人知道在Java SE 7里引入了更新的输入/输出 API（NIO.2）。但是对于普通的开发者来说基本的I/O操作就够用了，而NIO则是在处理I/O性能优化方面带来显著性效果。更快的速度则意味着NIO和NIO.2的API暴露了更多低层次的系统操作的入口，这对于开发者而言则意味着更复杂的操作和精巧的程序设计。从前面的几节的讲解来看NIO的操作无不繁琐。要完全掌握还是有点难度的。前面我们讲解了Buffer，Channel，Selector,都是从大的面上去探讨NIO的主要组件。这一节我们则从NIO的特性方面去探讨更细节的一些问题。 1.NIO的新特性总的来说java 中的IO 和NIO的区别主要有3点： IO是面向流的，NIO是面向缓冲的； IO是阻塞的，NIO是非阻塞的； IO是单线程的，NIO 是通过选择器来模拟多线程的； NIO在基础的IO流上发展处新的特点，分别是：内存映射技术，字符及编码，非阻塞I/O和文件锁定。下面我们分别就这些技术做一些说明。 2. 内存映射这个功能主要是为了提高大文件的读写速度而设计的。内存映射文件(memory-mappedfile)能让你创建和修改那些大到无法读入内存的文件。有了内存映射文件，你就可以认为文件已经全部读进了内存，然后把它当成一个非常大的数组来访问了。将文件的一段区域映射到内存中，比传统的文件处理速度要快很多。内存映射文件它虽然最终也是要从磁盘读取数据，但是它并不需要将数据读取到OS内核缓冲区，而是直接将进程的用户私有地址空间中的一部分区域与文件对象建立起映射关系，就好像直接从内存中读、写文件一样，速度当然快了。 NIO中内存映射主要用到以下两个类： java.nio.MappedByteBuffer java.nio.channels.FileChannel 下面我们通过一个例子来看一下内存映射读取文件和普通的IO流读取一个150M大文件的速度对比： 1234567891011121314151617181920212223242526272829303132333435363738public class MemMap &#123; public static void main(String[] args) &#123; try &#123; RandomAccessFile file = new RandomAccessFile("c://1.pdf","rw"); FileChannel channel = file.getChannel(); MappedByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY,0,channel.size()); ByteBuffer buffer1 = ByteBuffer.allocate(1024); byte[] b = new byte[1024]; long len = file.length(); long startTime = System.currentTimeMillis(); //读取内存映射文件 for(int i=0;i&lt;file.length();i+=1024*10)&#123; if (len - i &gt; 1024) &#123; buffer.get(b); &#125; else &#123; buffer.get(new byte[(int)(len - i)]); &#125; &#125; long endTime = System.currentTimeMillis(); System.out.println("使用内存映射方式读取文件总耗时： "+(endTime - startTime)); //普通IO流方式 long startTime1 = System.currentTimeMillis(); while(channel.read(buffer1) &gt; 0)&#123; buffer1.flip(); buffer1.clear(); &#125; long endTime1 = System.currentTimeMillis(); System.out.println("使用普通IO流方式读取文件总耗时： "+(endTime1 - startTime1)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 实验结果为： 效果对比还是挺明显的。我们看到在上面程序中调用FileChannel类的map方法进行内存映射，第一个参数设置映射模式,现在支持3种模式： FileChannel.MapMode.READ_ONLY：只读缓冲区，在缓冲区中如果发生写操作则会产生ReadOnlyBufferException； FileChannel.MapMode.READ_WRITE：读写缓冲区，任何时刻如果通过内存映射的方式修改了文件则立刻会对磁盘上的文件执行相应的修改操作。别的进程如果也共享了同一个映射，则也会同步看到变化。而不是像标准IO那样每个进程有各自的内核缓冲区，比如JAVA代码中，没有执行 IO输出流的 flush() 或者 close() 操作，那么对文件的修改不会更新到磁盘去，除非进程运行结束； FileChannel.MapMode.PRIVATE ：这个比较狠，可写缓冲区，但任何修改是缓冲区私有的，不会回到文件中。所以尽情的修改吧，结局跟突然停电是一样的。 我们注意到FileChannel类中有map方法来建立内存映射，按理说是否应用的有相应的unmap方法来卸载映射内存呢。但是竟然没有找到该方法。一旦建立映射保持有效，直到MappedByteBuffer对象被垃圾收集。 此外，映射缓冲区不会绑定到创建它们的通道。 关闭相关的FileChannel不会破坏映射; 只有缓冲对象本身的处理打破了映射。 内存映射文件的优点： 用户进程将文件数据视为内存，因此不需要发出read()或write()系统调用。 当用户进程触摸映射的内存空间时，将自动生成页面错误，以从磁盘引入文件数据。 如果用户修改映射的内存空间，受影响的页面将自动标记为脏，并随后刷新到磁盘以更新文件。 操作系统的虚拟内存子系统将执行页面的智能缓存，根据系统负载自动管理内存。 数据始终是页面对齐的，不需要缓冲区复制。 可以映射非常大的文件，而不消耗大量内存来复制数据。 下面我们再写一个复制文件的例子来看一下对于一个120M的文件通过这种方式到底能有多快速度的提升： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class MemMapReadWrite &#123; private static int len; /** * 读文件 * * @param fileName * @return */ public static ByteBuffer readFile(String fileName) &#123; try &#123; RandomAccessFile file = new RandomAccessFile(fileName, "rw"); len = (int) file.length(); FileChannel channel = file.getChannel(); MappedByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, len); return buffer.get(new byte[(int) file.length()]); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 写文件 * * @param readFileName * @param writeFileName */ public static void writeFile(String readFileName, String writeFileName) &#123; try &#123; RandomAccessFile file = new RandomAccessFile(writeFileName, "rw"); FileChannel channel = file.getChannel(); ByteBuffer buffer = readFile(readFileName); MappedByteBuffer bytebuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, len); long startTime = System.currentTimeMillis(); for (int i = 0; i &lt; len; i++) &#123; bytebuffer.put(i, buffer.get(i)); &#125; bytebuffer.flip(); long endTime = System.currentTimeMillis(); System.out.println("写文件耗时： " + (endTime - startTime)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; String readFileName = "c://1.pdf"; String writeFileName = "c://2.pdf"; writeFile(readFileName, writeFileName); &#125;&#125; 结果为： 这个速度还是相当惊人的！ 2. 字符及编码说到字符和编码，我们的先说一个概念，字符编码方案： 编码方案定义了如何把字符编码的序列表达为字节序列。字符编码的数值不需要与编码字节相同，也不需要是一对一或一对多个的关系。原则上，把字符集编码和解码近似视为对象的序列化和反序列化。 通常字符数据编码是用于网络传输或文件存储。编码方案不是字符集，它是映射；但是因为它们之间的紧密联系，大部分编码都与一个独立的字符集相关联。例如，UTF-8，仅用来编码Unicode字符集。尽管如此，用一个编码方案处理多个字符集还是可能发生的。例如，EUC可以对几个亚洲语言的字符进行编码。 目前字符编码方案有US-ASCII,UTF-8,GB2312, BIG5,GBK,GB18030,UTF-16BE, UTF-16LE, UTF-16,UNICODE。其中Unicode试图把全世界所有语言的字符集统一到全面的映射之中。虽然战友一定的市场份额，但是目前其余的字符方案仍然广被采用。大部分的操作系统在I/O与文件存储方面仍是以字节为导向的，所以无论使用何种编码，Unicode或其他编码，在字节序列和字符集编码之间仍需要进行转化。 由java.nio.charset包组成的类满足了这个需求。这不是Java平台第一次处理字符集编码，但是它是最系统、最全面、以及最灵活的解决方式。下面我们通过一个小例子来看一下通过不同的Charset实现如何把字符翻译成字节序列： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class CharsetTest &#123; public static void main(String[] args) &#123; Scanner input = new Scanner(System.in); String str = input.next(); String[] charsetNames = &#123;"US-ASCII", "ISO-8859-1", "UTF-8", "UTF-16BE", "UTF-16LE", "UTF-16" &#125;; for (int i = 0; i &lt; charsetNames.length; i++) &#123; doEncode(Charset.forName(charsetNames[i]), str); &#125; &#125; private static void doEncode(Charset cs, String input) &#123; ByteBuffer bb = cs.encode(input); System.out.println("Charset: " + cs.name()); System.out.println(" Input: " + input); System.out.println("Encoded: "); for (int i = 0; bb.hasRemaining(); i++) &#123; int b = bb.get(); int ival = ((int) b) &amp; 0xff; char c = (char) ival; // Keep tabular alignment pretty if (i &lt; 10) System.out.print(" "); // 打印索引序列 System.out.print(" " + i + ": "); // Better formatted output is coming someday... if (ival &lt; 16) System.out.print("0"); // 输出该字节位值的16进制形式 System.out.print(Integer.toHexString(ival)); // 打印出刚才我们输入的字符，如果是空格或者标准字符集中没有包含 //该字符输出空格，否则输出该字符 if (Character.isWhitespace(c) || Character.isISOControl(c)) &#123; System.out.println(""); &#125; else &#123; System.out.println(" (" + c + ")"); &#125; &#125; System.out.println(""); &#125;&#125; 输出为： abc Charset: US-ASCII Input: abc Encoded: 0: 61 (a) 1: 62 (b) 2: 63 (c) Charset: ISO-8859-1 Input: abc Encoded: 0: 61 (a) 1: 62 (b) 2: 63 (c) Charset: UTF-8 Input: abc Encoded: 0: 61 (a) 1: 62 (b) 2: 63 (c) Charset: UTF-16BE Input: abc Encoded: 0: 00 1: 61 (a) 2: 00 3: 62 (b) 4: 00 5: 63 (c) Charset: UTF-16LE Input: abc Encoded: 0: 61 (a) 1: 00 2: 62 (b) 3: 00 4: 63 (c) 5: 00 Charset: UTF-16 Input: abc Encoded: 0: fe (þ) 1: ff (ÿ) 2: 00 3: 61 (a) 4: 00 5: 62 (b) 6: 00 7: 63 (c) Process finished with exit code 0 2.1 字符集编码器和解码器字符的编码和解码是使用很频繁的，试想如果使用UTF-8字符集进行编码，但是却是用UTF-16字符集进行解码，那么这条信息对于用户来说其实是无用的。因为没人能看得懂。在NIO中提供了两个类CharsetEncoder和CharsetDecoder来实现编码转换方案。 CharsetEncoder类是一个状态编码引擎。实际上，编码器有状态意味着它们不是线程安全的：CharsetEncoder对象不应该在线程中共享。CharsetEncoder对象是一个状态转换引擎：字符进去，字节出来。一些编码器的调用可能需要完成转换。编码器存储在调用之间转换的状态。 字符集解码器是编码器的逆转。通过特殊的编码方案把字节编码转化成16-位Unicode字符的序列。与CharsetEncoder类似的, CharsetDecoder也是状态转换引擎。 3. 非阻塞IO一般来说 I/O 模型可以分为：同步阻塞，同步非阻塞，异步阻塞，异步非阻塞 四种IO模型。 同步阻塞 IO ： 在此种方式下，用户进程在发起一个 IO 操作以后，必须等待 IO 操作的完成，只有当真正完成了 IO 操作以后，用户进程才能运行。 JAVA传统的 IO 模型属于此种方式！ 同步非阻塞 IO: 在此种方式下，用户进程发起一个 IO 操作以后可以返回做其它事情，但是用户进程需要时不时的询问 IO 操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的 CPU 资源浪费。其中目前 JAVA 的 NIO 就属于同步非阻塞 IO 。 异步阻塞 IO ： 此种方式下是指应用发起一个 IO 操作以后，不等待内核 IO 操作的完成，等内核完成 IO 操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问 IO 是否完成，那么为什么说是阻塞的呢？因为此时是通过 select 系统调用来完成的，而 select 函数本身的实现方式是阻塞的，而采用 select 函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！ 异步非阻塞 IO: 在此种模式下，用户进程只需要发起一个 IO 操作然后立即返回，等 IO 操作真正的完成以后，应用程序会得到 IO 操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的 IO 读写操作，因为 真正的 IO读取或者写入操作已经由 内核完成了。目前 Java 中还没有支持此种 IO 模型。 上面我们说到nio是使用了同步非阻塞模型。我们知道典型的非阻塞IO模型一般如下： 1234567while(true)&#123; data = socket.read(); if(data!= error)&#123; 处理数据 break; &#125;&#125; 但是对于非阻塞IO就有一个非常严重的问题，在while循环中需要不断地去询问内核数据是否就绪，这样会导致CPU占用率非常高，因此一般情况下很少使用while循环这种方式来读取数据。所以这就不得不说到下面这个概念–多路复用IO模型。 多路复用IO模型 在多路复用IO模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。 NIO 的非阻塞 I/O 机制是围绕 选择器和 通道构建的。 Channel 类表示服务器和客户机之间的一种通信机制。Selector 类是 Channel 的多路复用器。 Selector 类将传入客户机请求多路分用并将它们分派到各自的请求处理程序。NIO 设计背后的基石是反应器(Reactor)设计模式。 关于Reactor模式在此就不多做介绍，网上很多。Reactor负责IO事件的响应，一旦有事件发生，便广播发送给相应的handler去处理。而NIO的设计则是完全按照Reactor模式来设计的。Selector发现某个channel有数据时，会通过SelectorKey来告知，然后实现事件和handler的绑定。 在Reactor模式中，包含如下角色： Reactor 将I/O事件发派给对应的Handler Acceptor 处理客户端连接请求 Handlers 执行非阻塞读/写 我们简单写一个利用了Reactor模式的NIO服务端: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class NIOServer &#123; private static final Logger LOGGER = LoggerFactory.getLogger(NIOServer.class); public static void main(String[] args) throws IOException &#123; Selector selector = Selector.open(); ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); serverSocketChannel.bind(new InetSocketAddress(1234)); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) &#123; if(selector.selectNow() &lt; 0) &#123; continue; &#125; //获取注册的channel Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); //遍历所有的key Iterator&lt;SelectionKey&gt; iterator = keys.iterator(); while(iterator.hasNext()) &#123; SelectionKey key = iterator.next(); iterator.remove(); //如果通道上有事件发生 if (key.isAcceptable()) &#123; //获取该通道 ServerSocketChannel acceptServerSocketChannel = (ServerSocketChannel) key.channel(); SocketChannel socketChannel = acceptServerSocketChannel.accept(); socketChannel.configureBlocking(false); LOGGER.info("Accept request from &#123;&#125;", socketChannel.getRemoteAddress()); //同时将SelectionKey标记为可读，以便读取。 SelectionKey readKey = socketChannel.register(selector, SelectionKey.OP_READ); //利用SelectionKey的attache功能绑定Acceptor 如果有事情，触发Acceptor //Processor对象为自定义处理请求的类 readKey.attach(new Processor()); &#125; else if (key.isReadable()) &#123; Processor processor = (Processor) key.attachment(); processor.process(key); &#125; &#125; &#125; &#125;&#125;/** * Processor类中设置一个线程池来处理请求， * 这样就可以充分利用多线程的优势 */class Processor &#123; private static final Logger LOGGER = LoggerFactory.getLogger(Processor.class); private static final ExecutorService service = Executors.newFixedThreadPool(16); public void process(final SelectionKey selectionKey) &#123; service.submit(new Runnable() &#123; @Override public void run() &#123; ByteBuffer buffer = null; SocketChannel socketChannel = null; try &#123; buffer = ByteBuffer.allocate(1024); socketChannel = (SocketChannel) selectionKey.channel(); int count = socketChannel.read(buffer); if (count &lt; 0) &#123; socketChannel.close(); selectionKey.cancel(); LOGGER.info("&#123;&#125;\t Read ended", socketChannel); &#125; else if(count == 0) &#123; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; LOGGER.info("&#123;&#125;\t Read message &#123;&#125;", socketChannel, new String(buffer.array())); &#125; &#125;); &#125;&#125; 这种方式带来的好处也是不言而喻的。利用多路复用机制避免了线程的阻塞，提高了连接的数量。一个线程就可以管理多个socket，只有当socket真正有读写事件发生才会占用资源来进行实际的读写操作。虽然多线程+ 阻塞IO 达到类似的效果，但是由于在多线程 + 阻塞IO 中，每个socket对应一个线程，这样会造成很大的资源占用，并且尤其是对于长连接来说，线程的资源一直不会释放，如果后面陆续有很多连接的话，就会造成性能上的瓶颈。 另外多路复用IO为何比非阻塞IO模型的效率高是因为在非阻塞IO中，不断地询问socket状态时通过用户线程去进行的，而在多路复用IO中，轮询每个socket状态是内核在进行的，这个效率要比用户线程要高的多。 4. 文件锁定NIO中的文件通道（FileChannel）在读写数据的时候主 要使用了阻塞模式，它不能支持非阻塞模式的读写，而且FileChannel的对象是不能够直接实例化的， 他的实例只能通过getChannel()从一个打开的文件对象上边读取（RandomAccessFile、 FileInputStream、FileOutputStream），并且通过调用getChannel()方法返回一个 Channel对象去连接同一个文件，也就是针对同一个文件进行读写操作。 文件锁的出现解决了很多Java应用程序和非Java程序之间共享文件数据的问题，在以前的JDK版本中，没有文件锁机制使得Java应用程序和其他非Java进程程序之间不能够针对同一个文件共享 数据，有可能造成很多问题，JDK1.4里面有了FileChannel，它的锁机制使得文件能够针对很多非 Java应用程序以及其他Java应用程序可见。但是Java里面 的文件锁机制主要是基于共 享锁模型，在不支持共享锁模型的操作系统上，文件锁本身也起不了作用，JDK1.4使用文件通道读写方式可以向一些文件 发送锁请求，FileChannel的 锁模型主要针对的是每一个文件，并不是每一个线程和每一个读写通道，也就是以文件为中心进行共享以及独占，也就是文件锁本身并不适合于同一个JVM的不同 线程之间。 我们简要看一下相关API： // 如果请求的锁定范围是有效的，阻塞直至获取锁 public final FileLock lock() // 尝试获取锁非阻塞，立刻返回结果 public final FileLock tryLock() // 第一个参数：要锁定区域的起始位置 // 第二个参数：要锁定区域的尺寸, // 第三个参数：true为共享锁，false为独占锁 public abstract FileLock lock (long position, long size, boolean shared) public abstract FileLock tryLock (long position, long size, boolean shared) 锁定区域的范围不一定要限制在文件的size值以内，锁可以扩展从而超出文件尾。因此，我们可以提前把待写入数据的区域锁定，我们也可以锁定一个不包含任何文件内容的区域，比如文件最后一个字节以外的区域。如果之后文件增长到达那块区域，那么你的文件锁就可以保护该区域的文件内容了。相反地，如果你锁定了文件的某一块区域，然后文件增长超出了那块区域，那么新增加 的文件内容将不会受到您的文件锁的保护。 我们写一个简单实例： 1234567891011121314151617181920212223242526272829303132333435public class NIOLock &#123; private static final Logger LOGGER = LoggerFactory.getLogger(NIOServer.class); public static void main(String[] args) throws IOException &#123; FileChannel fileChannel = new RandomAccessFile("c://1.txt", "rw").getChannel(); // 写入4个字节 fileChannel.write(ByteBuffer.wrap("abcd".getBytes())); // 将前2个字节区域锁定（共享锁） FileLock lock1 = fileChannel.lock(0, 2, true); // 当前锁持有锁的类型（共享锁/独占锁） lock1.isShared(); // IOException 不能修改只读的共享区域 // fileChannel.write(ByteBuffer.wrap("a".getBytes())); // 可以修改共享锁之外的区域，从第三个字节开始写入 fileChannel.write(ByteBuffer.wrap("ef".getBytes()), 2); // OverlappingFileLockException 重叠的文件锁异常 // FileLock lock2 = fileChannel.lock(0, 3, true); // FileLock lock3 = fileChannel.lock(0, 3, false); //得到创建锁的通道 lock1.channel(); //锁的起始位置 long position = lock1.position(); //锁的范围 long size = lock1.size(); //判断锁是否与指定文件区域有重叠 lock1.overlaps(position, size); // 记得用try/catch/finally&#123;release()&#125;方法释放锁 lock1.release(); &#125;&#125; 上面我们总结了NIO的4个新特性，对于IO来说都是很重要的功能以及性能的升级。下面我们写一个完整的NIO Socket客户端和服务端，总结一下NIO 的用法，每一行都加了注释： 服务端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public class Server &#123; //标识数字/ private int flag = 0; //缓冲区大小/ private int BLOCK = 4096; //接受数据缓冲区/ private ByteBuffer sendbuffer = ByteBuffer.allocate(BLOCK); //发送数据缓冲区/ private ByteBuffer receivebuffer = ByteBuffer.allocate(BLOCK); private Selector selector; public static void main(String[] args) throws IOException &#123; // TODO Auto-generated method stub int port = 7788; Server server = new Server(port); server.listen(); &#125; public Server(int port) throws IOException &#123; // 打开服务器套接字通道 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 服务器配置为非阻塞 serverSocketChannel.configureBlocking(false); // 检索与此通道关联的服务器套接字 ServerSocket serverSocket = serverSocketChannel.socket(); // 进行服务的绑定 serverSocket.bind(new InetSocketAddress(port)); // 通过open()方法找到Selector selector = Selector.open(); // 注册到selector，等待连接 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println("Server Start----7788:"); &#125; // 监听 private void listen() throws IOException &#123; while (true) &#123; // 选择一组键，并且相应的通道已经打开 selector.select(); // 返回此选择器的已选择键集。 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) &#123; SelectionKey selectionKey = iterator.next(); iterator.remove(); handleKey(selectionKey); &#125; &#125; &#125; // 处理请求 private void handleKey(SelectionKey selectionKey) throws IOException &#123; // 接受请求 ServerSocketChannel server = null; SocketChannel client = null; String receiveText; String sendText; int count = 0; // 测试此键的通道是否已准备好接受新的套接字连接。 if (selectionKey.isAcceptable()) &#123; // 返回为之创建此键的通道。 server = (ServerSocketChannel) selectionKey.channel(); // 接受到此通道套接字的连接。 // 此方法返回的套接字通道（如果有）将处于阻塞模式。 client = server.accept(); // 配置为非阻塞 client.configureBlocking(false); // 注册到selector，等待连接 client.register(selector, SelectionKey.OP_READ); &#125; else if (selectionKey.isReadable()) &#123; // 返回为之创建此键的通道。 client = (SocketChannel) selectionKey.channel(); //将缓冲区清空以备下次读取 receivebuffer.clear(); //读取服务器发送来的数据到缓冲区中 count = client.read(receivebuffer); if (count &gt; 0) &#123; receiveText = new String(receivebuffer.array(), 0, count); System.out.println("服务器端接受客户端数据--:" + receiveText); client.register(selector, SelectionKey.OP_WRITE); &#125; &#125; else if (selectionKey.isWritable()) &#123; //将缓冲区清空以备下次写入 sendbuffer.clear(); // 返回为之创建此键的通道。 client = (SocketChannel) selectionKey.channel(); sendText = "message from server--" + flag++; //向缓冲区中输入数据 sendbuffer.put(sendText.getBytes()); //将缓冲区各标志复位,因为向里面put了数据标志被改变要想从中读取数据发向服务器,就要复位 sendbuffer.flip(); //输出到通道 client.write(sendbuffer); System.out.println("服务器端向客户端发送数据--：" + sendText); client.register(selector, SelectionKey.OP_READ); &#125; &#125;&#125; 客户端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class Client &#123; //标识数字/ private static int flag = 0; //缓冲区大小/ private static int BLOCK = 4096; //接受数据缓冲区/ private static ByteBuffer sendbuffer = ByteBuffer.allocate(BLOCK); //发送数据缓冲区/ private static ByteBuffer receivebuffer = ByteBuffer.allocate(BLOCK); //服务器端地址/ private final static InetSocketAddress SERVER_ADDRESS = new InetSocketAddress( "localhost", 7788); public static void main(String[] args) throws IOException &#123; // TODO Auto-generated method stub // 打开socket通道 SocketChannel socketChannel = SocketChannel.open(); // 设置为非阻塞方式 socketChannel.configureBlocking(false); // 打开选择器 Selector selector = Selector.open(); // 注册连接服务端socket动作 socketChannel.register(selector, SelectionKey.OP_CONNECT); // 连接 socketChannel.connect(SERVER_ADDRESS); // 分配缓冲区大小内存 Set&lt;SelectionKey&gt; selectionKeys; Iterator&lt;SelectionKey&gt; iterator; SelectionKey selectionKey; SocketChannel client; String receiveText; String sendText; int count = 0; while (true) &#123; //选择一组键，其相应的通道已为 I/O 操作准备就绪。 //此方法执行处于阻塞模式的选择操作。 selector.select(); //返回此选择器的已选择键集。 selectionKeys = selector.selectedKeys(); //System.out.println(selectionKeys.size()); iterator = selectionKeys.iterator(); while (iterator.hasNext()) &#123; selectionKey = iterator.next(); if (selectionKey.isConnectable()) &#123; System.out.println("client connect"); client = (SocketChannel) selectionKey.channel(); // 判断此通道上是否正在进行连接操作。 // 完成套接字通道的连接过程。 if (client.isConnectionPending()) &#123; client.finishConnect(); System.out.println("完成连接!"); sendbuffer.clear(); sendbuffer.put("Hello,Server".getBytes()); sendbuffer.flip(); client.write(sendbuffer); &#125; client.register(selector, SelectionKey.OP_READ); &#125; else if (selectionKey.isReadable()) &#123; client = (SocketChannel) selectionKey.channel(); //将缓冲区清空以备下次读取 receivebuffer.clear(); //读取服务器发送来的数据到缓冲区中 count = client.read(receivebuffer); if (count &gt; 0) &#123; receiveText = new String(receivebuffer.array(), 0, count); System.out.println("客户端接受服务器端数据--:" + receiveText); client.register(selector, SelectionKey.OP_WRITE); &#125; &#125; else if (selectionKey.isWritable()) &#123; sendbuffer.clear(); client = (SocketChannel) selectionKey.channel(); sendText = "message from client--" + (flag++); sendbuffer.put(sendText.getBytes()); //将缓冲区各标志复位,因为向里面put了数据标志被改变要想从中读取数据发向服务器,就要复位 sendbuffer.flip(); client.write(sendbuffer); System.out.println("客户端向服务器端发送数据--：" + sendText); client.register(selector, SelectionKey.OP_READ); &#125; &#125; selectionKeys.clear(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（二）----创建并运行java线程]]></title>
    <url>%2Fposts%2Fc845f6f3.html</url>
    <content type="text"><![CDATA[1 实现线程的两种方式上一节我们了解了关于线程的一些基本知识，下面我们正式进入多线程的实现环节。实现线程常用的有两种方式，一种是继承Thread类，一种是实现Runnable接口。当然还有第三种方式，那就是通过线程池来生成线程，后面我们还会学习，一步一个脚印打好基础。 Runnable接口： 12345public interface Runnable &#123; public abstract void run(); &#125; Thread类： 1234567891011121314151617181920212223242526public class Thread implements Runnable &#123; public synchronized void start() &#123; if (threadStatus != 0) throw new IllegalThreadStateException(); group.add(this); boolean started = false; try &#123; start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ &#125; &#125; @Override public void run() &#123; if (target != null) &#123; target.run(); &#125; &#125;&#125; 上面为Thread类和Runnable类的源码，我们可以看到Thread类也是实现了Runnable接口，即Thread是Runnable的实现，那么他们到底在实现多线程上有什么区别呢？ Thread和Runnable解析： ①Runnable接口： Runnable接口是java中线程的定义类。所有线程都是通过该接口来实现，该接口中的run（）方法为实现方法，即线程所要实现的内容写入该方法里面，当线程启动时会调用该方法。在大多数情况下，如果只想重写run（）方法而不重写其他方法，应使用Runnable接口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class ThreadDemo3 &#123; public static void main(String[] args) &#123; //new了两个线程对象——s1和s2 //其中两个对象各对应一个内存区域。线程运行过程中运行都是自己内存块中的数据 Shop1 s1 = new Shop1("小武"); s1.start(); Shop1 s2 = new Shop1("小潘"); s2.start(); /* //实例化了两个线程对象，所以分配了两块内存空间 //执行过程中操作的是自己的内存空间 Shop2 s3 = new Shop2("小武"); s3.run(); Shop2 s4 = new Shop2("小潘"); s4.run(); //实际实例化了两个线程对象 //所以同样分配两个内存空间 Thread t1 = new Thread(new Shop2("小武")); t1.start(); Thread t2 = new Thread(new Shop2("小潘")); t2.start(); */ //创建了两个线程对象，但是使用的是同一个对象——s6 Shop2 s5 = new Shop2("w"); Shop1 s6 = new Shop1("T"); Thread t3 = new Thread(s6); t3.start(); Thread t4 =new Thread(s6); t4.start(); &#125;&#125;/** * 武大郎卖烧饼（因为业务的拓展，现在可以实现多窗口的出售） * 要求：每天只卖10个 * */class Shop1 extends Thread&#123; //private int count = 10; //使用静态变量可以有效的实现资源共享（因为在内存中只有一份count） private static int count = 10; public Shop1(String name) &#123; super(name); &#125; public void run()&#123; //判断是否已经卖完 while(count&gt;0)&#123; count--; System.out.println(this.getName() +"卖出了一个烧饼" + ",现在剩余" + count); &#125; &#125;&#125; /** * 使用接口实现上面的代码 * */class Shop2 implements Runnable&#123; //私有变量，存储剩余烧饼的个数 private int count = 10; //存储当前人的姓名 private String name=""; public Shop2(String name) &#123; this.name = name; &#125; /** * 实现销售的方法 */ public void run()&#123; //判断是否已经卖完 while(count&gt;0)&#123; count--; System.out.println(Thread.currentThread().getId() + "、" + this.name +"卖出了一个烧饼" + ",现在剩余" + count); &#125; &#125;&#125; ②Thread类： Thread类是Runnable接口的实现，jdk给我们提供了一个不用我们去想如何实现线程的方式供我们使用。同样你在继承Thread类的时候也需要重写run()方法来实现你想在线程中实现的内容。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Test&#123; public static void main(String[] args) &#123; //传统方式——单任务方式 /* SimpleClass sc1 = new SimpleClass(); sc1.say("Mike"); SimpleClass sc2 = new SimpleClass(); sc2.say("Han Meimei"); */ //创建一个线程 ThreadClass tc1 = new ThreadClass("Mike"); //启动线程 tc1.start(); //创建一个线程 ThreadClass tc2 = new ThreadClass("Han Meimei"); tc2.start(); &#125; &#125;&#125; class SimpleClass&#123; public void say(String name)&#123; while(true)&#123; System.out.println("Hi,Im " + name); &#125; &#125;&#125;class ThreadClass extends Thread&#123; public ThreadClass(String name) &#123; super(name); &#125; /** * 将父类（Thread）的run()方法进行重写 * 在run()方法中包含了需要执行的代码 */ public void run()&#123; while(true)&#123; System.out.println("Hi,Im " + this.getName() + "|" + this.getId() + "|" + this.getStackTrace()); &#125; &#125;&#125; Thread类中常用方法： run()：如果该线程时使用独立的Runnable运行对象构造的，则调用该Runnable对象的run方法。否则，该方法不执行任何操作并返回。 sleep(longmillls):在指定的毫秒数内让当前正在执行的线程休眠（暂停执行），此操作受到系统计时器和调度程序精度和准确性的影响。 yield():暂停当前正在执行的线程对象，并执行其他线程 start()：使该线程开始运行，java虚拟机再调用该线程的run方法 。 join():等待该线程结束。 对比： 12345上面给出了Thread和Runnable的实现，我们能看到在使用Runnable的方式实现线程的过程中：Shop1 s6 = new Shop1("T");Thread t3 = new Thread(s6);t3.start(); 即把Runnable对象（实现了Runnable接口的对象）还是塞进了Thread中让Thread来实现。那么我们可以new 多个Thread来实现同一个Runnbale对象，即实现了资源的共享，比如在售票系统中多名用户对同一种票的抢购。另一方面，java是单继承多实现的，如果我们使用Thread的话意味着该类只能继承Thread，对于程序的扩展不利，而实现Runnbale接口则没有这个顾虑。考虑程序的健壮性，我们应该尽量使用Runnable来实现我们的线程。 run和start初学多线程我们总是分不清楚run()方法和start()方法的区别，其实我们再看一下上面Thread类的源码就不难发现他们的用法是很容易区分的： run()方法是线程的实现方法，即你需要线程去做什么事情，那么这些实现的内容写在run()里面，当线程启动时就会调用run()方法继而实现run()内部的代码； start()方法是线程的启动方法，即如果你new Thread()这样并不算完。你还得new Thread().start()才算启动这个线程，启动完之后线程内部会主动的调用run()方法执行该线程的业务逻辑代码。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程（一）----线程基础知识]]></title>
    <url>%2Fposts%2Fac18980b.html</url>
    <content type="text"><![CDATA[在任何的生产环境中我们都不可逃避并发这个问题，多线程作为并发问题的技术支持让我们不得不去了解。这一块知识就像一个大蛋糕一样等着我们去分享，抱着学习的心态，记录下自己对并发的认识。 ###1.线程的状态：线程状态图： 1、新建状态（New）：新创建了一个线程对象。 2、就绪状态（Runnable）：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于可运行线程池中，变得可运行，等待获取CPU的使用权。 3、运行状态（Running）：就绪状态的线程获取了CPU，执行程序代码。 4、阻塞状态（Blocked）：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种： （一）、等待阻塞：运行的线程执行wait()方法，JVM会把该线程放入等待池中。 （二）、同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。 （三）、其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。 5、死亡状态（Dead）：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。 ###2.线程调度2.1、调整线程优先级：Java线程有优先级，优先级高的线程会获得较多的运行机会。Java线程的优先级用整数表示，取值范围是1~10，Thread类有以下三个静态常量：static int MAX_PRIORITY线程可以具有的最高优先级，取值为10。static int MIN_PRIORITY线程可以具有的最低优先级，取值为1。static int NORM_PRIORITY分配给线程的默认优先级，取值为5。Thread类的setPriority()和getPriority()方法分别用来设置和获取线程的优先级。每个线程都有默认的优先级。主线程的默认优先级为Thread.NORM_PRIORITY。线程的优先级有继承关系，比如A线程中创建了B线程，那么B将和A具有相同的优先级。JVM提供了10个线程优先级，但与常见的操作系统都不能很好的映射。如果希望程序能移植到各个操作系统中，应该仅仅使用Thread类有以下三个静态常量作为优先级，这样能保证同样的优先级采用了同样的调度方式。 ###3.线程基本方法使用说明：-线程睡眠：Thread.sleep(longmillis)，使线程转到阻塞状态。millis参数设定睡眠的时间，以毫秒为单位。当睡眠结束后，就转为就绪（Runnable）状态。sleep()平台移植性好。-线程等待：Object类中的wait()，导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 唤醒方法。这个两个唤醒方法也是Object类中的方法，行为等价于调用 wait(0) 一样。-线程让步：Thread.yield()，暂停当前正在执行的线程对象，把执行机会让给相同或者更高优先级的线程。-线程加入：join()，等待其他线程终止。在当前线程中调用另一个线程的join()方法，则当前线程转入阻塞状态，直到另一个进程运行结束，当前线程再由阻塞转为就绪状态。-线程唤醒：Object类中的notify()方法，唤醒在此对象监视器上等待的单个线程。如果所有线程都在此对象上等待，则会选择唤醒其中一个线程。选择是任意性的，并在对实现做出决定时发生。线程通过调用其中一个 wait 方法，在对象的监视器上等待。 直到当前的线程放弃此对象上的锁定，才能继续执行被唤醒的线程。被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞争；例如，唤醒的线程在作为锁定此对象的下一个线程方面没有可靠的特权或劣势。类似的方法还有一个notifyAll()，唤醒在此对象监视器上等待的所有线程。 注意：Thread中suspend()和resume()两个方法在JDK1.5中已经废除，不再介绍。因为有死锁倾向。 Java 中的线程可以分为守护线程(Daemon Thread) 和用户线程( User Thread) 。用户线程会阻止JVM 的正常停止，即JVM 正常停止前应用程序中的所有用户线程必须先停止完毕,否则JVM 无法停止。而守护线程则不会影响JVM 的正常停止，即应用程序中有守护线程在运行也不影响JVM 的正常停止。因此，守护线程通常用于执行一些重要性不是很高的任务，例如用于监视其他线程的运行情况。]]></content>
      <categories>
        <category>多线程与并发编程</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
</search>
